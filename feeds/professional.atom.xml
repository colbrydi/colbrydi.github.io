<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Dirk's Home Page - Professional</title><link href="https://colbrydi.github.io/" rel="alternate"></link><link href="https://colbrydi.github.io/feeds/professional.atom.xml" rel="self"></link><id>https://colbrydi.github.io/</id><updated>2020-01-26T00:00:00-05:00</updated><entry><title>Live Closed Captioning</title><link href="https://colbrydi.github.io/live-closed-captioning.html" rel="alternate"></link><published>2020-01-26T00:00:00-05:00</published><updated>2020-01-26T00:00:00-05:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2020-01-26:/live-closed-captioning.html</id><summary type="html">&lt;p&gt;&lt;img alt="Picture of me writing on the white board with live closed captioning" src="//colbrydi.github.io/images/CC_example.png"&gt;&lt;/p&gt;
&lt;p&gt;Many MSU classrooms have two overhead monitors that project on two screens at the front of class.  Each room is equipped with a technology cart that has a desktop computer, overhead camera and laptop connections that can be used to project any of the content to either screen. Up until …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="Picture of me writing on the white board with live closed captioning" src="//colbrydi.github.io/images/CC_example.png"&gt;&lt;/p&gt;
&lt;p&gt;Many MSU classrooms have two overhead monitors that project on two screens at the front of class.  Each room is equipped with a technology cart that has a desktop computer, overhead camera and laptop connections that can be used to project any of the content to either screen. Up until now I haven't really seen many learning benefit of having two screens in smaller classrooms.  However, recently I have been using one screen for my standard presentation and the other screen with a live close caption.  Here is a video with a few examples:&lt;/p&gt;
&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/fE1bveNGeR0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;https://youtu.be/fE1bveNGeR0
To get this to work I am using &lt;a href="https://support.google.com/docs/answer/9109474?hl=en"&gt;Google Slide&lt;/a&gt; presentations which have an option for live closed captioning.  Here are my steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Log into the classroom desktop with my MSU login/password&lt;/li&gt;
&lt;li&gt;Open up Chrome&lt;/li&gt;
&lt;li&gt;Log into &lt;a href="http://googleapps.msu.edu"&gt;http://googleapps.msu.edu&lt;/a&gt; drive using my MSU login/password&lt;/li&gt;
&lt;li&gt;Open a new Google Slides file and set the background to black&lt;/li&gt;
&lt;li&gt;Start the presentation and hit the 'CC' button which appears at the bottom of the screen when I move my mouse&lt;/li&gt;
&lt;li&gt;Attach the portable room microphone to my lapel and turn it on&lt;/li&gt;
&lt;li&gt;Adjust volume as appropriate for room and test the captioning&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Once I have closed captioning work on the right monitor, I plug in my laptop and use the technology cart interface to set the left screen and desktop monitor to the laptop input.  Now I can control my lecture content from my laptop and the close captioning will work on a mostly black screen.  &lt;/p&gt;
&lt;p&gt;Obviously student's with a hearing disability (temporary and long term) may benefit from the technology but overall I have found many students appreciate the extra information. When I am excited I can talk fast and this helps students keep up with what I am saying. I also have had positive feedback from international students for which English is a second language.   &lt;/p&gt;
&lt;p&gt;Another drawback to this approach is that I can't figure out how to download a transcript from the lecture. I full transcript could be useful resource for me as well as students.  &lt;/p&gt;</content><category term="Professional"></category><category term="Accessibility"></category></entry><entry><title>CMSE Impact Video</title><link href="https://colbrydi.github.io/cmse-impact-video.html" rel="alternate"></link><published>2019-12-14T00:00:00-05:00</published><updated>2019-12-14T00:00:00-05:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2019-12-14:/cmse-impact-video.html</id><content type="html">&lt;p&gt;&lt;img alt="Picture of me" src="//colbrydi.github.io/images/3_horiz.png"&gt;&lt;/p&gt;
&lt;p&gt;Xiaoxing (Adele) Han is a videographer who made some amazing videos to help promote research being done in our department.  The following is the video she made of my research which I am very excited to share.  I think she did a great job!&lt;/p&gt;
&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/VdsKHhncXYw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;Thank you Adele!!!&lt;/p&gt;</content><category term="Professional"></category><category term="Research"></category></entry><entry><title>Running ImageJ on the HPCC</title><link href="https://colbrydi.github.io/running-imagej-on-the-hpcc.html" rel="alternate"></link><published>2019-12-04T00:00:00-05:00</published><updated>2019-12-04T00:00:00-05:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2019-12-04:/running-imagej-on-the-hpcc.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="Fiji logo" hspace="10" src="//imagej.net/_images/a/ae/Fiji-icon.png" width="200,"&gt;&lt;/p&gt;
&lt;p&gt;A group working over in Plant and Soil Sciences are experts on ImageJ but are relatively new to the HPCC.  Together we put together a workflow for getting ImageJ up and running on the HPCC.&lt;/p&gt;
&lt;h3&gt;Step 1: Log onto the HPCC with an X11 connection&lt;/h3&gt;
&lt;p&gt;Log onto the HPC using …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="Fiji logo" hspace="10" src="//imagej.net/_images/a/ae/Fiji-icon.png" width="200,"&gt;&lt;/p&gt;
&lt;p&gt;A group working over in Plant and Soil Sciences are experts on ImageJ but are relatively new to the HPCC.  Together we put together a workflow for getting ImageJ up and running on the HPCC.&lt;/p&gt;
&lt;h3&gt;Step 1: Log onto the HPCC with an X11 connection&lt;/h3&gt;
&lt;p&gt;Log onto the HPC using an X11 connection.  You need x11 in order to test the install using the Graphical User Interface (GUI).  If you are on windows, I recommend &lt;a href="//mobaxterm.mobatek.net/"&gt;MobaXTerm&lt;/a&gt; as an easy way to get started, if you are on Mac you may need to install &lt;a href="https://www.xquartz.org/"&gt;XQuarts&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you don't have X11 working you can try logging in using the HPCC remote server and a "full linux desktop" by going to the following website:&lt;/p&gt;
&lt;p&gt;https://webrdp.hpcc.msu.edu&lt;/p&gt;
&lt;p&gt;You can test if graphics are working by typing the following on the command line:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;xeyes
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Step 2: Install ImageJ&lt;/h3&gt;
&lt;p&gt;For this step I recommend installing &lt;a href="https://fiji.sc/"&gt;Fiji&lt;/a&gt; (Fiji is just ImageJ) which a little easier to use than ImageJ proper.  For one thing it makes installing a few plug-ins much easier.&lt;/p&gt;
&lt;p&gt;Download the 64-bit installer into your home directory on the HPCC.  Go to the &lt;a href="//imagej.net/Fiji/Downloads"&gt;Fiji&lt;/a&gt; website to get a URL link to the latest version.  Once you have the URL you can run the following command on an HPC Development node:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;wget https://downloads.imagej.net/fiji/latest/fiji-linux64.zip
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;After the file has downloaded you just need to unzip the file using the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;unzip fiji-linux64.zip
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Test ImageJ using the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;~/Fiji.app/ImageJ-linux64
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The first time running it will ask if you want to run the "updater." I would recommend doing this.&lt;/p&gt;
&lt;h3&gt;Step 3: Install needed plugins&lt;/h3&gt;
&lt;p&gt;Once you have Fiji running you shold be able to install most plugins from the user interface.  You can also copy plugin jar files to the plugins folder inside the Fiji.app folder.&lt;/p&gt;
&lt;h3&gt;Step 4: Write a Macro&lt;/h3&gt;
&lt;p&gt;You can run for about 2 hours on any of the HPCC development nodes, however, to really take advantage of the HPCC you want to run in batch mode.  Batch mode does not let you use the mouse and click on the graphics which means you need to create an ImageJ macro that runs from start to end without any user input.  For now I will assume that you know how to make a macro, if not, you may have to look for some sort of online tutorial or read the &lt;a href="https://imagej.nih.gov/ij/docs/guide/146-14.html"&gt;manual&lt;/a&gt;,&lt;/p&gt;
&lt;p&gt;If you want to just do a quick test I recmmend making a macro with just a "hello world" print command as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hello&lt;/span&gt; &lt;span class="n"&gt;world&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Save the file as &lt;code&gt;myMacro.ijm&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;Step 5: Submit the macro to the scheduler&lt;/h3&gt;
&lt;p&gt;Let us assume that your macro name is &lt;code&gt;myMacro.ijm&lt;/code&gt; then the following submission script should work to get your macro running in SLURM:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;
&lt;span class="c1"&gt;#SBATCH --mem=4gb&lt;/span&gt;
&lt;span class="c1"&gt;#SBATCH --time=04:00:00&lt;/span&gt;
&lt;span class="c1"&gt;#SBATCH -n 1&lt;/span&gt;
&lt;span class="c1"&gt;#SBATCH -c 1&lt;/span&gt;

module load java
module load powertools

srun ~/Fiji.app/ImageJ-linux64 --headless --memory&lt;span class="o"&gt;=&lt;/span&gt;4000M -macro myMacro.ijm

js &lt;span class="nv"&gt;$SLURM_JOB_ID&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If we call the above script &lt;code&gt;runFiji.sb&lt;/code&gt; then you can submit the job to the SLURM scheduler using the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sbatch runFiji.sb
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That should be it. You can change the required memory or the amount of time it takes to run.  &lt;/p&gt;</content><category term="Professional"></category><category term="HPC"></category></entry><entry><title>CMSE Presentation at SC19</title><link href="https://colbrydi.github.io/cmse-presentation-at-sc19.html" rel="alternate"></link><published>2019-11-17T00:00:00-05:00</published><updated>2019-11-17T00:00:00-05:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2019-11-17:/cmse-presentation-at-sc19.html</id><summary type="html">&lt;p&gt;&lt;img alt="SC19 Logo" src="https://sc19.supercomputing.org/app/uploads/2018/11/ogimage_1200.png"&gt;&lt;/p&gt;
&lt;p&gt;I just got out of giving a presentation about the CMSE department as part of the &lt;a href="https://sc19.supercomputing.org/session/?sess=sess104"&gt;Sixth SC Workshop on Best Practices for HPC Training and Education (BPHTE19)&lt;/a&gt; workshop at &lt;a href="https://sc19.supercomputing.org/"&gt;SC19&lt;/a&gt;. It was fun to show people what we are doing in CMSE and share our progress.  &lt;a href="//colbrydi.github.io/images/SC19_bphpcte_Colbrydi.pdf"&gt;Here is a …&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="SC19 Logo" src="https://sc19.supercomputing.org/app/uploads/2018/11/ogimage_1200.png"&gt;&lt;/p&gt;
&lt;p&gt;I just got out of giving a presentation about the CMSE department as part of the &lt;a href="https://sc19.supercomputing.org/session/?sess=sess104"&gt;Sixth SC Workshop on Best Practices for HPC Training and Education (BPHTE19)&lt;/a&gt; workshop at &lt;a href="https://sc19.supercomputing.org/"&gt;SC19&lt;/a&gt;. It was fun to show people what we are doing in CMSE and share our progress.  &lt;a href="//colbrydi.github.io/images/SC19_bphpcte_Colbrydi.pdf"&gt;Here is a link for my slides&lt;/a&gt;.  &lt;/p&gt;
&lt;h2&gt;Computational Mathematics, Science and Engineering (CMSE): Establishing an Academic Department: Dedicated to Scientific Computation as a Discipline&lt;/h2&gt;
&lt;p&gt;By Dirk Colbry, Michael Murillo, Adam Alessio and Andrew Christlieb&lt;/p&gt;
&lt;h3&gt;Abstract&lt;/h3&gt;
&lt;p&gt;The Computational Mathematics, Science and Engineering (CMSE) department is one of the newest units at Michigan State University (MSU). Founded in 2015, CMSE recognizes computation as the “triple junction” of algorithm development and analysis, high performance computing, and applications to scientific and engineering modeling and data science (as illustrated in Figure 1). This approach is designed to engage with computation as a new integrated discipline, rather than a series of decentralized, isolated sub-specialties. In the four years since its inception, the department has grown and flourished; however, the pathway was sometimes arduous. This paper shares lessons learned during the department’s development and the initiatives it has taken on to support computational research and education across the university. By sharing these lessons, we hope to encourage and support the establishment of similar departments at other universities and grow this integrated approach to scientific computation as a discipline.&lt;/p&gt;</content><category term="Professional"></category><category term="Presentations"></category></entry><entry><title>Sherpas of Supercomputing</title><link href="https://colbrydi.github.io/sherpas-of-supercomputing.html" rel="alternate"></link><published>2019-09-15T00:00:00-04:00</published><updated>2019-09-15T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2019-09-15:/sherpas-of-supercomputing.html</id><summary type="html">&lt;p&gt;&lt;img alt="Cover picture of the September 2019 ASEE PRISM Magazine Featuring the Sherpas of Supercomputing article" src="http://www.asee-prism.org/wp-content/uploads/2019/10/Sherpas-of-Supercomputing.jpg"&gt;&lt;/p&gt;
&lt;p&gt;I had the honor of recently being featured in an ASEE PRISM Magazine article about research facilitation.  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;An essential, if not yet well-defined, field is emerging at the intersection of research and the high-performance machines that make sense of big data.
By Lucy Birmingham and Mark Matthews&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href="http://www.asee-prism.org/sherpas-of-supercomputing/"&gt;See the full …&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="Cover picture of the September 2019 ASEE PRISM Magazine Featuring the Sherpas of Supercomputing article" src="http://www.asee-prism.org/wp-content/uploads/2019/10/Sherpas-of-Supercomputing.jpg"&gt;&lt;/p&gt;
&lt;p&gt;I had the honor of recently being featured in an ASEE PRISM Magazine article about research facilitation.  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;An essential, if not yet well-defined, field is emerging at the intersection of research and the high-performance machines that make sense of big data.
By Lucy Birmingham and Mark Matthews&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href="http://www.asee-prism.org/sherpas-of-supercomputing/"&gt;See the full article here&lt;/a&gt;&lt;/p&gt;</content><category term="Professional"></category><category term="Presentations"></category></entry><entry><title>Developing curriculum to train Graduate students how to utilize Raspberry Pis to Automate Research Labs</title><link href="https://colbrydi.github.io/developing-curriculum-to-train-graduate-students-how-to-utilize-raspberry-pis-to-automate-research-labs.html" rel="alternate"></link><published>2019-07-24T00:00:00-04:00</published><updated>2019-07-24T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2019-07-24:/developing-curriculum-to-train-graduate-students-how-to-utilize-raspberry-pis-to-automate-research-labs.html</id><summary type="html">&lt;p&gt;&lt;img alt="Picture of Shelby in front of her poster" src="//colbrydi.github.io/images/2019_ENSURE_Shelby.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Summer 2019 CMSE &lt;a href="https://cmse.msu.edu/employment-opportunities/cmse-student-technical-support/"&gt;CMSE Undergraduate Intern&lt;/a&gt; Poster presentation at MidSure by Shelby Santos&lt;/p&gt;
&lt;p&gt;Raspberry Pis (RPis) are affordable microcomputers (approx. $35) that have the capability to revolutionize the accuracy and efficiency of data collection in basic laboratory environments. Recreationally, RPis can be used as a base for smart televisions, home …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="Picture of Shelby in front of her poster" src="//colbrydi.github.io/images/2019_ENSURE_Shelby.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Summer 2019 CMSE &lt;a href="https://cmse.msu.edu/employment-opportunities/cmse-student-technical-support/"&gt;CMSE Undergraduate Intern&lt;/a&gt; Poster presentation at MidSure by Shelby Santos&lt;/p&gt;
&lt;p&gt;Raspberry Pis (RPis) are affordable microcomputers (approx. $35) that have the capability to revolutionize the accuracy and efficiency of data collection in basic laboratory environments. Recreationally, RPis can be used as a base for smart televisions, home automation or video games. However, by utilizing basic robotics and circuits in the workplace, microcomputers such as RPis can be programmed to automate data collection (such as temperature measurements or time laps photography) and output sophisticated plots, create response mechanisms, and other mechanical or electronic tools to automate a research and save significant amounts of researcher time while producing more precise measurements. In this project we are exploring the capabilities of RPis for graduate laboratories and developing curriculum to teach graduate students how to take advantage of this highly flexible and affordable technology.  &lt;/p&gt;</content><category term="Professional"></category><category term="Presentations"></category></entry><entry><title>Investigation of the process of converting a C++ code into an implementable FPGA file</title><link href="https://colbrydi.github.io/investigation-of-the-process-of-converting-a-c-code-into-an-implementable-fpga-file.html" rel="alternate"></link><published>2019-07-24T00:00:00-04:00</published><updated>2019-07-24T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2019-07-24:/investigation-of-the-process-of-converting-a-c-code-into-an-implementable-fpga-file.html</id><summary type="html">&lt;p&gt;&lt;img alt="Picture of Ana in front of her poster" src="//colbrydi.github.io/images/2019_ENSURE_Ana.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Summer 2019 &lt;a href="https://www.egr.msu.edu/graduate/ensure"&gt;ENSURE Student&lt;/a&gt; Poster presentation at MidSure by Ana Flavia Borges de Almeida Barreto&lt;/p&gt;
&lt;p&gt;A Field Programmable Gate Arrays (FPGAs) is an integrated circuit that can be “rewired” to become other circuits.  This ability makes FPGAs highly configurable and can significantly help speed up large scale computation used in …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="Picture of Ana in front of her poster" src="//colbrydi.github.io/images/2019_ENSURE_Ana.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Summer 2019 &lt;a href="https://www.egr.msu.edu/graduate/ensure"&gt;ENSURE Student&lt;/a&gt; Poster presentation at MidSure by Ana Flavia Borges de Almeida Barreto&lt;/p&gt;
&lt;p&gt;A Field Programmable Gate Arrays (FPGAs) is an integrated circuit that can be “rewired” to become other circuits.  This ability makes FPGAs highly configurable and can significantly help speed up large scale computation used in scientific research.  While useful, FPGAs are often underutilized because of the complexity of developing circuits using Hardware Descriptive Languages (HDLs).  Software compilers exist (ex. OpenCL and Merlin) to make circuit design easier but these compilers require many hours to translate C++ into a variable circuit implementable file and can fail to even find a solution. Compiling a C++ code into an implementable file has three main steps. First, converting the C++ code into an HDL code, running the implementation of that code, and finally mapping the implementation for the specific FPGA. The first two steps are relatively quick to complete. However, the mapping part is what makes the whole process slow. It is difficult for the computer to take an arbitrary HDL circuit diagram and map it to the FPGA framework.  The calculations is an optimization problem that requires searching though many different circuit pathways to find one that will work.  The premise of this project is to explore methods to more efficiently converting C++ into FPGA applicable file. As this is a big problem to tackle, the first objective is to understand how the mapping is currently done (using Intel FPGA SDK), make a practical guide of installing and using the open source compiler and explore alternatives to the existing FPGA programming workflows.  &lt;/p&gt;</content><category term="Professional"></category><category term="Presentations"></category></entry><entry><title>Searching the Algorithm Space to Automate Scientific Image Analysis Workflows</title><link href="https://colbrydi.github.io/searching-the-algorithm-space-to-automate-scientific-image-analysis-workflows.html" rel="alternate"></link><published>2019-07-24T00:00:00-04:00</published><updated>2019-07-24T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2019-07-24:/searching-the-algorithm-space-to-automate-scientific-image-analysis-workflows.html</id><summary type="html">&lt;p&gt;&lt;img alt="Picture of Noah in front of her poster" src="//colbrydi.github.io/images/2019_ENSURE_Noah.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Summer 2019 &lt;a href="https://grad.msu.edu/srop"&gt;SROP student&lt;/a&gt; poster presentation at MidSure by Noah Stolz&lt;/p&gt;
&lt;p&gt;Scientific data is often gathered in the form of Images.  Scientific Image analysis is the process of pulling specific measurements out of images.  Which measures are important complete depend on the scientific question being asked.  For this reason, there …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="Picture of Noah in front of her poster" src="//colbrydi.github.io/images/2019_ENSURE_Noah.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Summer 2019 &lt;a href="https://grad.msu.edu/srop"&gt;SROP student&lt;/a&gt; poster presentation at MidSure by Noah Stolz&lt;/p&gt;
&lt;p&gt;Scientific data is often gathered in the form of Images.  Scientific Image analysis is the process of pulling specific measurements out of images.  Which measures are important complete depend on the scientific question being asked.  For this reason, there is no single image analysis software that scientists can use to analyze their data.  Currently new software needs to be written for every problem.  This research aims to automate the software development by focusing on common image analysis workflows.  We are developing methods to formulate these workflows and search the “algorithm space” to find the specific workflow for a specific scientific problem.&lt;br&gt;
As an example and proof of concept, this research will look at the common workflow of Image Segmentation. Image segmentation is a process used in many fields of research, from analyzing cells in petri dishes to identifying different crops in fields. However, image segmentation is a time- consuming process. Although an individual picture may take a short amount of time for a researcher to manually segment, this task can become an overwhelming burden for large data sets. While there are many image segmentation algorithms for specific data sets, no single algorithm will generalize well across other data sets. In this project, we aim to create a tool that helps research segment any image based data set and try to find an algorithm that will automate the process for the particular data analysis task.  The success of this tool is in reducing the amount of research time it takes to segment an image data set. In this prototype, we will use python’s skimage.segmentation library which provides a comprehensive set of image segmentation algorithms. Each algorithm in the skimage.segmentation has multiple parameters which leads to a large search space of different parameters and algorithms. We call this search space the “Algorithm Space”.  We will apply genetic algorithms which are known to effectively evaluate large, non-differentiable search spaces to the image segemntaiton “Algorithm Space”. This tool will be tested against prelabeled datasets and measure  amount of time the tool saves for the researcher to segment the images.&lt;/p&gt;</content><category term="Professional"></category><category term="Presentations"></category></entry><entry><title>The Keyboard Trap: Making Jupyter Notebooks Accessible to All Students</title><link href="https://colbrydi.github.io/the-keyboard-trap-making-jupyter-notebooks-accessible-to-all-students.html" rel="alternate"></link><published>2019-07-24T00:00:00-04:00</published><updated>2019-07-24T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2019-07-24:/the-keyboard-trap-making-jupyter-notebooks-accessible-to-all-students.html</id><summary type="html">&lt;p&gt;&lt;img alt="Picture of Abudit in front of her poster" src="//colbrydi.github.io/images/2019_EnSURE_Abudit.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Summer 2019 &lt;a href="https://cmse.msu.edu/employment-opportunities/cmse-student-technical-support/"&gt;CMSE Undergraduate Intern&lt;/a&gt; Poster presentation at MidSure by Abudit Rai:&lt;/p&gt;
&lt;p&gt;Jupyter Notebook is a relatively new environment that incorporates formatted text (using markdown), multimedia (video and pictures using html) and executable code where users can write and execute code within “cells” for languages such as Python, Julia, and …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="Picture of Abudit in front of her poster" src="//colbrydi.github.io/images/2019_EnSURE_Abudit.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Summer 2019 &lt;a href="https://cmse.msu.edu/employment-opportunities/cmse-student-technical-support/"&gt;CMSE Undergraduate Intern&lt;/a&gt; Poster presentation at MidSure by Abudit Rai:&lt;/p&gt;
&lt;p&gt;Jupyter Notebook is a relatively new environment that incorporates formatted text (using markdown), multimedia (video and pictures using html) and executable code where users can write and execute code within “cells” for languages such as Python, Julia, and R  making it a particularly effective means of teaching students concepts that involve programming. Because notebooks help in communication, many instructors prefer to implement class content using  Jupyter Notebooks. However, there are currently several accessibility issues with the current Jupyter Notebook software that prevents every user from having an equal opportunity to use this platform.  This research investigates  one of the largest problems; the issue of keyboard traps where keyboard navigation of a website becomes stuck after a certain point, effectively trapping a user who does not have the ability to use the mouse. By reviewing the Javascript code for Jupyter Notebooks, this project will look at key bindings and commands to see how the interface is set up, find the areas that cause this trap to occur, come up with ways to fix the potential solutions and provide the best fix to the OpenSource Jupyter Software Community Project.&lt;/p&gt;</content><category term="Professional"></category><category term="Presentations"></category></entry><entry><title>2019 Ensure Talk - An Engineers Autobiography</title><link href="https://colbrydi.github.io/2019-ensure-talk-an-engineers-autobiography.html" rel="alternate"></link><published>2019-06-25T00:00:00-04:00</published><updated>2019-06-25T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2019-06-25:/2019-ensure-talk-an-engineers-autobiography.html</id><summary type="html">&lt;p&gt;&lt;img alt="EnSURE Logo" src="//www.egr.msu.edu/graduate/sites/default/files/content/ensure_logo.jpg"&gt;&lt;/p&gt;
&lt;p&gt;I gave my annual autobiographical talk today to the &lt;a href="//www.egr.msu.edu/graduate/ensure"&gt;EnSURE&lt;/a&gt; (Engineering Summer Undergraduate Research Experience) students. I give this talk every year and it is noticeably different that most of my presentations because the EnSURE organizers asked me to talk about myself and how I got where I am (instead …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="EnSURE Logo" src="//www.egr.msu.edu/graduate/sites/default/files/content/ensure_logo.jpg"&gt;&lt;/p&gt;
&lt;p&gt;I gave my annual autobiographical talk today to the &lt;a href="//www.egr.msu.edu/graduate/ensure"&gt;EnSURE&lt;/a&gt; (Engineering Summer Undergraduate Research Experience) students. I give this talk every year and it is noticeably different that most of my presentations because the EnSURE organizers asked me to talk about myself and how I got where I am (instead of research or teaching).  The first time I gave this talk it was really awkward.  However, now I think it is kind of fun to tell stories about the choices I made throughout school and my carrier.  I get a lot of questions when I am done so I like to think the student's enjoyed the talk as well.  This year was a basic carbon copy of last years talk with a little design update to the slides.  Here are a copy of my slides:&lt;/p&gt;
&lt;p&gt;&lt;a href="./Images/20190625_An_Engineers_Autobiography.pdf"&gt;20190625_An_Engineers_Autobiography.pdf&lt;/a&gt;&lt;/p&gt;</content><category term="Professional"></category><category term="Presentations"></category></entry><entry><title>Research Team Retreat</title><link href="https://colbrydi.github.io/research-team-retreat.html" rel="alternate"></link><published>2019-06-18T00:00:00-04:00</published><updated>2019-06-18T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2019-06-18:/research-team-retreat.html</id><summary type="html">&lt;p&gt;&lt;img alt="Research group in front of college van" src="//colbrydi.github.io/images/Group_Van.jpg"&gt;&lt;/p&gt;
&lt;p&gt;This summer we managed to find a time to take my research team on a retreat (Road Trip!) to the lake (Noah, Abudit, Shelby, Lilly and Anna).  It was a great opportunity to get to know each other and really bond as a team.  We played games, had a boat …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="Research group in front of college van" src="//colbrydi.github.io/images/Group_Van.jpg"&gt;&lt;/p&gt;
&lt;p&gt;This summer we managed to find a time to take my research team on a retreat (Road Trip!) to the lake (Noah, Abudit, Shelby, Lilly and Anna).  It was a great opportunity to get to know each other and really bond as a team.  We played games, had a boat ride, went swimming and even got some work done.  &lt;/p&gt;
&lt;p&gt;Overall it was a great trip. I hope to be able to maintain this new tradition with future summer students.&lt;/p&gt;
&lt;p&gt;&lt;img align="right," alt="Playing a little cards while Dirk is on a Phone call" hspace="10" src="//colbrydi.github.io/images/Cards.jpg" width="33%,"&gt; &lt;img align="right," alt="Dirk on a Phone call" hspace="10" src="//colbrydi.github.io/images/Work.jpg" width="33%,"&gt;  &lt;img align="right," alt="Team taking a Boat Ride" hspace="10" src="//colbrydi.github.io/images/Boat.jpg" width="33%,"&gt; &lt;img align="right," alt="Big kids can play tether ball too" hspace="10" src="//colbrydi.github.io/images/TetherBall.jpg" width="33%,"&gt;&lt;img align="right," alt="Another Group Photol" hspace="10" src="//colbrydi.github.io/images/Lake.jpg" width="66%,"&gt;&lt;/p&gt;</content><category term="Professional"></category><category term="Research"></category></entry><entry><title>Workshop Community Building for High-Performance Computing Curriculum development</title><link href="https://colbrydi.github.io/workshop-community-building-for-high-performance-computing-curriculum-development.html" rel="alternate"></link><published>2019-06-10T00:00:00-04:00</published><updated>2019-06-10T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2019-06-10:/workshop-community-building-for-high-performance-computing-curriculum-development.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="National Computational Science Institute Logo" hspace="10" src="http://shodor.org/logos/logos/NCSI/thumb.jpg" width="200,"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img align="right," alt="XSEDE Logo" hspace="10" src="https://www.xsede.org/image/image_gallery?uuid=c0ae4cfa-fa0e-4546-8b02-3305bf2a99cc&amp;amp;groupId=10157&amp;amp;t=1369258426990" width="200,"&gt;&lt;/p&gt;
&lt;p&gt;Last year, I attended a two-and-a-half-day community and curriculum building workshop.  It could not have been more perfectly timed. I was able to come up with a solid plan for my CMSE401 parallel programming course which I ended up teaching this last spring.  &lt;/p&gt;
&lt;p&gt;This year I was not able to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="National Computational Science Institute Logo" hspace="10" src="http://shodor.org/logos/logos/NCSI/thumb.jpg" width="200,"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img align="right," alt="XSEDE Logo" hspace="10" src="https://www.xsede.org/image/image_gallery?uuid=c0ae4cfa-fa0e-4546-8b02-3305bf2a99cc&amp;amp;groupId=10157&amp;amp;t=1369258426990" width="200,"&gt;&lt;/p&gt;
&lt;p&gt;Last year, I attended a two-and-a-half-day community and curriculum building workshop.  It could not have been more perfectly timed. I was able to come up with a solid plan for my CMSE401 parallel programming course which I ended up teaching this last spring.  &lt;/p&gt;
&lt;p&gt;This year I was not able to attend the workshop in Tulsa OK (darn jury duty!):&lt;/p&gt;
&lt;p&gt;&lt;a href="https://portal.xsede.org/course-calendar/-/training-user/class/1311/session/2613"&gt;link to CBHPCCD19&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;However, I did arrange with the organizer (Aaron Weeden) and was able to give a video conference presentation about my class.  Hopefully this year's participants found my talk useful.  Here is a link to my slides in case anyone is intertested:&lt;/p&gt;
&lt;p&gt;&lt;a href="//colbrydi.github.io/images/20190612-MSU_HPC_CMSE401.pdf"&gt;Link to Slides&lt;/a&gt;&lt;/p&gt;</content><category term="Professional"></category><category term="Presentations"></category></entry><entry><title>Do More, Faster: Utilizing Advanced Computational Resources in Your Research Team</title><link href="https://colbrydi.github.io/do-more-faster-utilizing-advanced-computational-resources-in-your-research-team.html" rel="alternate"></link><published>2019-05-21T00:00:00-04:00</published><updated>2019-05-21T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2019-05-21:/do-more-faster-utilizing-advanced-computational-resources-in-your-research-team.html</id><summary type="html">&lt;p&gt;&lt;img alt="INSciTS Logo" src="https://www.inscits.org/assets/site/inscits-logo.png"&gt;&lt;/p&gt;
&lt;p&gt;Here are my slides from the &lt;a href="https://www.inscits.org/"&gt;SciTS conference&lt;/a&gt; last month.  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The SciTS conference is the annual international forum dedicated to SciTS, bringing together thought leaders from a broad range of disciplines and fields, including: communications, management, social and behavioral sciences, information technology, systems science, and translational research. It provides investigators …&lt;/p&gt;&lt;/blockquote&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="INSciTS Logo" src="https://www.inscits.org/assets/site/inscits-logo.png"&gt;&lt;/p&gt;
&lt;p&gt;Here are my slides from the &lt;a href="https://www.inscits.org/"&gt;SciTS conference&lt;/a&gt; last month.  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The SciTS conference is the annual international forum dedicated to SciTS, bringing together thought leaders from a broad range of disciplines and fields, including: communications, management, social and behavioral sciences, information technology, systems science, and translational research. It provides investigators, academic administrators, and funders wit  h state-of-the-art knowledge, strategies, and connections. SciTS scholars, scientists engaged in team-based research, institutional leaders who promote collaborative research, policymakers, and federal agency representatives will be in attendance.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;
The use of technology in research is becoming ubiquitous as low cost programmable sensors and advanced computing (e.g., AI and big data) emerge in nearly every domain. Out of necessity, many scientists and domain experts have become Technology Users: individuals who need to employ advanced technology in their research, but who do not have broad expertise in topics such as engineering and programming.  Modern laptop and desktop computers are extremely powerful, and most scientists can accomplish 90-95% of what they need with a computer in their office.  However, much of today’s cutting edge science needs bigger, stronger and faster computers.  High Performance Computing (HPC) systems (aka supercomputers) are designed to take science to the next level.  Universities and national funding agencies (NSF, NIH, DOD, DOE, etc.) provide researchers access to  large scale computing resources, often free of charge.  The most common barrier to scientists who want to utilize these resources is knowledge: that these tools exist, and how to get started using them.&lt;/p&gt;
&lt;p&gt;This talk introduced the world of large scale computing. We discussed how to gain access to both local and national resources, the common types of problems that can be solved using these resources, and training programs specifically designed to help new researchers leverage these technologies and use them effectively in their own research.&lt;/p&gt;
&lt;p&gt;&lt;a href="//colbrydi.github.io/images/20190521-SciTS.pdf"&gt;Link to the slides&lt;/a&gt;&lt;/p&gt;</content><category term="Professional"></category><category term="Presentations"></category></entry><entry><title>Automating Scientific Image Analysis Workflows</title><link href="https://colbrydi.github.io/automating-scientific-image-analysis-workflows.html" rel="alternate"></link><published>2019-04-23T00:00:00-04:00</published><updated>2019-04-23T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2019-04-23:/automating-scientific-image-analysis-workflows.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="GA Title Slide" hspace="10" src="//colbrydi.github.io/images/20190423_GA_Talk.png" width="200,"&gt;&lt;/p&gt;
&lt;p&gt;I was asked to give a talk to Michael Murillo machine learning seminar group.  Michael put the group together as a first step to gather topics/ideas for a graduate level machine learning class that CMSE will be teaching in the fall.&lt;/p&gt;
&lt;p&gt;In this talk I introduced a difficult machine …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="GA Title Slide" hspace="10" src="//colbrydi.github.io/images/20190423_GA_Talk.png" width="200,"&gt;&lt;/p&gt;
&lt;p&gt;I was asked to give a talk to Michael Murillo machine learning seminar group.  Michael put the group together as a first step to gather topics/ideas for a graduate level machine learning class that CMSE will be teaching in the fall.&lt;/p&gt;
&lt;p&gt;In this talk I introduced a difficult machine learning problem in the area of Exploratory Image Analysis.  I explained why this problem is unique and not easily solved using machine learning. Then I introduced my ideas on how we plan to try and solve the problem this summer using machine learning and, more specifically, Genetic Algorithms.  &lt;/p&gt;
&lt;p&gt;&lt;a href="//colbrydi.github.io/images/20190423_GA_Image_Segmentation.pdf"&gt;Link to the slides&lt;/a&gt;&lt;/p&gt;</content><category term="Professional"></category><category term="Presentations"></category></entry><entry><title>Extracting Desire to learn (D2L) zip files into student folders</title><link href="https://colbrydi.github.io/extracting-desire-to-learn-d2l-zip-files-into-student-folders.html" rel="alternate"></link><published>2019-04-15T00:00:00-04:00</published><updated>2019-04-15T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2019-04-15:/extracting-desire-to-learn-d2l-zip-files-into-student-folders.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="D2L Logo" hspace="10" src="https://info.d2l.com/hs-fs/hubfs/D2L-web-500.png?width=500&amp;amp;name=D2L-web-500.png" width="200,"&gt;&lt;/p&gt;
&lt;p&gt;At MSU we use Desire to Learn for our classroom content management system.  Students can go to D2L to get their assignments and turn in their assignments though the D2L dropbox.  &lt;/p&gt;
&lt;p&gt;When grading, I can download all of the student's submissions into a zip file such as the following:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Part …&lt;/code&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="D2L Logo" hspace="10" src="https://info.d2l.com/hs-fs/hubfs/D2L-web-500.png?width=500&amp;amp;name=D2L-web-500.png" width="200,"&gt;&lt;/p&gt;
&lt;p&gt;At MSU we use Desire to Learn for our classroom content management system.  Students can go to D2L to get their assignments and turn in their assignments though the D2L dropbox.  &lt;/p&gt;
&lt;p&gt;When grading, I can download all of the student's submissions into a zip file such as the following:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Part 1 - Software Evaluation Download Mar 23, 2019 609 AM.zip&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;HW1 - Matrix Transpose Download Feb 2, 2019 1001 AM.zip&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If this folder is unzipped files similar to the following will appear:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="mi"&gt;323771&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;372818&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Sam&lt;/span&gt; &lt;span class="n"&gt;Smith&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Jan&lt;/span&gt; &lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2019&lt;/span&gt; &lt;span class="mi"&gt;652&lt;/span&gt; &lt;span class="n"&gt;PM&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;submission&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tgz&lt;/span&gt;
&lt;span class="mi"&gt;325034&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;372818&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Nan&lt;/span&gt; &lt;span class="n"&gt;Carpenter&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Jan&lt;/span&gt; &lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2019&lt;/span&gt; &lt;span class="mi"&gt;330&lt;/span&gt; &lt;span class="n"&gt;PM&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="n"&gt;wave&lt;/span&gt; &lt;span class="n"&gt;eqn&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pages&lt;/span&gt;
&lt;span class="mi"&gt;325034&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;372818&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Nan&lt;/span&gt; &lt;span class="n"&gt;Carpenter&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Jan&lt;/span&gt; &lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2019&lt;/span&gt; &lt;span class="mi"&gt;330&lt;/span&gt; &lt;span class="n"&gt;PM&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;wave1d&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
&lt;span class="mi"&gt;331582&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;372818&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Joe&lt;/span&gt; &lt;span class="n"&gt;Taylor&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Jan&lt;/span&gt; &lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2019&lt;/span&gt; &lt;span class="mi"&gt;315&lt;/span&gt; &lt;span class="n"&gt;PM&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;HW1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ipynb&lt;/span&gt;
&lt;span class="mi"&gt;331582&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;372818&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Joe&lt;/span&gt; &lt;span class="n"&gt;Taylor&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Jan&lt;/span&gt; &lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2019&lt;/span&gt; &lt;span class="mi"&gt;315&lt;/span&gt; &lt;span class="n"&gt;PM&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;HW1_report&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdf&lt;/span&gt;
&lt;span class="mi"&gt;331582&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;372818&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Joe&lt;/span&gt; &lt;span class="n"&gt;Taylor&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Jan&lt;/span&gt; &lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2019&lt;/span&gt; &lt;span class="mi"&gt;315&lt;/span&gt; &lt;span class="n"&gt;PM&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;short&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mp4&lt;/span&gt;
&lt;span class="mi"&gt;331582&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;372818&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Joe&lt;/span&gt; &lt;span class="n"&gt;Taylor&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;Jan&lt;/span&gt; &lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2019&lt;/span&gt; &lt;span class="mi"&gt;320&lt;/span&gt; &lt;span class="n"&gt;PM&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;HW1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tgz&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;For many of the topics we cover (mostly programming) these filenames are not easy to use.  In my classes student often submit files that need to work together with given file names (everything after the final dash).  I wrote the following program to convert the directory of complex filenames into folders. A separate folder for each student with the files in the folder:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;
&lt;span class="nv"&gt;files&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;ls&lt;span class="sb"&gt;`&lt;/span&gt;
find . -iname &lt;span class="s2"&gt;&amp;quot;*&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="nb"&gt;read&lt;/span&gt; file
&lt;span class="k"&gt;do&lt;/span&gt;
        &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$file&lt;/span&gt;
        &lt;span class="nv"&gt;folder&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$file&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; cut -d &lt;span class="s2"&gt;&amp;quot;-&amp;quot;&lt;/span&gt; -f &lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; xargs&lt;span class="sb"&gt;`&lt;/span&gt;
        &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;creating folder &lt;/span&gt;&lt;span class="nv"&gt;$folder&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
        mkdir -p &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$folder&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
        &lt;span class="nv"&gt;newname&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$file&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; cut -d &lt;span class="s2"&gt;&amp;quot;-&amp;quot;&lt;/span&gt; -f5- &lt;span class="p"&gt;|&lt;/span&gt; xargs&lt;span class="sb"&gt;`&lt;/span&gt;
        &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Renaming to &lt;/span&gt;&lt;span class="nv"&gt;$newname&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
        mv &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$file&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;./&lt;/span&gt;&lt;span class="nv"&gt;$folder&lt;/span&gt;&lt;span class="s2"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;$newname&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;Sam&lt;/span&gt; &lt;span class="n"&gt;Smith&lt;/span&gt;
&lt;span class="n"&gt;Nan&lt;/span&gt; &lt;span class="n"&gt;Carpenter&lt;/span&gt;
&lt;span class="n"&gt;Joe&lt;/span&gt; &lt;span class="n"&gt;Taylor&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Each directory contains that student's files. For example the &lt;code&gt;Joe Taylor&lt;/code&gt; folder will have:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;HW1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ipynb&lt;/span&gt;
&lt;span class="n"&gt;HW1_report&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdf&lt;/span&gt;
&lt;span class="n"&gt;short&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mp4&lt;/span&gt;
&lt;span class="n"&gt;HW1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tgz&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I hope you find this script useful.&lt;/p&gt;</content><category term="Professional"></category><category term="Teaching"></category></entry><entry><title>Accessibility of Jupyter for Impaired Individuals</title><link href="https://colbrydi.github.io/accessibility-of-jupyter-for-impaired-individuals.html" rel="alternate"></link><published>2019-04-05T00:00:00-04:00</published><updated>2019-04-05T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2019-04-05:/accessibility-of-jupyter-for-impaired-individuals.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="Asha in front of her poster" hspace="10" src="//colbrydi.github.io/images/AshaPoster.jpeg" width="200,"&gt;&lt;/p&gt;
&lt;p&gt;This poster presents work by CMSETech Intern, Ahsa Shekar and her work on finding ways to make Jupyter More accessible.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Jupyter is an open-source programming environment that uses "literate programming" by combining documentation, coding and visualization into one file format. The Jupyter notebook format is also particularly well-suited for …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="Asha in front of her poster" hspace="10" src="//colbrydi.github.io/images/AshaPoster.jpeg" width="200,"&gt;&lt;/p&gt;
&lt;p&gt;This poster presents work by CMSETech Intern, Ahsa Shekar and her work on finding ways to make Jupyter More accessible.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Jupyter is an open-source programming environment that uses "literate programming" by combining documentation, coding and visualization into one file format. The Jupyter notebook format is also particularly well-suited for learning environments, where the instructional content (text, links, videos, etc.) can be combined with executable code and student output (graphs, charts, solutions, feedback) in a single, easy-to-use, file format. Unfortunately, Jupyter software is not fully accessible.  This means individuals with impaired senses and abilities may not be able to interact with Jupyter effectively. MSU is leading an initiative working towards making Jupyter more accessible. In this project, I investigated the different accessibility issues with Jupyter and identified key problems that, if fixed, would provide an improved experience for the greatest number of our students. This project made progress in solving two key issues; 1) automatically identify and measuring color contrast across the entire graphical user interface and 2) identify structural edits to the source code that can be made to improve the overall readability for screen readers.&lt;/p&gt;
&lt;p&gt;&lt;a href="//colbrydi.github.io/images/UURAF_Jupyter_Accessibility.pdf"&gt;Link to the poster&lt;/a&gt;&lt;/p&gt;</content><category term="Professional"></category><category term="Presentations"></category></entry><entry><title>The challenges of developing research tools in active and responsive open source communities</title><link href="https://colbrydi.github.io/the-challenges-of-developing-research-tools-in-active-and-responsive-open-source-communities.html" rel="alternate"></link><published>2019-04-05T00:00:00-04:00</published><updated>2019-04-05T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2019-04-05:/the-challenges-of-developing-research-tools-in-active-and-responsive-open-source-communities.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="Poster with Ty and Hattie" hspace="10" src="//colbrydi.github.io/images/2019_PA_Poster.jpg" width="200,"&gt;&lt;/p&gt;
&lt;p&gt;This poster presents work by Professorial Assistance, Ty Buckly and Hattie Pimentel and their work on building an image annotation system inside of Jupyter.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Scientists often gather observations of the world using images and need efficient image annotating tools to extract data from these images. Project Insight seeks to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="Poster with Ty and Hattie" hspace="10" src="//colbrydi.github.io/images/2019_PA_Poster.jpg" width="200,"&gt;&lt;/p&gt;
&lt;p&gt;This poster presents work by Professorial Assistance, Ty Buckly and Hattie Pimentel and their work on building an image annotation system inside of Jupyter.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Scientists often gather observations of the world using images and need efficient image annotating tools to extract data from these images. Project Insight seeks to make this process easier and quicker. The project consists of two parts: first, an image annotation package, the Graphical User Interface (GUI); and second, behind-the-scenes machine learning. When Project Insight is completed, data from the GUI will be sent to the machine learning component, which will attempt to anticipate the user’s next choices. The machine-learning component will search through algorithm space for the most suitable algorithm.&lt;/p&gt;
&lt;p&gt;Jupyter Notebooks are an interface used by researchers to combines code, pictures, notes and other multimedia. Using Jupyter Notebooks, several image annotation tools were created. Currently, the image annotation tools are being moved to a future replacement of Jupyter Notebooks: JupyterLab. Citing security concerns, the JupyterLab team blocked key JavaScript execution in the beta version of JupyterLab. This means that many programs that worked in the original Jupyter Notebooks, including most of the Project Insight programs, are not functional in JupyterLab.&lt;/p&gt;
&lt;p&gt;This presentation will cover multiple attempts to retaining functionality in JupyterLab and discuss why the JupyterLab’s security block hinders functionality and contrasts the accessible theme of JupyterLab.&lt;/p&gt;
&lt;p&gt;&lt;a href="//colbrydi.github.io/images/2019_Jupyter_PA_Poster.pdf"&gt;Link to the poster&lt;/a&gt;&lt;/p&gt;</content><category term="Professional"></category><category term="Presentations"></category></entry><entry><title>HPCC SLURM Buy-in Notes</title><link href="https://colbrydi.github.io/hpcc-slurm-buy-in-notes.html" rel="alternate"></link><published>2019-03-28T00:00:00-04:00</published><updated>2019-03-28T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2019-03-28:/hpcc-slurm-buy-in-notes.html</id><summary type="html">&lt;p&gt;&lt;a href="https://slurm.schedmd.com/"&gt;&lt;img align="right," alt="SLURM Logo" hspace="10" src="//upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Slurm_logo.svg/2000px-Slurm_logo.svg.png" width="200,"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This year, the HPCC moved over to SLURM.  Overall, I think the new scheduler is nice but it required me to relearn a bunch of things I have gotten to know by reflex.&lt;/p&gt;
&lt;p&gt;One nice new feature is that I can manage our own Buy-in account.  The CMSE department has …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://slurm.schedmd.com/"&gt;&lt;img align="right," alt="SLURM Logo" hspace="10" src="//upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Slurm_logo.svg/2000px-Slurm_logo.svg.png" width="200,"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This year, the HPCC moved over to SLURM.  Overall, I think the new scheduler is nice but it required me to relearn a bunch of things I have gotten to know by reflex.&lt;/p&gt;
&lt;p&gt;One nice new feature is that I can manage our own Buy-in account.  The CMSE department has multiple buy-in nodes. For example, the command to &lt;strong&gt;show&lt;/strong&gt; everyone on the CMSE account is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;sacctmgr&lt;/span&gt; &lt;span class="k"&gt;show&lt;/span&gt; &lt;span class="nv"&gt;association&lt;/span&gt; &lt;span class="nv"&gt;account&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;cmse&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If I want to &lt;strong&gt;add&lt;/strong&gt; someone to the CMSE buy-in account I just do the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sacctmgr&lt;/span&gt; &lt;span class="k"&gt;add&lt;/span&gt; &lt;span class="k"&gt;user&lt;/span&gt; &lt;span class="n"&gt;account&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cmse&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;colbrydi&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Then if I want to &lt;strong&gt;delete&lt;/strong&gt; someone from he CMSE buy-in account is just as easy:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sacctmgr&lt;/span&gt; &lt;span class="k"&gt;delete&lt;/span&gt; &lt;span class="k"&gt;user&lt;/span&gt; &lt;span class="n"&gt;account&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cmse&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;colbrydi&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The HPCC staff also provides the following useful powertools that users can access by running &lt;code&gt;module load powertools&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;priority_status&lt;/strong&gt; or &lt;strong&gt;buyin_status&lt;/strong&gt; - equivalent commands that shows all of your buy-in nodes and who is currently running on them.&lt;/p&gt;
&lt;p&gt;To use the buy-in account you need to specifically use the account option in the job script (I think).  For example, the following SBATCH commands should request one of the Volta GPU cards on the cmse account:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="n"&gt;SBATCH&lt;/span&gt; &lt;span class="c1"&gt;--gres=gpu:1  &lt;/span&gt;
&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="n"&gt;SBATCH&lt;/span&gt; &lt;span class="c1"&gt;--nodelist=nvl-001&lt;/span&gt;
&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="n"&gt;SBATCH&lt;/span&gt; &lt;span class="c1"&gt;--time=08:00:00&lt;/span&gt;
&lt;span class="o"&gt;#&lt;/span&gt;&lt;span class="n"&gt;SBATCH&lt;/span&gt; &lt;span class="c1"&gt;--account=cmse&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Many of our people want to use the Volta over Jupyterhub run though the &lt;a href="https://webrdp.hpcc.msu.edu"&gt;webrdp&lt;/a&gt; website.  To do this, you would log into &lt;a href="https://webrdp.hpcc.msu.edu"&gt;webrdp&lt;/a&gt;, open a terminal on the &lt;a href="https://webrdp.hpcc.msu.edu"&gt;webrdp&lt;/a&gt; desktop, ssh to one of the dev nodes and then issue the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;salloc&lt;/span&gt; &lt;span class="c1"&gt;--gres=gpu:1  --x11 --nodelist=nvl-001 --time=08:00:00 --mail-type=BEGIN --account=cmse&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Once the job starts, you would just type &lt;code&gt;jupyter notebook&lt;/code&gt; assuming you have it installed.&lt;/p&gt;
&lt;p&gt;Hope you find these notes useful.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dirk&lt;/li&gt;
&lt;/ul&gt;</content><category term="Professional"></category><category term="HPC"></category></entry><entry><title>Understanding Research Technology Support and Where it Fails</title><link href="https://colbrydi.github.io/understanding-research-technology-support-and-where-it-fails.html" rel="alternate"></link><published>2019-03-26T00:00:00-04:00</published><updated>2019-03-26T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2019-03-26:/understanding-research-technology-support-and-where-it-fails.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="Image of a Microscope" hspace="10" src="//colbrydi.github.io/images/Microscope.png" width="200,"&gt;&lt;/p&gt;
&lt;p&gt;I was invited to give a talk to a newly formed IT Research Support group here on MSU campus.  As the name suggests, the purpose of this group is to find the best ways to help researchers use technology to do their science.  &lt;/p&gt;
&lt;p&gt;This talk was a patchwork of many …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="Image of a Microscope" hspace="10" src="//colbrydi.github.io/images/Microscope.png" width="200,"&gt;&lt;/p&gt;
&lt;p&gt;I was invited to give a talk to a newly formed IT Research Support group here on MSU campus.  As the name suggests, the purpose of this group is to find the best ways to help researchers use technology to do their science.  &lt;/p&gt;
&lt;p&gt;This talk was a patchwork of many of my other talks.  I motivated the discussion by talking about the history of research computing  and  telling a few stories about how research IT is very different than Enterprise IT.  The core of the talk was a group discussion around the idea that the  most common source of failure in any project is in human communication.&lt;/p&gt;
&lt;p&gt;Then I discussed both campus and national efforts to solve the "human problem" by training a workforce of CI professionals dedicated to supporting research technology.  I ended my talk with a quick review of the many national efforts and a plug for our &lt;a href="https://colbrydi.github.io/cyberambassadors/"&gt;CyberAmbassador&lt;/a&gt; project.&lt;/p&gt;
&lt;p&gt;A link to my slides can be found here:&lt;/p&gt;
&lt;p&gt;&lt;a href="//colbrydi.github.io/images/20190326_IT_Research_support_Talk.pdf"&gt;Link to pdf of slides&lt;/a&gt;&lt;/p&gt;</content><category term="Professional"></category><category term="HPC"></category><category term="Presentations"></category></entry><entry><title>Managing Files on the MSU Engineering Jupyterhub server</title><link href="https://colbrydi.github.io/managing-files-on-the-msu-engineering-jupyterhub-server.html" rel="alternate"></link><published>2019-03-08T00:00:00-05:00</published><updated>2019-03-08T00:00:00-05:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2019-03-08:/managing-files-on-the-msu-engineering-jupyterhub-server.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="Disk Icon" hspace="10" src="//colbrydi.github.io/images/Floppy_Disk.png" width="200,"&gt;&lt;/p&gt;
&lt;p&gt;The MSU Engineering Jupyterhub server provides 2GB of disk storage space for each student.  It can be helpful to learn some disk management so you can use this space effectively.&lt;/p&gt;
&lt;p&gt;For example, pip install uses a temporary folder when downloading packages.  Periodically, deleting this folder can significantly free up space …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="Disk Icon" hspace="10" src="//colbrydi.github.io/images/Floppy_Disk.png" width="200,"&gt;&lt;/p&gt;
&lt;p&gt;The MSU Engineering Jupyterhub server provides 2GB of disk storage space for each student.  It can be helpful to learn some disk management so you can use this space effectively.&lt;/p&gt;
&lt;p&gt;For example, pip install uses a temporary folder when downloading packages.  Periodically, deleting this folder can significantly free up space.  &lt;/p&gt;
&lt;p&gt;&lt;code&gt;rm -rf ~/.cache&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Also, some functions in the scikit learn and seaboarn libraries download their own data folders. You may also want to have them delete those once they are no longer using those packages.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;rm&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;rf&lt;/span&gt;  &lt;span class="o"&gt;~/&lt;/span&gt;&lt;span class="n"&gt;scikit_learn_data&lt;/span&gt;
&lt;span class="n"&gt;rm&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;rf&lt;/span&gt; &lt;span class="o"&gt;~/&lt;/span&gt;&lt;span class="n"&gt;seaborn&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="k"&gt;data&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Another good command to learn is the “dh” command.  I like to run the following in my home directory to see which of my folders are taking up the most space:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;du -sh ~/*&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;To include hidden folders use:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;du -sch .[!.]* *&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;To also sort the results (may take a while):&lt;/p&gt;
&lt;p&gt;&lt;code&gt;du -sch .[!.]* * | sort -h&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dirk&lt;/li&gt;
&lt;/ul&gt;</content><category term="Professional"></category><category term="Jupyter"></category></entry><entry><title>Virtual Reality Talk at the MSU Library</title><link href="https://colbrydi.github.io/virtual-reality-talk-at-the-msu-library.html" rel="alternate"></link><published>2019-02-26T00:00:00-05:00</published><updated>2019-02-26T00:00:00-05:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2019-02-26:/virtual-reality-talk-at-the-msu-library.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="VR Image" hspace="10" src="//cmse.msu.edu/sites/_cmse/assets/Image/dsc00645.jpg" width="300,"&gt;&lt;/p&gt;
&lt;p&gt;A few weeks ago I was asked by Terence O'Neill to give a talk to the VR/AR seminar group being held at the library.  He wanted me to talk about our "Mobile beast" and show how we are using VR equipment in CMSE.  &lt;/p&gt;
&lt;p&gt;The VR equipment had a bug …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="VR Image" hspace="10" src="//cmse.msu.edu/sites/_cmse/assets/Image/dsc00645.jpg" width="300,"&gt;&lt;/p&gt;
&lt;p&gt;A few weeks ago I was asked by Terence O'Neill to give a talk to the VR/AR seminar group being held at the library.  He wanted me to talk about our "Mobile beast" and show how we are using VR equipment in CMSE.  &lt;/p&gt;
&lt;p&gt;The VR equipment had a bug and we could not get the demo working.  Oh well, I still think the talk went well and I was able to make a few new connections.  &lt;/p&gt;
&lt;p&gt;Below is a copy of my slides:&lt;/p&gt;
&lt;p&gt;&lt;a href="//colbrydi.github.io/images/20190226-VR_Library.pdf"&gt;CMSE VR Presentation Slides&lt;/a&gt;&lt;/p&gt;</content><category term="Professional"></category><category term="VR"></category><category term="Presentations"></category></entry><entry><title>Quick Makefile Overview</title><link href="https://colbrydi.github.io/quick-makefile-overview.html" rel="alternate"></link><published>2019-02-06T00:00:00-05:00</published><updated>2019-02-06T00:00:00-05:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2019-02-06:/quick-makefile-overview.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="Makefile as a Directed Acyclic Graph" hspace="10" src="//colbrydi.github.io/images/make.png" width="320,"&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="//colbrydi.github.io/images//Makefile"&gt;Example Makefile&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A former student recently emailed me asking for a good reference about makefiles.  To be honest, I teach a lot about makefiles but I am not sure I have a go-to source.  I could have googled something but instead I just tapped out this quick description. I thought …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="Makefile as a Directed Acyclic Graph" hspace="10" src="//colbrydi.github.io/images/make.png" width="320,"&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="//colbrydi.github.io/images//Makefile"&gt;Example Makefile&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A former student recently emailed me asking for a good reference about makefiles.  To be honest, I teach a lot about makefiles but I am not sure I have a go-to source.  I could have googled something but instead I just tapped out this quick description. I thought it makes for a fairly quick introduction to Makefiles.  Feel free to leave your favorite resource in the comments.&lt;/p&gt;
&lt;p&gt;Makefiles are fairly simple in concept but are an entire programming language so can get very advanced. Basically a makefile consists of rules in the following format:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;prerequisite_file1&lt;/span&gt; &lt;span class="n"&gt;prerequisite_file2&lt;/span&gt; &lt;span class="n"&gt;prequiste_file3&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;
  &lt;span class="n"&gt;Recipe&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
  &lt;span class="n"&gt;Recipe&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
  &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;When you type “make Target” on the command line you active the rule.  Then the Make program recursively activates rules to make each of the prerequisites.  If there is no rule to make a prerequisite it looks to see if the prerequisite file exists. If there is no rule and there is no file you will get an error.  However, assuming you have all the prerequisite files you need  for a rule, the Make program then runs the Recipe commands (things like gcc or whatever you want).  It is assumed that the commands will take the prerequisites as inputs and generate the target file (this is not always the case).
That is basically it.  Some more things to note:
*   If you just type “make” (with no target) the Make command assumes you are trying to make the first rule in the file.
*   Often the first rule target is called “all” with a bunch of prerequisites and no recipe steps.  This is just a high level rule that tells make to build all of your main target files. There is nothing special about the keyword “all” it is just used as a convention.
*   Often there is a rule at the end of a makefile called “clean” with no prerequisites.   You typically have to explicitly activate  this target by writing “make clean” (i.e. you normally do not make “clean” a prerequisite to a rule).  Typically the Recipe steps are remove (rm) commands that delete all intermediate files you may have generated (ex exe and *.o files). Basically giving you a clean slate.
*   Makefiles can have variables and wildcards. In these cases they can get fairly advanced.
*   Make is fairly smart,  it will rebuild a target if the targets modification date is older than the modification date of it’s prerequisites.  This means that if you repeat the make command it will not automatically regenerate a file it thinks will not change.&lt;/p&gt;
&lt;p&gt;That was fun for me.  I hope you find this description a useful first step.  &lt;/p&gt;
&lt;p&gt;Above is a toy example of a makefile and a visual representation.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dirk&lt;/li&gt;
&lt;/ul&gt;</content><category term="Professional"></category></entry><entry><title>Quick Graphviz Tutorial</title><link href="https://colbrydi.github.io/quick-graphviz-tutorial.html" rel="alternate"></link><published>2019-01-02T00:00:00-05:00</published><updated>2019-01-02T00:00:00-05:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2019-01-02:/quick-graphviz-tutorial.html</id><summary type="html">&lt;p&gt;&lt;img alt="vim system diagram" src="//colbrydi.github.io/images/vim.jpg"&gt;&lt;/p&gt;
&lt;p&gt;This quick tutorial shows provides basic instructions for generating the above graph using &lt;a href="https://www.graphviz.org/"&gt;Graphviz&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.graphviz.org/"&gt;&lt;img alt="Graphviz" src="https://graphviz.gitlab.io/_pages/Resources/app.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you already have Anaconda installed on your system, you can quickly install graphviz using the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;conda&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;graphviz&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Once graphviz is installed you need to create a text file with the connections.  This …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="vim system diagram" src="//colbrydi.github.io/images/vim.jpg"&gt;&lt;/p&gt;
&lt;p&gt;This quick tutorial shows provides basic instructions for generating the above graph using &lt;a href="https://www.graphviz.org/"&gt;Graphviz&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.graphviz.org/"&gt;&lt;img alt="Graphviz" src="https://graphviz.gitlab.io/_pages/Resources/app.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you already have Anaconda installed on your system, you can quickly install graphviz using the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;conda&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;graphviz&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Once graphviz is installed you need to create a text file with the connections.  This file is called a dot file.  There are a lot of tutorials about the dot syntax but the basics is to make a list of nodes and their connections. For example, the following file (called test.dot) makes the figure above.  Use the &lt;code&gt;-&amp;gt;&lt;/code&gt; to indicate a directed link and a &lt;code&gt;--&lt;/code&gt; to indicate a bi-directional link:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;digraph&lt;/span&gt; &lt;span class="k"&gt;G&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;
 &lt;span class="n"&gt;Linux&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;Normal&lt;/span&gt;  &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;vim&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;];&lt;/span&gt;
 &lt;span class="n"&gt;Normal&lt;/span&gt;  &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;Insert&lt;/span&gt;  &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;i/I/a/A/o/O&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;];&lt;/span&gt;
 &lt;span class="k"&gt;Insert&lt;/span&gt;  &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;Normal&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;Esc&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
 &lt;span class="n"&gt;Normal&lt;/span&gt;  &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;Command&lt;/span&gt;  &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;: (colon)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
 &lt;span class="n"&gt;Command&lt;/span&gt;  &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;Normal&lt;/span&gt;  &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;w&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;];&lt;/span&gt;
 &lt;span class="n"&gt;Command&lt;/span&gt;  &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;Linux&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;q/q!/wq/x&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="err"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Once you have the file you can make an image using the following &lt;code&gt;dot&lt;/code&gt; command (dot is one of the commands installed by Graphviz)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;dot&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Tpng&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dot&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ovim&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;png&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Just for fun, I tried my dot file with the other tools provided with Graphviz (twopim, sfdp, neato, osage, fdp, circo and patchwork).  They don't look as good as dot (most of them mess up the line labels) however i could see that they may be useful (and easy) for other figures:&lt;/p&gt;
&lt;p&gt;&lt;img alt="twopim" src="//colbrydi.github.io/images/twopi.jpg"&gt;
&lt;img alt="sfdp" src="//colbrydi.github.io/images/sfdp.jpg"&gt;
&lt;img alt="neato" src="//colbrydi.github.io/images/neato.jpg"&gt;
&lt;img alt="osage" src="//colbrydi.github.io/images/osage.jpg"&gt;
&lt;img alt="fdp" src="//colbrydi.github.io/images/fdp.jpg"&gt;
&lt;img alt="circo" src="//colbrydi.github.io/images/circo.jpg"&gt;
&lt;img alt="patchwork" src="//colbrydi.github.io/images/patchwork.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Hope you find this useful.&lt;/p&gt;</content><category term="Professional"></category></entry><entry><title>Accessing a computer's camera inside of jupyter without installing OpenCV (Also works in Jupyterhub)</title><link href="https://colbrydi.github.io/accessing-a-computers-camera-inside-of-jupyter-without-installing-opencv-also-works-in-jupyterhub.html" rel="alternate"></link><published>2018-12-21T00:00:00-05:00</published><updated>2018-12-21T00:00:00-05:00</updated><author><name>Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-12-21:/accessing-a-computers-camera-inside-of-jupyter-without-installing-opencv-also-works-in-jupyterhub.html</id><summary type="html">&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;img src="//colbrydi.github.io/images/Camera.png"&gt;&lt;/p&gt;
&lt;p&gt;The following code lets you take pictures inside of jupyter notebooks.  It uses Javascript inside of jupyterhub to access the client computers camera and transfer images back into python.&lt;/p&gt;
&lt;p&gt;I am particularly proud of this code because of the following features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Does not require the installation of OpenCV (This can be tricky)&lt;/li&gt;</summary><content type="html">&lt;style type="text/css"&gt;/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell &gt; div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area &gt; div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area &gt; div.highlight &gt; pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the &lt;head&gt; if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev &lt;Maniac@SoftwareManiacs.Org&gt;
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area 
div.output_area 
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph &gt; img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}



.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}






.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}








.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}





.rendered_html pre,




.rendered_html tr,
.rendered_html th,


.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}

.rendered_html * + p {
  margin-top: 1em;
}

.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,

.rendered_html img.unconfined,


.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] 
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell &gt; div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered 
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered 
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
&lt;/style&gt;
&lt;style type="text/css"&gt;.highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */&lt;/style&gt;&lt;body&gt;&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;img src="//colbrydi.github.io/images/Camera.png"&gt;&lt;/p&gt;
&lt;p&gt;The following code lets you take pictures inside of jupyter notebooks.  It uses Javascript inside of jupyterhub to access the client computers camera and transfer images back into python.&lt;/p&gt;
&lt;p&gt;I am particularly proud of this code because of the following features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Does not require the installation of OpenCV (This can be tricky)&lt;/li&gt;
&lt;li&gt;Will work with Jupyterhub.  This is a big one. If you run OpenCV on Jupyterhub it will look for the camera on the server and not the client computer. Since this code runs in javascript it uses the client's computer.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some negativies to this approach:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Does not work in Jupyterlab.  This is because the default of JupyterLab does not enable javascript as a security measure.&lt;/li&gt;
&lt;li&gt;Is not fast enough to transmit video.  This is because I use Unicode to transmit the image and it can't handle enough images in a reasonable amount of time.  There may be a way to record the video inside of javascript and then transmit the entire video but I have not figured that out.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="Step-1:-Access-the-camera-in-the-Javascript"&gt;Step 1: Access the camera in the Javascript&lt;a class="anchor-link" href="#Step-1:-Access-the-camera-in-the-Javascript"&gt;&amp;#182;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;This program works in two major steps. The first step is written in javascript.  In summary, the code creates a javascript canvas and attaches the local camera.  The code also creates a simple javascript button.  WHen the user presses the button a picture is taken and the context is saved as a Unicode URL.  The information is passed back to the python kernel using the &lt;code&gt;IPython.notebook.kernel.execute&lt;/code&gt; command.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[&amp;nbsp;]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Code developed by Dirk Colbry&lt;/span&gt;
&lt;span class="c1"&gt;# This code snipit tries to read from your computer&amp;#39;s camera.  It is not fully tested so it may not work for everyone.&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;IPython.display&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;HTML&lt;/span&gt;

&lt;span class="n"&gt;main_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="s2"&gt;&amp;lt;video id=&amp;quot;video&amp;quot; width=&amp;quot;320&amp;quot; height=&amp;quot;240&amp;quot; autoplay&amp;gt;&amp;lt;/video&amp;gt;&lt;/span&gt;
&lt;span class="s2"&gt;&amp;lt;button id=&amp;quot;snap&amp;quot;&amp;gt;Snap Photo&amp;lt;/button&amp;gt;&lt;/span&gt;
&lt;span class="s2"&gt;&amp;lt;canvas id=&amp;quot;canvas&amp;quot; width=&amp;quot;320&amp;quot; height=&amp;quot;240&amp;quot;&amp;gt;&amp;lt;/canvas&amp;gt;&lt;/span&gt;

&lt;span class="s2"&gt;&amp;lt;script&amp;gt;&lt;/span&gt;
&lt;span class="s2"&gt;// Grab elements, create settings, etc.&lt;/span&gt;
&lt;span class="s2"&gt;var video = document.getElementById(&amp;#39;video&amp;#39;);&lt;/span&gt;

&lt;span class="s2"&gt;// Get access to the camera!&lt;/span&gt;
&lt;span class="s2"&gt;if(navigator.mediaDevices &amp;amp;&amp;amp; navigator.mediaDevices.getUserMedia) {&lt;/span&gt;
&lt;span class="s2"&gt;    // Not adding `{ audio: true }` since we only want video now&lt;/span&gt;
&lt;span class="s2"&gt;    navigator.mediaDevices.getUserMedia({ video: true }).then(function(stream) {&lt;/span&gt;
&lt;span class="s2"&gt;        //video.src = window.URL.createObjectURL(stream);&lt;/span&gt;
&lt;span class="s2"&gt;        //video.play();&lt;/span&gt;
&lt;span class="s2"&gt;        video.srcObject=stream;&lt;/span&gt;
&lt;span class="s2"&gt;        video.play();&lt;/span&gt;
&lt;span class="s2"&gt;    });&lt;/span&gt;
&lt;span class="s2"&gt;}&lt;/span&gt;

&lt;span class="s2"&gt;// Elements for taking the snapshot&lt;/span&gt;
&lt;span class="s2"&gt;var canvas = document.getElementById(&amp;#39;canvas&amp;#39;);&lt;/span&gt;
&lt;span class="s2"&gt;var context = canvas.getContext(&amp;#39;2d&amp;#39;);&lt;/span&gt;
&lt;span class="s2"&gt;var video = document.getElementById(&amp;#39;video&amp;#39;);&lt;/span&gt;

&lt;span class="s2"&gt;// Trigger photo take&lt;/span&gt;
&lt;span class="s2"&gt;document.getElementById(&amp;quot;snap&amp;quot;).addEventListener(&amp;quot;click&amp;quot;, function() {&lt;/span&gt;
&lt;span class="s2"&gt;	context.drawImage(video, 0, 0, 320, 240);&lt;/span&gt;
&lt;span class="s2"&gt;    var myCanvas = document.getElementById(&amp;#39;canvas&amp;#39;);&lt;/span&gt;
&lt;span class="s2"&gt;    var image = myCanvas.toDataURL(&amp;quot;image/png&amp;quot;);&lt;/span&gt;
&lt;span class="s2"&gt;    IPython.notebook.kernel.execute(&amp;quot;print(&amp;#39;testing&amp;#39;)&amp;quot;)&lt;/span&gt;
&lt;span class="s2"&gt;    IPython.notebook.kernel.execute(&amp;quot;image = &amp;#39;&amp;quot; + image + &amp;quot;&amp;#39;&amp;quot;)&lt;/span&gt;
&lt;span class="s2"&gt;});&lt;/span&gt;
&lt;span class="s2"&gt;&amp;lt;/script&amp;gt;&lt;/span&gt;

&lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;HTML&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;main_text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Step-2:-Convert-string-back-into-image"&gt;Step 2: Convert string back into image&lt;a class="anchor-link" href="#Step-2:-Convert-string-back-into-image"&gt;&amp;#182;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;We can now access the URL string from inside of python.  The following function does all of the magic to decode the base 64 bit image into an IO stream which is then passed into the &lt;code&gt;PIL.Image.open&lt;/code&gt; function.  The end result is a image in the Python Image Library (PIL) format.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[&amp;nbsp;]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;PIL&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Image&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;base64&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;io&lt;/span&gt;

&lt;span class="n"&gt;pil_im&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Image&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;io&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;BytesIO&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;base64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;b64decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])))&lt;/span&gt;
&lt;span class="n"&gt;pil_im&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Step-3:-(Optional)-Convert-PIL-image-to-Numpy-array"&gt;Step 3: (Optional) Convert PIL image to Numpy array&lt;a class="anchor-link" href="#Step-3:-(Optional)-Convert-PIL-image-to-Numpy-array"&gt;&amp;#182;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Typically I like to work with images as a 3D numpy array (row, columns, channel).  The following code just converts the PIL image into a numpy array.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[&amp;nbsp;]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="k"&gt;matplotlib&lt;/span&gt; inline
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pylab&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="n"&gt;im3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pil_im&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;im3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;im3&lt;/span&gt;&lt;span class="p"&gt;[:,:,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;imshow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;im3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;I hope you found this example useful. Please leave a comment if you use it in your project.  I would really like to see how it is used.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dirk&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[&amp;nbsp;]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
 

&lt;/body&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['$','$'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        " linebreaks: { automatic: true, width: '95% container' }, " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;
</content><category term="Professional"></category><category term="Jupyter"></category></entry><entry><title>Using an X11 Virtual Frame Buffer to run GUI jobs in batch mode on the HPC.</title><link href="https://colbrydi.github.io/using-an-x11-virtual-frame-buffer-to-run-gui-jobs-in-batch-mode-on-the-hpc.html" rel="alternate"></link><published>2018-12-20T00:00:00-05:00</published><updated>2018-12-20T00:00:00-05:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-12-20:/using-an-x11-virtual-frame-buffer-to-run-gui-jobs-in-batch-mode-on-the-hpc.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="X11 Logo" hspace="10" src="//upload.wikimedia.org/wikipedia/commons/a/ab/X11.png" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;I have an example program that came with &lt;a href="http://bccd.net/"&gt;BCCD&lt;/a&gt; called Pandemic which I wanted to run on our local HPCC. Unfortunately Pandemic requires X11 to run and I would get a segmentation fault every time I ran it in the batch system.&lt;/p&gt;
&lt;p&gt;This blog post shows how I used the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="X11 Logo" hspace="10" src="//upload.wikimedia.org/wikipedia/commons/a/ab/X11.png" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;I have an example program that came with &lt;a href="http://bccd.net/"&gt;BCCD&lt;/a&gt; called Pandemic which I wanted to run on our local HPCC. Unfortunately Pandemic requires X11 to run and I would get a segmentation fault every time I ran it in the batch system.&lt;/p&gt;
&lt;p&gt;This blog post shows how I used the X11 Virtual Frame Buffer (Xvfb) to enable X11 in batch mode.  This example uses SLURM running in CentOS7.  This trick can come in really handing when you are using MATLAB to because last I checked it needed X11 to run in order to generate and save figures. This will let you do that even in batch mode.&lt;/p&gt;
&lt;p&gt;First, here is the batch script for the OpenMP version (Should work for serial jobs as well).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;
&lt;span class="c1"&gt;#SBATCH --time=00:10:00&lt;/span&gt;
&lt;span class="c1"&gt;#SBATCH --ntasks=1&lt;/span&gt;
&lt;span class="c1"&gt;#SBATCH --cpus-per-task=16&lt;/span&gt;
&lt;span class="c1"&gt;#SBATCH --mem=10G&lt;/span&gt;
&lt;span class="c1"&gt;#SBATCH --job-name Pandemic-OpenMP&lt;/span&gt;

&lt;span class="nb"&gt;cd&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;SLURM_SUBMIT_DIR&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;# Have X11 find an open display number and communicate the number&lt;/span&gt;
&lt;span class="c1"&gt;# though a temporary file to set the environment variable.&lt;/span&gt;
&lt;span class="nv"&gt;display_file&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;.tmp_display.txt
Xvfb -displayfd &lt;span class="m"&gt;1&lt;/span&gt; -auth /dev/null  &lt;span class="m"&gt;1&lt;/span&gt;&amp;gt;&lt;span class="nv"&gt;$display_file&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;&amp;gt; /dev/null &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;
sleep &lt;span class="m"&gt;5&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;DISPLAY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;:&lt;span class="sb"&gt;`&lt;/span&gt;cat &lt;span class="nv"&gt;$display_file&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;DISPLAY set to &lt;/span&gt;&lt;span class="nv"&gt;$DISPLAY&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
rm &lt;span class="nv"&gt;$display_file&lt;/span&gt;

&lt;span class="c1"&gt;# Benchmark program with different numbers of processes&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;OMP_NUM_THREADS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;16&lt;/span&gt;
&lt;span class="nb"&gt;time&lt;/span&gt; ./Pandemic.c-openmp
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;OMP_NUM_THREADS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;8&lt;/span&gt;
&lt;span class="nb"&gt;time&lt;/span&gt; ./Pandemic.c-openmp
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;OMP_NUM_THREADS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;
&lt;span class="nb"&gt;time&lt;/span&gt; ./Pandemic.c-openmp
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;OMP_NUM_THREADS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;
&lt;span class="nb"&gt;time&lt;/span&gt; ./Pandemic.c-openmp
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;OMP_NUM_THREADS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="nb"&gt;time&lt;/span&gt; ./Pandemic.c-openmp
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="k"&gt;done&lt;/span&gt;

&lt;span class="c1"&gt;# Report job statistics&lt;/span&gt;
scontrol show job &lt;span class="nv"&gt;$SLURM_JOB_ID&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And here is the job I got working with MPI. Notice it is basically the same but I need to pass the DISPLAY variable though MPI for it to work.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;
&lt;span class="c1"&gt;#SBATCH --time=00:10:00&lt;/span&gt;
&lt;span class="c1"&gt;#SBATCH --ntasks=16&lt;/span&gt;
&lt;span class="c1"&gt;#SBATCH --cpus-per-task=1&lt;/span&gt;
&lt;span class="c1"&gt;#SBATCH --mem=10G&lt;/span&gt;
&lt;span class="c1"&gt;#SBATCH --job-name Pandemic-MPI&lt;/span&gt;

&lt;span class="nb"&gt;cd&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;SLURM_SUBMIT_DIR&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
module swap GNU Intel
module load OpenMPI

&lt;span class="c1"&gt;# Have X11 find an open display number and communicate the number&lt;/span&gt;
&lt;span class="c1"&gt;# though a temporary file to set the environment variable.&lt;/span&gt;
&lt;span class="nv"&gt;display_file&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;.tmp_display.txt
Xvfb -displayfd &lt;span class="m"&gt;1&lt;/span&gt; -auth /dev/null  &lt;span class="m"&gt;1&lt;/span&gt;&amp;gt;&lt;span class="nv"&gt;$display_file&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;&amp;gt; /dev/null &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;
sleep &lt;span class="m"&gt;5&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;DISPLAY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;:&lt;span class="sb"&gt;`&lt;/span&gt;cat &lt;span class="nv"&gt;$display_file&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;DISPLAY set to &lt;/span&gt;&lt;span class="nv"&gt;$DISPLAY&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
rm &lt;span class="nv"&gt;$display_file&lt;/span&gt;

&lt;span class="c1"&gt;# Benchmark program with different numbers of processes&lt;/span&gt;
&lt;span class="nb"&gt;time&lt;/span&gt; mpirun -n &lt;span class="m"&gt;16&lt;/span&gt; -x &lt;span class="nv"&gt;DISPLAY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$HOSTNAME&lt;/span&gt;:&lt;span class="nv"&gt;$DISPLAY&lt;/span&gt; ./Pandemic.c-mpi
&lt;span class="nb"&gt;time&lt;/span&gt; mpirun -n &lt;span class="m"&gt;8&lt;/span&gt; -x &lt;span class="nv"&gt;DISPLAY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$HOSTNAME$DISPLAY&lt;/span&gt; ./Pandemic.c-mpi
&lt;span class="nb"&gt;time&lt;/span&gt; mpirun -n &lt;span class="m"&gt;4&lt;/span&gt; -x &lt;span class="nv"&gt;DISPLAY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$HOSTNAME$DISPLAY&lt;/span&gt; ./Pandemic.c-mpi
&lt;span class="nb"&gt;time&lt;/span&gt; mpirun -n &lt;span class="m"&gt;2&lt;/span&gt; -x &lt;span class="nv"&gt;DISPLAY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$HOSTNAME$DISPLAY&lt;/span&gt; ./Pandemic.c-mpi
&lt;span class="nb"&gt;time&lt;/span&gt; mpirun -n &lt;span class="m"&gt;1&lt;/span&gt; -x &lt;span class="nv"&gt;DISPLAY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$HOSTNAME$DISPLAY&lt;/span&gt; ./Pandemic.c-mpi

&lt;span class="c1"&gt;# Report job statistics&lt;/span&gt;
scontrol show job &lt;span class="nv"&gt;$SLURM_JOB_ID&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hope you find this useful.&lt;/p&gt;</content><category term="Professional"></category><category term="HPC"></category></entry><entry><title>How do we know what we don't know we don't know?</title><link href="https://colbrydi.github.io/how-do-we-know-what-we-dont-know-we-dont-know.html" rel="alternate"></link><published>2018-12-07T00:00:00-05:00</published><updated>2018-12-07T00:00:00-05:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-12-07:/how-do-we-know-what-we-dont-know-we-dont-know.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="Education2035" hspace="10" src="//colbrydi.github.io/images/Education2035.jpg" width="100%,"&gt;&lt;/p&gt;
&lt;p&gt;Faculty at MSU conducted a workshop to brainstorm and discuss ways we can try and foresee how education will be changed by technology in an effort to get ahead of the changes and make sure our teaching goals and values stay intact.&lt;/p&gt;
&lt;p&gt;My presentation was about the difficulty in predicting …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="Education2035" hspace="10" src="//colbrydi.github.io/images/Education2035.jpg" width="100%,"&gt;&lt;/p&gt;
&lt;p&gt;Faculty at MSU conducted a workshop to brainstorm and discuss ways we can try and foresee how education will be changed by technology in an effort to get ahead of the changes and make sure our teaching goals and values stay intact.&lt;/p&gt;
&lt;p&gt;My presentation was about the difficulty in predicting what technology will look like in 17 years.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="//colbrydi.github.io/images/20181207-Education_2035_colbrydi.pdf"&gt;Link to the Presentation Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="Professional"></category><category term="Presentations"></category></entry><entry><title>Emerging Technologies (FPGAs) @ 2018 ACI-REF VR</title><link href="https://colbrydi.github.io/emerging-technologies-fpgas-2018-aci-ref-vr.html" rel="alternate"></link><published>2018-08-10T00:00:00-04:00</published><updated>2018-08-10T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-08-10:/emerging-technologies-fpgas-2018-aci-ref-vr.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="Picture from Panel" hspace="10" src="//colbrydi.github.io/images/Emerging_Technologies.jpg" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;Today is the last day of the &lt;a href="http://www.oscer.ou.edu/acirefvirtres2018.php"&gt;2018 ACI-REF Virtual residency&lt;/a&gt; workshop here in Norman Ok.  It was a great week with a lot of great people.  I highly recommend the workshop for anyone in the area of Advanced Computing Instruction especially those do some Research and Education Facilitation in …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="Picture from Panel" hspace="10" src="//colbrydi.github.io/images/Emerging_Technologies.jpg" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;Today is the last day of the &lt;a href="http://www.oscer.ou.edu/acirefvirtres2018.php"&gt;2018 ACI-REF Virtual residency&lt;/a&gt; workshop here in Norman Ok.  It was a great week with a lot of great people.  I highly recommend the workshop for anyone in the area of Advanced Computing Instruction especially those do some Research and Education Facilitation in their roles.  &lt;/p&gt;
&lt;p&gt;Thank you Aaron Bergstrom (U North Dakota) for again facilitating the panel discussion on &lt;strong&gt;Emerging Technologies&lt;/strong&gt; at the . My fellow panel members included:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;David Chin, Drexel U re Hadoop/Spark/MapReduce&lt;/li&gt;
&lt;li&gt;Shawn Doughty, Tufts U re OnDemand and Jupyter/Rstudio&lt;/li&gt;
&lt;li&gt;Anita Schwartz, U Delaware re Singularity&lt;/li&gt;
&lt;li&gt;Mariya Vyushkova, U Notre Dame re Quantum Computing&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I was invited to this panel to share based on the work we are doing at the CMSE department related to FPGAs.  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Purchased 2 nodes with Altera FPGAs&lt;/li&gt;
&lt;li&gt;Started a FPGA Taskforce for interested researchers&lt;/li&gt;
&lt;li&gt;Working with a Graduate Student (Ahmed Yousif) on an independent study related to an optimization problem (function fitting) on FPGAs&lt;/li&gt;
&lt;li&gt;This fall CMSE plans to conduct a Graduate Course to benchmark and test the 7 dwarves algorithms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is a direct link to my FPGA slides:&lt;/p&gt;
&lt;p&gt;&lt;a href="//colbrydi.github.io/images/20180810_ACI_REF_VR_FPGAs.pdf"&gt;FPGA only slides&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Follow the workshop on &lt;a href="https://www.facebook.com/OUHPC/"&gt;Facebook&lt;/a&gt;&lt;/p&gt;</content><category term="Professional"></category><category term="Presentations"></category><category term="HPC"></category></entry><entry><title>Deciding Which Technologies to Adopt, and When @ 2018 ACI-REF VR</title><link href="https://colbrydi.github.io/deciding-which-technologies-to-adopt-and-when-2018-aci-ref-vr.html" rel="alternate"></link><published>2018-08-08T00:00:00-04:00</published><updated>2018-08-08T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-08-08:/deciding-which-technologies-to-adopt-and-when-2018-aci-ref-vr.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="Image used in presentation representing the technology adoption wave" hspace="10" src="//colbrydi.github.io/images/Wave.jpg" width="30%,"&gt;&lt;/p&gt;
&lt;p&gt;I had fun leading a discussion on &lt;strong&gt;Deciding Which Technologies to Adopt, and When&lt;/strong&gt; at the &lt;a href="http://www.oscer.ou.edu/acirefvirtres2018.php"&gt;2018 ACI-REF Virtual residency&lt;/a&gt; event in Norman Oklahoma. Since many of the participants were virtual I experimented with doing a Brainstorming exercise over zoom. We had local volunteers on typing in comments from our …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="Image used in presentation representing the technology adoption wave" hspace="10" src="//colbrydi.github.io/images/Wave.jpg" width="30%,"&gt;&lt;/p&gt;
&lt;p&gt;I had fun leading a discussion on &lt;strong&gt;Deciding Which Technologies to Adopt, and When&lt;/strong&gt; at the &lt;a href="http://www.oscer.ou.edu/acirefvirtres2018.php"&gt;2018 ACI-REF Virtual residency&lt;/a&gt; event in Norman Oklahoma. Since many of the participants were virtual I experimented with doing a Brainstorming exercise over zoom. We had local volunteers on typing in comments from our local participants and remote participants typing their comments directly into the zoom group chat.  I tried my best to use typical brainstorming techniques and repeat all of the comments so everyone could hear them. This was especially important since remote participates could not hear the local participants.&lt;/p&gt;
&lt;p&gt;See a video of the discussion here:&lt;/p&gt;
&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/HR1_OZnKqn0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;If you are interested, you can find a copy of my slides can be found here:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.oscer.ou.edu/acirefvirtres2018_talk_techadoption_colbry_20180808.pdf"&gt;PDF of Slides&lt;/a&gt;&lt;/p&gt;</content><category term="Professional"></category><category term="Presentations"></category><category term="HPC"></category></entry><entry><title>Teams of CI Professionals: Recruitment &amp; Retention, Management, Team-building, and Motivation Panel @ 2018 ACI-REF VR</title><link href="https://colbrydi.github.io/teams-of-ci-professionals-recruitment-retention-management-team-building-and-motivation-panel-2018-aci-ref-vr.html" rel="alternate"></link><published>2018-08-07T00:00:00-04:00</published><updated>2018-08-07T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-08-07:/teams-of-ci-professionals-recruitment-retention-management-team-building-and-motivation-panel-2018-aci-ref-vr.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="Image from Panel" hspace="10" src="//colbrydi.github.io/images/Audience.jpg" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;Thank you Aaron Bergstrom (U North Dakota) for facilitating the panel discussion on &lt;strong&gt;Teams of CI Professionals: Recruitment &amp;amp; Retention, Management, Team-building, and Motivation&lt;/strong&gt; at the &lt;a href="http://www.oscer.ou.edu/acirefvirtres2018.php"&gt;2018 ACI-REF Virtual residency&lt;/a&gt;. My fellow panel members included:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Jerry Perez, U Texas Dallas&lt;/li&gt;
&lt;li&gt;Derek Leydig, Pennsylvania State U&lt;/li&gt;
&lt;li&gt;Claire Mizumoto, U California San Diego …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="Image from Panel" hspace="10" src="//colbrydi.github.io/images/Audience.jpg" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;Thank you Aaron Bergstrom (U North Dakota) for facilitating the panel discussion on &lt;strong&gt;Teams of CI Professionals: Recruitment &amp;amp; Retention, Management, Team-building, and Motivation&lt;/strong&gt; at the &lt;a href="http://www.oscer.ou.edu/acirefvirtres2018.php"&gt;2018 ACI-REF Virtual residency&lt;/a&gt;. My fellow panel members included:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Jerry Perez, U Texas Dallas&lt;/li&gt;
&lt;li&gt;Derek Leydig, Pennsylvania State U&lt;/li&gt;
&lt;li&gt;Claire Mizumoto, U California San Diego&lt;/li&gt;
&lt;li&gt;Robert Ping, Indiana U&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I thought the panel went really well with both remote and local panelist and both local and remote participants. We discussed all types of topics related to finding good people, mentoring students, professional development and institutional politics.  Go to the  &lt;a href="http://www.oscer.ou.edu/acirefvirtres2018.php"&gt;2018 ACI-REF Virtual residency&lt;/a&gt; and they should link to a video if you want to watch.&lt;/p&gt;
&lt;p&gt;Follow the workshop on &lt;a href="https://www.facebook.com/OUHPC/"&gt;Facebook&lt;/a&gt;&lt;/p&gt;</content><category term="Professional"></category><category term="Presentations"></category><category term="HPC"></category></entry><entry><title>Leading and Listening in Complex CI Conversations @ 2018 ACI-REF VR</title><link href="https://colbrydi.github.io/leading-and-listening-in-complex-ci-conversations-2018-aci-ref-vr.html" rel="alternate"></link><published>2018-08-06T00:00:00-04:00</published><updated>2018-08-06T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-08-06:/leading-and-listening-in-complex-ci-conversations-2018-aci-ref-vr.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="Graphical Depiction of two people having a complex conversation" hspace="10" src="//www.leamcleod.com/wp-content/uploads/2014/06/Communication-challenge.jpg" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;I just got done trying out our latest CyberAmbassador Curriculum developed specifically for the  &lt;a href="http://www.oscer.ou.edu/acirefvirtres2018.php"&gt;2018 ACI-REF Virtual residency&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We had some growing pains related to getting zoom breakout rooms working with a large group of people calling in.  Some didn't have working mics, others work in a group room and …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="Graphical Depiction of two people having a complex conversation" hspace="10" src="//www.leamcleod.com/wp-content/uploads/2014/06/Communication-challenge.jpg" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;I just got done trying out our latest CyberAmbassador Curriculum developed specifically for the  &lt;a href="http://www.oscer.ou.edu/acirefvirtres2018.php"&gt;2018 ACI-REF Virtual residency&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We had some growing pains related to getting zoom breakout rooms working with a large group of people calling in.  Some didn't have working mics, others work in a group room and could not talk, others just didn't feel like participating.  Overall though I think it worked out well especially during the second breakout when we had a little more time.  Check out the slides on the CyberAmbassador website:&lt;/p&gt;
&lt;p&gt;&lt;a href="//colbrydi.github.io/cyberambassadors/practice-examples-for-complex-communication.html"&gt;Link to ACI-REF 2018 Complex Communications Files&lt;/a&gt;&lt;/p&gt;</content><category term="Professional"></category><category term="Presentations"></category></entry><entry><title>Progress Update on the Development and Implementation of the Advanced CI-REF VR Program</title><link href="https://colbrydi.github.io/progress-update-on-the-development-and-implementation-of-the-advanced-ci-ref-vr-program.html" rel="alternate"></link><published>2018-07-25T00:00:00-04:00</published><updated>2018-07-25T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-07-25:/progress-update-on-the-development-and-implementation-of-the-advanced-ci-ref-vr-program.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="ACI-Ref Buiding Picture" hspace="10" src="https://aciref.org/wp-content/uploads/2017/09/FullSizeRender-2-1024x765.jpg" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;Henry Neeman did a great job presenting our paper on &lt;a href="https://pearc18.conference-program.com/?page_id=10&amp;amp;id=pap144&amp;amp;sess=sess164"&gt;Progress Update for the CI-REF VR Program&lt;/a&gt; at &lt;a href="//www.pearc18.pearc.org/"&gt;PEARC18&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Writing of this paper was truly a unique experience for me. The entire paper was written virtually over weekly video conference meetings and included the thirteen sited (maximum) authors and I …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="ACI-Ref Buiding Picture" hspace="10" src="https://aciref.org/wp-content/uploads/2017/09/FullSizeRender-2-1024x765.jpg" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;Henry Neeman did a great job presenting our paper on &lt;a href="https://pearc18.conference-program.com/?page_id=10&amp;amp;id=pap144&amp;amp;sess=sess164"&gt;Progress Update for the CI-REF VR Program&lt;/a&gt; at &lt;a href="//www.pearc18.pearc.org/"&gt;PEARC18&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Writing of this paper was truly a unique experience for me. The entire paper was written virtually over weekly video conference meetings and included the thirteen sited (maximum) authors and I think dozens of other contributors.  Henry does an amazing job coordinating this army of people, soliciting their input and giving them opportunities to learn.   I am looking forward to the ACI-Ref Virtual Residency workshop in a couple of weeks so I can see everyone again in person.&lt;/p&gt;
&lt;p&gt;Below is a summary:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; Description: &lt;/strong&gt;
Cyberinfrastructure facilitation -- working directly with researchers to advance the computing-intensive and data-intensive aspects of their investigations, especially via large-scale and advanced computing -- has emerged as a crucial component of research computing processes. However, because no national formal education curriculum exists to cultivate the needed workforce, informal education is the most viable approach. The Advanced Cyberinfrastructure Research and Education Facilitator (ACI-REF) Virtual Residency (VR) program, in operation since summer 2015, is a national informal education program that trains Cyberinfrastructure (CI) Facilitators on effective methods for serving their research and education constituents, especially focusing on professional (soft) skills (because much of the technical content that facilitators need is available via other opportunities). The VR consists primarily of (a) summer weeklong intensive workshops that provide both content and experiences in facilitation, (b) biweekly conference calls that expand upon both the kinds of topics introduced in the workshops and additional content and experiences, (c) meetings at national conferences and (d) a grant proposal writing apprenticeship. Future plans focus on extending the VR model to intermediate and advanced levels, as well as disseminating a "train-the-trainers-of-trainers" approach to teaching other organizations to conduct their own VR activities within their own CI Facilitator communities, in order to expand the VR's scale, scope, and reach. The VR program and its offshoots have already served 364 CI professionals at 188 institutions across the US and internationally. Virtual Residents are positioned to advance to the intermediate level and beyond, and ultimately to become institutional and national CI leaders.&lt;/p&gt;</content><category term="Professional"></category><category term="Presentations"></category><category term="Publication"></category></entry><entry><title>Fitting iCE-Cube Neutrino Path models using Neural Networks</title><link href="https://colbrydi.github.io/fitting-ice-cube-neutrino-path-models-using-neural-networks.html" rel="alternate"></link><published>2018-07-24T00:00:00-04:00</published><updated>2018-07-24T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-07-24:/fitting-ice-cube-neutrino-path-models-using-neural-networks.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="Mohammed and his poster" hspace="10" src="//colbrydi.github.io/images/Mohammed.jpg" width="30%,"&gt;&lt;/p&gt;
&lt;p&gt;This summer Mohammed Salih worked with me as part of the Engineering &lt;a href="https://www.egr.msu.edu/graduate/ensure"&gt;ENSURE&lt;/a&gt; Program.  He presented his work with Jessie Micallef and me as a poster at &lt;a href="https://urca.msu.edu/mid-sure"&gt;MidSURE&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Poster Abstract&lt;/strong&gt;: Neutrinos are small particles with a mass close to zero. It’s rare interaction with normal matter makes it difficult …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="Mohammed and his poster" hspace="10" src="//colbrydi.github.io/images/Mohammed.jpg" width="30%,"&gt;&lt;/p&gt;
&lt;p&gt;This summer Mohammed Salih worked with me as part of the Engineering &lt;a href="https://www.egr.msu.edu/graduate/ensure"&gt;ENSURE&lt;/a&gt; Program.  He presented his work with Jessie Micallef and me as a poster at &lt;a href="https://urca.msu.edu/mid-sure"&gt;MidSURE&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Poster Abstract&lt;/strong&gt;: Neutrinos are small particles with a mass close to zero. It’s rare interaction with normal matter makes it difficult to determine its precise mass. Researchers in the the Ice Cube project are working on determining neutrinos precise mass. The Ice Cube project is a sub particle detector in the south pole that records the interactions of neutrinos. The detector is a 150 KM grid with a hexagonal shape 1 km under Ice. Each hole in the grid has a 1 km string, each with about 60 light sensors. Since a neutrino is faster than the speed of light in ice, it emits light in ice. Therefore, the emitted photon is detected by the sensors in the detector. Using the measurements from the detector, we can determine angle, origin, speed, and energy using analytics and machine learning. The interest in this project is to identify neutrinos have come from the center of the galaxy. To check if machine learning is an appropriate method for this project, we create a virtual ice cube simulator using phantom data generation method to simplify and control the data set. Then we use machine learning on this data to determine if it is an appropriate method for this problem.&lt;/p&gt;</content><category term="Professional"></category><category term="Presentations"></category></entry><entry><title>Campus Champions 101 Panel at PEARC18</title><link href="https://colbrydi.github.io/campus-champions-101-panel-at-pearc18.html" rel="alternate"></link><published>2018-07-23T00:00:00-04:00</published><updated>2018-07-23T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-07-23:/campus-champions-101-panel-at-pearc18.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="Campus Champion Logo Logo" hspace="10" src="https://www.xsede.org/wwwteragrid/archive/image/image_gallery%3Fuuid=554fecca-1a37-44d0-826f-afad9470153d&amp;amp;groupId=298192&amp;amp;t=1291845274821" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;I had an opportunity to participate on the "Researcher Facing" Panel as part of the  &lt;a href="https://www.xsede.org/community-engagement/campus-champions"&gt;Campus Champion 101&lt;/a&gt; workshop at &lt;a href="https://www.pearc18.pearc.org/"&gt;PEARC18&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;&lt;a href="//docs.google.com/document/d/1OsOCUOeWAk1IfJzEi8LuO5YnIiKkU2AO-cxzY0F0gzk/edit"&gt;Link to Notes For the Panel can be found  here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://pearc18.conference-program.com/?page_id=10&amp;amp;id=work108&amp;amp;sess=sess123"&gt;Campus Champions 101 workshop&lt;/a&gt; explores campus research computing roles. The workshop builds on the Campus Champions’ history and …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="Campus Champion Logo Logo" hspace="10" src="https://www.xsede.org/wwwteragrid/archive/image/image_gallery%3Fuuid=554fecca-1a37-44d0-826f-afad9470153d&amp;amp;groupId=298192&amp;amp;t=1291845274821" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;I had an opportunity to participate on the "Researcher Facing" Panel as part of the  &lt;a href="https://www.xsede.org/community-engagement/campus-champions"&gt;Campus Champion 101&lt;/a&gt; workshop at &lt;a href="https://www.pearc18.pearc.org/"&gt;PEARC18&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;&lt;a href="//docs.google.com/document/d/1OsOCUOeWAk1IfJzEi8LuO5YnIiKkU2AO-cxzY0F0gzk/edit"&gt;Link to Notes For the Panel can be found  here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://pearc18.conference-program.com/?page_id=10&amp;amp;id=work108&amp;amp;sess=sess123"&gt;Campus Champions 101 workshop&lt;/a&gt; explores campus research computing roles. The workshop builds on the Campus Champions’ history and leverages the recent Research Computing and Data Professionals Job Elements and Career Guide that was developed by the March 2018 NSF-sponsored Campus Research Computing Consortium (CaRCC) workshop. Opening sessions will cover (a) the Cyberinfrastructure ecosystem and (b) research computing roles and responsibilities, introducing four broad job families: researcher-facing roles, systems-facing roles, sponsor/stakeholder-facing roles, and software/data-facing roles. Short talks, panels and roundtables will cover three of these four roles: researcher-facing, sponsor/stakeholder-facing, and systems-facing.&lt;/p&gt;</content><category term="Professional"></category><category term="Presentations"></category></entry><entry><title>Bringing Professional Skills Training to CI - PEARC18 Birds of a Feather (BOF)</title><link href="https://colbrydi.github.io/bringing-professional-skills-training-to-ci-pearc18-birds-of-a-feather-bof.html" rel="alternate"></link><published>2018-07-22T00:00:00-04:00</published><updated>2018-07-22T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-07-22:/bringing-professional-skills-training-to-ci-pearc18-birds-of-a-feather-bof.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="PEARC18 Logo" hspace="10" src="http://insidehpc.com/wp-content/uploads/2017/10/pearc18.jpg" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href="//colbrydi.github.io/cyberambassadors"&gt;CyberAmbassador&lt;/a&gt;  a Birds of a Feather Event at the 2018 PEARC Conference. Please Join us on Wednesday, July 25th from 5pm - 6pm.  More information can be found here:&lt;/p&gt;
&lt;p&gt;&lt;a href="//pearc18.conference-program.com/?page_id=10&amp;amp;id=bof122&amp;amp;sess=sess203"&gt;Link to BOF Schedule&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; Description: &lt;/strong&gt;
A number of professional skills training programs and resources have been developed in recent years, in …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="PEARC18 Logo" hspace="10" src="http://insidehpc.com/wp-content/uploads/2017/10/pearc18.jpg" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href="//colbrydi.github.io/cyberambassadors"&gt;CyberAmbassador&lt;/a&gt;  a Birds of a Feather Event at the 2018 PEARC Conference. Please Join us on Wednesday, July 25th from 5pm - 6pm.  More information can be found here:&lt;/p&gt;
&lt;p&gt;&lt;a href="//pearc18.conference-program.com/?page_id=10&amp;amp;id=bof122&amp;amp;sess=sess203"&gt;Link to BOF Schedule&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; Description: &lt;/strong&gt;
A number of professional skills training programs and resources have been developed in recent years, in part due to the efforts of the NSF CyberTraining Initiative. The goal of this BOF is to bring these groups together and explore ways to share information and coordinate efforts.&lt;/p&gt;
&lt;p&gt;As the integration of CI in research continues, CI Professionals find themselves tackling problems and consulting on projects that are increasingly complex and collaborative. In order to respond to these various requests, CI Professionals need both the expertise to solve computational challenges and the professional skills to work effectively with individuals and teams who have diverse backgrounds, experiences, and goals.&lt;/p&gt;
&lt;p&gt;The organizers of this BOF will facilitate conversations and brainstorming activities within this interactive session, with the goal of identifying opportunities to build on each other’s success and develop ongoing collaborations. For example, authors of open-source professional skills curricula might meet experienced facilitators with an interest in bringing their content to new audiences. Or content developers might identify gaps in available resources and develop new partnerships to address these needs.&lt;/p&gt;
&lt;p&gt;This BOF is proposed by a team that has received NSF CyberTraining funds to develop open-source, professional skills training in communication, teamwork and leadership for CI Professionals along with a “train the trainers” module to facilitate national access to these materials.&lt;/p&gt;</content><category term="Professional"></category><category term="Presentations"></category></entry><entry><title>Pelican Github.io Tutorial</title><link href="https://colbrydi.github.io/pelican-githubio-tutorial.html" rel="alternate"></link><published>2018-07-17T00:00:00-04:00</published><updated>2018-07-17T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-07-17:/pelican-githubio-tutorial.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="Pelican Github.io  Logo" hspace="10" src="//docs.google.com/a/msu.edu/drawings/d/slwvmwORPg9obcema4qeYEg/image?parent=e/2PACX-1vRGU8icBbrWq1sHjWR3oDeCjeVVY_xgl2-aq1T3iTFxFMYiBdrv73kwax9A-P4pXXV_Wy6RwVtcG1Cz&amp;amp;rev=6&amp;amp;h=200&amp;amp;w=182&amp;amp;ac=1" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;My student's and I figured out how to use &lt;a href="https://blog.getpelican.com/"&gt;Pelican&lt;/a&gt; with &lt;a href="https://pages.github.com/"&gt;Github.io&lt;/a&gt; pages to create some websites for work.  We tried to type up the instructions as a tutorial and build a pelican template.  Here is a link to the tutorial:&lt;/p&gt;
&lt;p&gt;&lt;a href="//colbrydi.github.io/msupelican"&gt;Pelican / Github.io Tutorial&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Some of our websites …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="Pelican Github.io  Logo" hspace="10" src="//docs.google.com/a/msu.edu/drawings/d/slwvmwORPg9obcema4qeYEg/image?parent=e/2PACX-1vRGU8icBbrWq1sHjWR3oDeCjeVVY_xgl2-aq1T3iTFxFMYiBdrv73kwax9A-P4pXXV_Wy6RwVtcG1Cz&amp;amp;rev=6&amp;amp;h=200&amp;amp;w=182&amp;amp;ac=1" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;My student's and I figured out how to use &lt;a href="https://blog.getpelican.com/"&gt;Pelican&lt;/a&gt; with &lt;a href="https://pages.github.com/"&gt;Github.io&lt;/a&gt; pages to create some websites for work.  We tried to type up the instructions as a tutorial and build a pelican template.  Here is a link to the tutorial:&lt;/p&gt;
&lt;p&gt;&lt;a href="//colbrydi.github.io/msupelican"&gt;Pelican / Github.io Tutorial&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Some of our websites currently using this method of publishing include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="//colbrydi.github.io"&gt;http://colbrydi.github.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="//nolanfeeny.github.io/"&gt;http://nolanfeeny.github.io/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="//colbrydi.github.io/msupelican"&gt;http://colbrydi.github.io/msupelican&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="//colbrydi.github.io/cyberambassadors"&gt;http://colbrydi.github.io/cyberambassadors&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Feel free to comment below (or email me) if you have any questions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; Dirk &lt;/strong&gt;&lt;/p&gt;</content><category term="Professional"></category></entry><entry><title>Installing RStudio on the MSU HPCC</title><link href="https://colbrydi.github.io/installing-rstudio-on-the-msu-hpcc.html" rel="alternate"></link><published>2018-07-06T00:00:00-04:00</published><updated>2018-07-06T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-07-06:/installing-rstudio-on-the-msu-hpcc.html</id><summary type="html">&lt;p&gt;&lt;img alt="Rstudio" src="//www.rstudio.com/wp-content/uploads/2016/09/RStudio-Logo-Blue-Gray-250.png"&gt;&lt;/p&gt;
&lt;p&gt;These instructions are for installing RStudio on the HPCC. RStudio provides a variety of installers on their website &lt;a href="https://www.rstudio.com/products/rstudio/download2/"&gt;https://www.rstudio.com/products/rstudio/download2/&lt;/a&gt;. However, the HPCC uses an older version of Linux and the precompiled binaries are not compatible.  Trying to install RStudio from the source code is …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="Rstudio" src="//www.rstudio.com/wp-content/uploads/2016/09/RStudio-Logo-Blue-Gray-250.png"&gt;&lt;/p&gt;
&lt;p&gt;These instructions are for installing RStudio on the HPCC. RStudio provides a variety of installers on their website &lt;a href="https://www.rstudio.com/products/rstudio/download2/"&gt;https://www.rstudio.com/products/rstudio/download2/&lt;/a&gt;. However, the HPCC uses an older version of Linux and the precompiled binaries are not compatible.  Trying to install RStudio from the source code is an option but is also difficult due to the large numbers of libraries and compile dependancies.  I basically gave up trying to install RStudio on until I realized that a version is included as an option in Anaconda.  The following instructions show how to install RStudio using Anaconda.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Step 0:&lt;/strong&gt; Connect to the HPC.&lt;/h2&gt;
&lt;p&gt;Use ssh to connect to the HPCC and make sure you have a working X11 server (ex. MobaXterm on windows or XQuarts on Mac).  More information about X11 can be found here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="//wiki.hpcc.msu.edu/display/hpccdocs/Installing+an+X-server+on+Windows"&gt;Old HPCC Windows instructions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://wiki.hpcc.msu.edu/display/hpccdocs/Installing+an+X-server++for+Macs"&gt;Old HPCC Mac Instructions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;strong&gt;Step 1:&lt;/strong&gt; Download the Linux Anaconda installers&lt;/h2&gt;
&lt;p&gt;Find the latest Linux installer on the &lt;a href="//www.anaconda.com/download/#linux"&gt;Anaconda website&lt;/a&gt;. Right click on the download button for version 3.x and select "Copy Link". Use the &lt;code&gt;wget&lt;/code&gt; command on the hpcc to download the script file by typing wget and then pasting the url. For Example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;wget&lt;/span&gt; &lt;span class="n"&gt;https&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;repo&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;anaconda&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;com&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;archive&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Anaconda3&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Linux&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sh&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;&lt;strong&gt;Step 2:&lt;/strong&gt; Install anaconda using the defaults&lt;/h2&gt;
&lt;p&gt;Run the downloaded script in bash using the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;bash&lt;/span&gt; &lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Anaconda3&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Linux&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sh&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The last question will ask you to add the anaconda folder to your bashrc file. Say yes...&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Step 3:&lt;/strong&gt; Install RStudio&lt;/h2&gt;
&lt;p&gt;Use the conda install command to install RStudio.  Note you may need to run &lt;code&gt;source ~/.bashrc&lt;/code&gt; first to update your path:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;conda&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;rstudio&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That should be it, RStudio is now installed in your home directory on the HPCC.  The only other thing you will need is a X11 server.  Assuming you have connected to the hpcc with an X11 connection you can run rstudio from the command line by typing:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;rstudio&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="Professional"></category><category term="HPC"></category></entry><entry><title>Managing Inconsistent Runtimes on the HPCC</title><link href="https://colbrydi.github.io/managing-inconsistent-runtimes-on-the-hpcc.html" rel="alternate"></link><published>2018-06-29T00:00:00-04:00</published><updated>2018-06-29T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-06-29:/managing-inconsistent-runtimes-on-the-hpcc.html</id><summary type="html">&lt;p&gt;One of our postdocs stopped by my office today to talk about a problem with inconsistant runtimes on our &lt;a href="//icer.msu.edu"&gt;HPCC&lt;/a&gt;.  This user is running a lot of jobs with 512 cores (current cpu limit is 520).  The problem is that it is really difficult for the user to estimate the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;One of our postdocs stopped by my office today to talk about a problem with inconsistant runtimes on our &lt;a href="//icer.msu.edu"&gt;HPCC&lt;/a&gt;.  This user is running a lot of jobs with 512 cores (current cpu limit is 520).  The problem is that it is really difficult for the user to estimate the walltimes. There is a 2x difference in walltimes on the HPCC.  The code has been tested on other large scale systems with much less variation. The user would prefer more consistent runtimes and did not mind waiting in the queue (although less queue time is better).  &lt;/p&gt;
&lt;p&gt;The problem is that there are many things that can impact the runtime of a job. The HPCC runs at over 95% utilization most of the time so many of the resources are in contention.  Without additional information, my best guess is that the bottleneck is MPI communication over the high speed network. If this is the case, I hypothesize that moving more processes to the same nodes (instead of spread across the cluster) will help reduce network competition with other users and result in more consistent walltimes. Here are some things I suggested the user try:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Open a ticket with iCER and see if you can set up a consulting appointment. They may be able to get much better idea about what resources are in contention and causing the bottleneck: &lt;a href="https://contact.icer.msu.edu/contact"&gt;https://contact.icer.msu.edu/contact&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Add “qstat -f ${PBS_JOBID}” to the end of the jobscript.  This will provide some stats that may help us understand differences between jobs that run fast and slow.   &lt;/li&gt;
&lt;li&gt;Try different core and node ratios (ex. nodes=128:ppn=4, nodes=64:ppn=8, nodes=32:ppn=8 etc.). Although increasing the ppn will likely make queue times longer, i believe the overall runtime will be more consistent.&lt;/li&gt;
&lt;li&gt;Start the process to get DOE and XSEDE allocations.  Create XSEDE Portal account here: &lt;a href="https://portal.xsede.org/"&gt;https://portal.xsede.org/&lt;/a&gt; and send me your login name when you get it so we can add you to the MSU campus champion account.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Anyone else have a similar problem?  Other suggestions that I may have missed?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; Dirk &lt;/strong&gt;&lt;/p&gt;</content><category term="Professional"></category><category term="HPC"></category></entry><entry><title>Getting dlvr.it to work with Pelican generated website</title><link href="https://colbrydi.github.io/getting-dlvrit-to-work-with-pelican-generated-website.html" rel="alternate"></link><published>2018-06-28T14:00:00-04:00</published><updated>2018-06-28T14:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-06-28:/getting-dlvrit-to-work-with-pelican-generated-website.html</id><summary type="html">&lt;p&gt;Back when I worked for &lt;a href="//icer.msu.edi"&gt;iCER&lt;/a&gt; I had my blog set up to automatically Tweet when I posted something new using a service called Twitter Feed. Unfortunately, Twitter Feed is no longer around and their website recommended &lt;a href="//dlvr.it"&gt;dlvr.it&lt;/a&gt; as an alternative.  &lt;/p&gt;
&lt;p&gt;So far it was fairly strait forward to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Back when I worked for &lt;a href="//icer.msu.edi"&gt;iCER&lt;/a&gt; I had my blog set up to automatically Tweet when I posted something new using a service called Twitter Feed. Unfortunately, Twitter Feed is no longer around and their website recommended &lt;a href="//dlvr.it"&gt;dlvr.it&lt;/a&gt; as an alternative.  &lt;/p&gt;
&lt;p&gt;So far it was fairly strait forward to set up an account and I followed the menus to connect my &lt;a href="//docs.getpelican.com/en/3.6.3/"&gt;Pelican&lt;/a&gt; RSS feed to my &lt;a href="//twitter.com/colbrydi"&gt;Titter&lt;/a&gt; account. At first it didn't seem to do anything but then I noticed a message that said something like "Last checked 56 seconds ago" and I went back to my Twitter account and all of my blog posts had been tweeted.  Which is what I wanted so Yeah!&lt;/p&gt;
&lt;p&gt;However, there were a lot of options that I didn't understand.  For example, I thought it would only tweet the latest blog post.  It didn't, it tweeted them all. Which is fine, this is where I wanted to go but I was hoping to test it first before blasting all of my twitter followers (I do not think I have many).  &lt;/p&gt;
&lt;p&gt;The second problem was that it only tweeted the title and the URL which is not very detailed. I don't want to everyone to be required to go to my blog post.  I found an option to also include the body of the post.  We will see if that does anything.  &lt;/p&gt;
&lt;p&gt;I plan to use this post as a test.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dirk&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update 1:&lt;/strong&gt; There was a setting in dlvr.it that I turned on to "Post Body".  This let more come though the twitter feed and nicely includes an image.  This makes the behavior act as expected so I am really excited.  Oddly, this particular post is not seen on Twitter.  This is because I went over the 10 post limit on dlvr.it.   I am going to change the post date to today and see if that helps things out.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update 2:&lt;/strong&gt; Changing the date in the post didn't seem to trigger dlvr.it to post this message on twitter. I am now changing the filename inside of pelican to see if that changes the RSS feed enough to make dlvr.it think this is a new post.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update 3:&lt;/strong&gt; Changing the pelican filename didn't do anything either. I looked though the RSS feed and now I think maybe changing the post title will make a difference.&lt;/p&gt;</content><category term="Professional"></category><category term="Blogging"></category><category term="Product Reviews"></category></entry><entry><title>Ensure Talk - An Engineers Autobiography</title><link href="https://colbrydi.github.io/ensure-talk-an-engineers-autobiography.html" rel="alternate"></link><published>2018-06-27T00:00:00-04:00</published><updated>2018-06-27T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-06-27:/ensure-talk-an-engineers-autobiography.html</id><summary type="html">&lt;p&gt;&lt;img alt="EnSURE Logo" src="//www.egr.msu.edu/graduate/sites/default/files/content/ensure_logo.jpg"&gt;&lt;/p&gt;
&lt;p&gt;I gave an autobiographical talk today to the &lt;a href="//www.egr.msu.edu/graduate/ensure"&gt;EnSURE&lt;/a&gt; (Engineering Summer Undergraduate Research Experience) students. I have given this talk a few times and it is noticeably different that most of my presentations because the EnSURE organizers asked me to talk about myself and how I got where I am …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="EnSURE Logo" src="//www.egr.msu.edu/graduate/sites/default/files/content/ensure_logo.jpg"&gt;&lt;/p&gt;
&lt;p&gt;I gave an autobiographical talk today to the &lt;a href="//www.egr.msu.edu/graduate/ensure"&gt;EnSURE&lt;/a&gt; (Engineering Summer Undergraduate Research Experience) students. I have given this talk a few times and it is noticeably different that most of my presentations because the EnSURE organizers asked me to talk about myself and how I got where I am (instead of research or teaching).  The first time I gave this talk it was really awkward.  However, now I think it is kind of fun to tell stories about the choices I made throughout school and my carrier.  I get a lot of questions when I am done so I like to think the student's enjoyed the talk as well.  Here are a copy of my slides:&lt;/p&gt;
&lt;p&gt;&lt;a href="./Images/20180628_An_Engineers_Autobiography.pdf"&gt;0180628_An_Engineers_Autobiography.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; Dirk &lt;/strong&gt;&lt;/p&gt;</content><category term="Professional"></category><category term="Presentations"></category></entry><entry><title>Commit Early and Often</title><link href="https://colbrydi.github.io/commit-early-and-often.html" rel="alternate"></link><published>2018-06-26T12:00:00-04:00</published><updated>2018-06-26T12:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-06-26:/commit-early-and-often.html</id><summary type="html">&lt;p&gt;&lt;strong&gt;Ugh! Rookie mistake!&lt;/strong&gt;  I just spent all morning working on my website and blog.  I was really happy with the improvements. I was making some modifications to the Makefile in the pelican folder to streamline my workflow when... all of my files disappeared.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rookie Mistake #1:&lt;/strong&gt; I unintentionally did a …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;Ugh! Rookie mistake!&lt;/strong&gt;  I just spent all morning working on my website and blog.  I was really happy with the improvements. I was making some modifications to the Makefile in the pelican folder to streamline my workflow when... all of my files disappeared.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rookie Mistake #1:&lt;/strong&gt; I unintentionally did a &lt;code&gt;rm -rf *&lt;/code&gt; in the wrong folder and lost of of my work.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rookie Mistake #2:&lt;/strong&gt; I had not committed any of my changes to the repository.  All was lost.  &lt;/p&gt;
&lt;p&gt;Sigh. Now I need to try to go back and remember what I did all morning.  &lt;/p&gt;
&lt;p&gt;Lessons relearned:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Commit early and Often&lt;/li&gt;
&lt;li&gt;Be respectful of &lt;code&gt;rm -rf *&lt;/code&gt; especially when it is in a &lt;code&gt;Makefile&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt; Dirk &lt;/strong&gt;&lt;/p&gt;</content><category term="Professional"></category><category term="Blogging"></category><category term="Pelican"></category></entry><entry><title>Planning a new Course</title><link href="https://colbrydi.github.io/planning-a-new-course.html" rel="alternate"></link><published>2018-06-10T00:00:00-04:00</published><updated>2018-06-10T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-06-10:/planning-a-new-course.html</id><summary type="html">&lt;p&gt;This post describes a technique I use to plan an organize a course from scratch.  I learned this technique from Dr. Brian O'Shea.  &lt;/p&gt;
&lt;p&gt;At Michigan State University (MSU) my official title is curriculum specialist.  I have the unique opportunity to help develop entirely new courses for a brand new department …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This post describes a technique I use to plan an organize a course from scratch.  I learned this technique from Dr. Brian O'Shea.  &lt;/p&gt;
&lt;p&gt;At Michigan State University (MSU) my official title is curriculum specialist.  I have the unique opportunity to help develop entirely new courses for a brand new department (Computational Mathematics, Science and Engineering CMSE, EST 2015).  &lt;/p&gt;
&lt;p&gt;My colleague (Dr. Brian O'Shea) showed me a nice trick to organize my semester and brainstorm ideas to do a better job with backward design and matching up my lessons to my learning goals.  I make a grid of 3 rows with 5 columns on a whiteboard.  Each box represents one week of the semester (15 total).  I then use post-it notes to write down ideas and place them on the board.  This is a brainstorming stage where all ideas are equal.  If I do this early enough I can leave the board up and move the sticky notes around as I think about my learning goals.&lt;/p&gt;
&lt;p&gt;&lt;img alt="MarkerBoard Grid" src="./Images/markdown-img-paste-20180610141148377.png"&gt;&lt;/p&gt;
&lt;p&gt;I recently moved away from the whiteboard and use a blank wall in my office. I created the grid with painters tape. This leaves my whiteboard open for other ideas and lets me put up a board really early. For example, it is June and I have a board up for my Spring Course on Parallel programming.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Painters Tape Wall" src="./Images/markdown-img-paste-20180610140831494.png"&gt;&lt;/p&gt;
&lt;p&gt;Since I have been desinging many courses I may just leave the painters tape up.  &lt;/p&gt;</content><category term="Professional"></category><category term="Teaching"></category></entry><entry><title>Spark mail</title><link href="https://colbrydi.github.io/spark-mail.html" rel="alternate"></link><published>2018-06-06T00:00:00-04:00</published><updated>2018-06-06T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-06-06:/spark-mail.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="Spark Logo" hspace="10" src="//sparkmailapp.com/img/spark2/common/spark.svg" width="20%,"&gt;
I am weird that I like email.  It is my preferred form of communication on projects (maybe I am just getting old).  I trust that I will get to my email and that I will not loose things.  I realize that this trust is often not true but it is …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="Spark Logo" hspace="10" src="//sparkmailapp.com/img/spark2/common/spark.svg" width="20%,"&gt;
I am weird that I like email.  It is my preferred form of communication on projects (maybe I am just getting old).  I trust that I will get to my email and that I will not loose things.  I realize that this trust is often not true but it is true enough for me to keep productive. For the longest time Gmail was my favorite email application. However, work changed policy from "we highly recommend you don't use Gmail" to "don't use gmail".  So I chose to switch to the university Office 365 accounts.  &lt;/p&gt;
&lt;p&gt;I tried the built-in Mac mail program.  It didn't thread my email the way I prefer.  I also tried outlook which had its own problems.  I don't really feel like bashing this software, it just didn't work in a way that fit my Gmail workflow.&lt;/p&gt;
&lt;p&gt;As I move into a new laptop I stubbled across the spark email client. About three weeks into using it I am very satisfied. The laptop and phone versions work nicely together. I really like having both my personal Gmail account and work accounts connected in one application.  There are a lot of things I like but probably the best is that since using Spark I have gotten my inbox to zero almost every day.  This is big news. I am a big fan of emptying my inbox but this is often a challenge.  I like the fact that Spark will allow me to show badges with the number of messages in my inbox instead of the number of unread messages.  For some reason this is a real motivator for getting my email where they need to be. It also helps me keep my Gmail clean which is mostly news feeds, advertisements, etc.  &lt;/p&gt;</content><category term="Professional"></category><category term="Product Reviews"></category><category term="Lifehacking"></category></entry><entry><title>Inverse Problems Seminar</title><link href="https://colbrydi.github.io/inverse-problems-seminar.html" rel="alternate"></link><published>2018-06-04T00:00:00-04:00</published><updated>2018-06-04T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-06-04:/inverse-problems-seminar.html</id><summary type="html">&lt;p&gt;I was invited to give a talk at the inverse seminars symposium:&lt;/p&gt;
&lt;p&gt;&lt;a href="//inverseproblems2018.org/"&gt;https://inverseproblems2018.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;At first I was a little nervous since I don't consider myself an expert in inverse problems so I did not fully understand what they wanted me to present. However after talking to the organizers …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I was invited to give a talk at the inverse seminars symposium:&lt;/p&gt;
&lt;p&gt;&lt;a href="//inverseproblems2018.org/"&gt;https://inverseproblems2018.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;At first I was a little nervous since I don't consider myself an expert in inverse problems so I did not fully understand what they wanted me to present. However after talking to the organizers (Kirk and James), I discovered what they wanted was a high level talk and overview of advanced computing. This was something I could do! I put together snippets from a variety of my previous talks. Here is a link to the slides:&lt;/p&gt;
&lt;p&gt;&lt;a href="./Images/20180604-InverseProblems.pdf"&gt;20180604-InverseProblems&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Originally I planned for a 60 minute talk but only ended up with 45 minutes (at most) of content. Luckly for me the organizers only really wanted a 30 Minutes talk and in the end I was relaxed and able to get though my slides at a reasonable pace in 20 minutes which led to 10 minutes of questions which turned out to be perfect.  &lt;/p&gt;
&lt;p&gt;Overall the Inverse Problems Symposium was a great event and I learned a lot. I was honored to be invited to give a talk. I was even considering attending next year at Notre Dame.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; Dirk &lt;/strong&gt;&lt;/p&gt;</content><category term="Professional"></category><category term="Presentations"></category><category term="HPC"></category></entry><entry><title>White Noise and Teaching</title><link href="https://colbrydi.github.io/white-noise-and-teaching.html" rel="alternate"></link><published>2018-05-23T00:00:00-04:00</published><updated>2018-05-23T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-05-23:/white-noise-and-teaching.html</id><summary type="html">&lt;p&gt;It can be difficult to be the first student to talk in a quite classroom.  I have been experimenting with the use of white noise to raise the overall din in the room and encourage taking more quickly.&lt;/p&gt;
&lt;p&gt;When I teach I try to encourage peer and group discussions.  Activities …&lt;/p&gt;</summary><content type="html">&lt;p&gt;It can be difficult to be the first student to talk in a quite classroom.  I have been experimenting with the use of white noise to raise the overall din in the room and encourage taking more quickly.&lt;/p&gt;
&lt;p&gt;When I teach I try to encourage peer and group discussions.  Activities such as think-pair-share, brainstorming and just group problem solving happen in of my classes.  I have started pumping white noise into the room during these work times. I do this more often when class size is low, there is low energy (such as after lunch) or the activity starts with a coding exercise where students work individually.  &lt;/p&gt;
&lt;p&gt;I feel that by using the white noise it encourages talking.  A quite room can
&lt;a href="//coffitivity.com/"&gt;Coffitivity.com&lt;/a&gt;&lt;/p&gt;</content><category term="Professional"></category><category term="Product Reviews"></category><category term="Teaching"></category></entry><entry><title>Remember the Milk</title><link href="https://colbrydi.github.io/remember-the-milk.html" rel="alternate"></link><published>2018-05-19T00:00:00-04:00</published><updated>2018-05-19T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-05-19:/remember-the-milk.html</id><summary type="html">&lt;p&gt;I have been a paid subscriber and dedicated customer to Remember the Milk (RTM) for many years (I have lost count). RTM is a todo list application. It is in the same category of something like Wonderlist and ToDoist (There are many others). RTM fits my personality and needs quite …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I have been a paid subscriber and dedicated customer to Remember the Milk (RTM) for many years (I have lost count). RTM is a todo list application. It is in the same category of something like Wonderlist and ToDoist (There are many others). RTM fits my personality and needs quite nicely. My workflow usese a lot of ideas from David Allen's "Getting things Done" (GTD) and I mostly utilize RTM with insparation from the following blog post:&lt;/p&gt;
&lt;p&gt;&lt;a href="blog.rememberthemilk.com/post/116665489183/guest-post-advanced-gtd-with-remember-the-milk"&gt;Remember the Milk&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Over the years I have thought about switching to one of the many different product. However, I like RTM, I like the company and it works for me.  I have my "Smart lists" setup with my basic workflows.&lt;/p&gt;
&lt;p&gt;The smart lists  allow me to "Program" RTM and make it into the app I want.  Sure there are a lot of features I would request but RTM is the tool for me.&lt;/p&gt;</content><category term="Professional"></category><category term="Product Reviews"></category><category term="Lifehacking"></category></entry><entry><title>Back to Blogging</title><link href="https://colbrydi.github.io/back-to-blogging.html" rel="alternate"></link><published>2018-05-18T00:00:00-04:00</published><updated>2018-05-18T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-05-18:/back-to-blogging.html</id><summary type="html">&lt;p&gt;I like the idea of blogging but often have difficulty in the delivery.  A few years ago I maintained a blog when I worked for the Institute for Cyber-Enabled Research (iCER) at Michigan State University (MSU). At iCER I did a lot of High Performance Computing (HPC) User support. This …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I like the idea of blogging but often have difficulty in the delivery.  A few years ago I maintained a blog when I worked for the Institute for Cyber-Enabled Research (iCER) at Michigan State University (MSU). At iCER I did a lot of High Performance Computing (HPC) User support. This involved mostly helping researchers figure out how to use advanced computing systems in their research.  I got into a habit of writing up a blog post when I learned something new or figured out a solution to a practical technical problem.  I also found the blog useful for posting slides and examples from presentations I would often make at workshops and conferences. Many of these old posts are still see a little traffic. Check them out here:&lt;/p&gt;
&lt;p&gt;&lt;a href="//wiki.hpcc.msu.edu/display/~colbrydi@msu.edu/Dirk%27s+iCER+wiki+homepage"&gt;iCER Wiki&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I also did some blogging related to my kids and our "maker" hobby.&lt;/p&gt;
&lt;p&gt;&lt;a href="//apprenticemaker.blogspot.com/"&gt;Maker Wiki&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Over the years I moved away from working directly for iCER and have not done a good job keeping up with my maker blog. I am going to try to bring the blogging habit back into my workflow.   I am currently in the middle of quite a few projects relating to education and large scale computing.&lt;/p&gt;
&lt;p&gt;I have a couple of goals for writing a blog. These include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Getting over my reluctance to share and communicate in online communities&lt;/li&gt;
&lt;li&gt;Helping me organize and be accountable for my projects&lt;/li&gt;
&lt;li&gt;Connecting with people with similar interests to my own&lt;/li&gt;
&lt;li&gt;Providing informations that others may find helpful&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To reach these goals I am going to try to get into a daily habit of writing.  I don't think I will post a blog everyday but the writing habit is important to me.&lt;/p&gt;</content><category term="Professional"></category><category term="Lifehacking"></category></entry><entry><title>Picking Blog Software</title><link href="https://colbrydi.github.io/picking-blog-software.html" rel="alternate"></link><published>2018-05-18T00:00:00-04:00</published><updated>2018-05-18T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-05-18:/picking-blog-software.html</id><summary type="html">&lt;p&gt;When I was at iCER we used confluence for our &lt;a href="//wiki.hpcc.msu.edu/display/~colbrydi@msu.edu/Dirk%27s+iCER+wiki+homepage"&gt;blogging software&lt;/a&gt; and when I did a (personal blog](//apprenticemaker.blogspot.com/) I used google blogger. On of the barriers for me getting back into blogging (besides my own personal hangups) is that I was never really satisified with either …&lt;/p&gt;</summary><content type="html">&lt;p&gt;When I was at iCER we used confluence for our &lt;a href="//wiki.hpcc.msu.edu/display/~colbrydi@msu.edu/Dirk%27s+iCER+wiki+homepage"&gt;blogging software&lt;/a&gt; and when I did a (personal blog](//apprenticemaker.blogspot.com/) I used google blogger. On of the barriers for me getting back into blogging (besides my own personal hangups) is that I was never really satisified with either solution.  I wanted to "own" my blog information and didn't really feel comfortable with advertisers making money directly from my content (this is it's own argument).  Here are some criteria for what I was looking for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Easy to edit/ add new content&lt;/li&gt;
&lt;li&gt;Easily backed up to my own computer and ported to a different system.&lt;/li&gt;
&lt;li&gt;Ability to modify and add my own tweaks/ features.&lt;/li&gt;
&lt;li&gt;Uses markdown or some similar text based file format to make it easy to use linux commands&lt;/li&gt;
&lt;li&gt;Comments&lt;/li&gt;
&lt;li&gt;Tags&lt;/li&gt;
&lt;li&gt;Usage statistics&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After some digging and talking to people I decided that I wanted to try out a static website generation tool and the obvious one that seemed to fit my interests and criteria is Pelican and a git repository.&lt;/p&gt;
&lt;p&gt;Unfortunately, Pelican was not as easy as I had hoped.  On two different occasions over the last couple of years I have made a deliberate effort to build a new website using Pelican.  It "worked" but there was some missing feature or bug that would get in my way actually making me adopt the format.  I also think that my reluctance to post things makes it harder for me to get started.&lt;/p&gt;
&lt;p&gt;In fact, as I write this blog post (in markdown) I do not actually have a blog to post it on.  My hope is that having some posts already waiting "in the hopper" will make my use of the software easier.  &lt;/p&gt;
&lt;p&gt;With the help of one of my summer students, I am making an effort to try to come up with a useable version of a blog using Pelican.  My feeling is that active open source projects are constantly evolving and therefore getting better. Maybe third time is a charm?  If Pelican still does not work out I may need to explore a different platform.  &lt;/p&gt;
&lt;p&gt;In the end I would like a workflow that not only works for my blog but also for some of other projects that need websites.  I also would like to try to make a kind of Pelican template repository that I can give to some of my peers and make it quick and easy for them to start their own website/blog.&lt;/p&gt;</content><category term="Professional"></category><category term="Blogging"></category><category term="Product Reviews"></category></entry><entry><title>Jupyter Accessibility Project</title><link href="https://colbrydi.github.io/jupyter-accessibility-project.html" rel="alternate"></link><published>2018-05-17T00:00:00-04:00</published><updated>2018-05-17T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-05-17:/jupyter-accessibility-project.html</id><summary type="html">&lt;p&gt;My university (Michigan State University) plans to scale up the use of Jupyter in our classrooms but we need to address accessibility issues before we can adopt the platform for wide scale use.  On behalf of MSU I had an external group conduct a preliminary audit of our current jupyterhub …&lt;/p&gt;</summary><content type="html">&lt;p&gt;My university (Michigan State University) plans to scale up the use of Jupyter in our classrooms but we need to address accessibility issues before we can adopt the platform for wide scale use.  On behalf of MSU I had an external group conduct a preliminary audit of our current jupyterhub server.  Based on this audit we determined that finding ways to improve Jupyter for the following user communities would be a good start.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Individuals who have some one of the more common types of colorblindness&lt;/li&gt;
&lt;li&gt;Individuals who use screen readers to help with understanding (ex. Dyslexia)&lt;/li&gt;
&lt;li&gt;Individuals with dexterity issues who cannot effectively use a mouse&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For part of my Jupyter hub project I am going to try to address these issues.  My hope is that some people are already working on these issues and I can just integrate existing plugins or patches.  However, If these communities can not be found I will try to build one myself.  I am currently talking with leaders in the Jupyter community to see the best way to build such a community.  Feel free to send me an email (colbrydi@msu.edu) and I would be happy to include you in on the conversation once I figure it out.&lt;/p&gt;</content><category term="Professional"></category><category term="Jupyter"></category><category term="Accessibility"></category></entry></feed>