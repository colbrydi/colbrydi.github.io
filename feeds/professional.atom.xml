<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Dirk's Home Page - Professional</title><link href="https://colbrydi.github.io/" rel="alternate"></link><link href="https://colbrydi.github.io/feeds/professional.atom.xml" rel="self"></link><id>https://colbrydi.github.io/</id><updated>2019-01-02T00:00:00-05:00</updated><entry><title>Quick Graphviz Tutorial</title><link href="https://colbrydi.github.io/quick-graphviz-tutorial.html" rel="alternate"></link><published>2019-01-02T00:00:00-05:00</published><updated>2019-01-02T00:00:00-05:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2019-01-02:/quick-graphviz-tutorial.html</id><summary type="html">&lt;p&gt;&lt;img alt="vim system diagram" src="//colbrydi.github.io/images/vim.jpg"&gt;&lt;/p&gt;
&lt;p&gt;This quick tutorial shows provides basic instructions for generating the above graph using &lt;a href="https://www.graphviz.org/"&gt;Graphviz&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.graphviz.org/"&gt;&lt;img alt="Graphviz" src="https://graphviz.gitlab.io/_pages/Resources/app.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you already have Anaconda installed on your system, you can quickly install graphviz using the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;conda install graphviz
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Once graphviz is installed you need to create a text file with the connections.  This …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="vim system diagram" src="//colbrydi.github.io/images/vim.jpg"&gt;&lt;/p&gt;
&lt;p&gt;This quick tutorial shows provides basic instructions for generating the above graph using &lt;a href="https://www.graphviz.org/"&gt;Graphviz&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.graphviz.org/"&gt;&lt;img alt="Graphviz" src="https://graphviz.gitlab.io/_pages/Resources/app.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you already have Anaconda installed on your system, you can quickly install graphviz using the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;conda install graphviz
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Once graphviz is installed you need to create a text file with the connections.  This file is called a dot file.  There are a lot of tutorials about the dot syntax but the basics is to make a list of nodes and their connections. For example, the following file (called test.dot) makes the figure above.  Use the &lt;code&gt;-&amp;gt;&lt;/code&gt; to indicate a directed link and a &lt;code&gt;--&lt;/code&gt; to indicate a bi-directional link:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;digraph G {
 Linux -&amp;gt; Normal  [ label=&amp;quot;vim&amp;quot; ];
 Normal  -&amp;gt; Insert  [ label=&amp;quot;i/I/a/A/o/O&amp;quot; ];
 Insert  -&amp;gt; Normal [ label=&amp;quot;Esc&amp;quot;];
 Normal  -&amp;gt; Command  [ label=&amp;quot;: (colon)&amp;quot;];
 Command  -&amp;gt; Normal  [ label=&amp;quot;w&amp;quot;];
 Command  -&amp;gt; Linux [ label=&amp;quot;q/q!/wq/x&amp;quot;]
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Once you have the file you can make an image using the following &lt;code&gt;dot&lt;/code&gt; command (dot is one of the commands installed by Graphviz)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;dot -Tpng test.dot -ovim.png
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Just for fun, I tried my dot file with the other tools provided with Graphviz (twopim, sfdp, neato, osage, fdp, circo and patchwork).  They don't look as good as dot (most of them mess up the line labels) however i could see that they may be useful (and easy) for other figures:&lt;/p&gt;
&lt;p&gt;&lt;img alt="twopim" src="//colbrydi.github.io/images/twopi.jpg"&gt;
&lt;img alt="sfdp" src="//colbrydi.github.io/images/sfdp.jpg"&gt;
&lt;img alt="neato" src="//colbrydi.github.io/images/neato.jpg"&gt;
&lt;img alt="osage" src="//colbrydi.github.io/images/osage.jpg"&gt;
&lt;img alt="fdp" src="//colbrydi.github.io/images/fdp.jpg"&gt;
&lt;img alt="circo" src="//colbrydi.github.io/images/circo.jpg"&gt;
&lt;img alt="patchwork" src="//colbrydi.github.io/images/patchwork.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Hope you find this useful.&lt;/p&gt;</content></entry><entry><title>Accessing a computer's camera inside of jupyter without installing OpenCV (Also works in Jupyterhub)</title><link href="https://colbrydi.github.io/accessing-a-computers-camera-inside-of-jupyter-without-installing-opencv-also-works-in-jupyterhub.html" rel="alternate"></link><published>2018-12-21T00:00:00-05:00</published><updated>2018-12-21T00:00:00-05:00</updated><author><name>Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-12-21:/accessing-a-computers-camera-inside-of-jupyter-without-installing-opencv-also-works-in-jupyterhub.html</id><summary type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;img src="//colbrydi.github.io/images/Camera.png"&gt;&lt;/p&gt;
&lt;p&gt;The following code lets you take pictures inside of jupyter notebooks.  It uses Javascript inside of jupyterhub to access the client computers camera and transfer images back into python.&lt;/p&gt;
&lt;p&gt;I am particularly proud of this code because of the following features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Does not require the installation of OpenCV (This can be tricky)&lt;/li&gt;</summary><content type="html">&lt;style type="text/css"&gt;/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell &gt; div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area &gt; div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area &gt; div.highlight &gt; pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the &lt;head&gt; if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev &lt;Maniac@SoftwareManiacs.Org&gt;
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area 
div.output_area 
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}



.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}






.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}








.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}


.rendered_html pre,



.rendered_html tr,
.rendered_html th,

.rendered_html td,


.rendered_html * + table {
  margin-top: 1em;
}

.rendered_html * + p {
  margin-top: 1em;
}

.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,

.rendered_html img.unconfined,

div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell &gt; div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered 
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
&lt;/style&gt;
&lt;style type="text/css"&gt;.highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */&lt;/style&gt;
&lt;style type="text/css"&gt;
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }
&lt;/style&gt;&lt;body&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;img src="//colbrydi.github.io/images/Camera.png"&gt;&lt;/p&gt;
&lt;p&gt;The following code lets you take pictures inside of jupyter notebooks.  It uses Javascript inside of jupyterhub to access the client computers camera and transfer images back into python.&lt;/p&gt;
&lt;p&gt;I am particularly proud of this code because of the following features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Does not require the installation of OpenCV (This can be tricky)&lt;/li&gt;
&lt;li&gt;Will work with Jupyterhub.  This is a big one. If you run OpenCV on Jupyterhub it will look for the camera on the server and not the client computer. Since this code runs in javascript it uses the client's computer.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some negativies to this approach:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Does not work in Jupyterlab.  This is because the default of JupyterLab does not enable javascript as a security measure.&lt;/li&gt;
&lt;li&gt;Is not fast enough to transmit video.  This is because I use Unicode to transmit the image and it can't handle enough images in a reasonable amount of time.  There may be a way to record the video inside of javascript and then transmit the entire video but I have not figured that out.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="Step-1:-Access-the-camera-in-the-Javascript"&gt;Step 1: Access the camera in the Javascript&lt;a class="anchor-link" href="#Step-1:-Access-the-camera-in-the-Javascript"&gt;&amp;#182;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;This program works in two major steps. The first step is written in javascript.  In summary, the code creates a javascript canvas and attaches the local camera.  The code also creates a simple javascript button.  WHen the user presses the button a picture is taken and the context is saved as a Unicode URL.  The information is passed back to the python kernel using the &lt;code&gt;IPython.notebook.kernel.execute&lt;/code&gt; command.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[&amp;nbsp;]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Code developed by Dirk Colbry&lt;/span&gt;
&lt;span class="c1"&gt;# This code snipit tries to read from your computer&amp;#39;s camera.  It is not fully tested so it may not work for everyone.&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;IPython.display&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;HTML&lt;/span&gt;

&lt;span class="n"&gt;main_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="s2"&gt;&amp;lt;video id=&amp;quot;video&amp;quot; width=&amp;quot;320&amp;quot; height=&amp;quot;240&amp;quot; autoplay&amp;gt;&amp;lt;/video&amp;gt;&lt;/span&gt;
&lt;span class="s2"&gt;&amp;lt;button id=&amp;quot;snap&amp;quot;&amp;gt;Snap Photo&amp;lt;/button&amp;gt;&lt;/span&gt;
&lt;span class="s2"&gt;&amp;lt;canvas id=&amp;quot;canvas&amp;quot; width=&amp;quot;320&amp;quot; height=&amp;quot;240&amp;quot;&amp;gt;&amp;lt;/canvas&amp;gt;&lt;/span&gt;

&lt;span class="s2"&gt;&amp;lt;script&amp;gt;&lt;/span&gt;
&lt;span class="s2"&gt;// Grab elements, create settings, etc.&lt;/span&gt;
&lt;span class="s2"&gt;var video = document.getElementById(&amp;#39;video&amp;#39;);&lt;/span&gt;

&lt;span class="s2"&gt;// Get access to the camera!&lt;/span&gt;
&lt;span class="s2"&gt;if(navigator.mediaDevices &amp;amp;&amp;amp; navigator.mediaDevices.getUserMedia) {&lt;/span&gt;
&lt;span class="s2"&gt;    // Not adding `{ audio: true }` since we only want video now&lt;/span&gt;
&lt;span class="s2"&gt;    navigator.mediaDevices.getUserMedia({ video: true }).then(function(stream) {&lt;/span&gt;
&lt;span class="s2"&gt;        //video.src = window.URL.createObjectURL(stream);&lt;/span&gt;
&lt;span class="s2"&gt;        //video.play();&lt;/span&gt;
&lt;span class="s2"&gt;        video.srcObject=stream;&lt;/span&gt;
&lt;span class="s2"&gt;        video.play();&lt;/span&gt;
&lt;span class="s2"&gt;    });&lt;/span&gt;
&lt;span class="s2"&gt;}&lt;/span&gt;

&lt;span class="s2"&gt;// Elements for taking the snapshot&lt;/span&gt;
&lt;span class="s2"&gt;var canvas = document.getElementById(&amp;#39;canvas&amp;#39;);&lt;/span&gt;
&lt;span class="s2"&gt;var context = canvas.getContext(&amp;#39;2d&amp;#39;);&lt;/span&gt;
&lt;span class="s2"&gt;var video = document.getElementById(&amp;#39;video&amp;#39;);&lt;/span&gt;

&lt;span class="s2"&gt;// Trigger photo take&lt;/span&gt;
&lt;span class="s2"&gt;document.getElementById(&amp;quot;snap&amp;quot;).addEventListener(&amp;quot;click&amp;quot;, function() {&lt;/span&gt;
&lt;span class="s2"&gt;	context.drawImage(video, 0, 0, 320, 240);&lt;/span&gt;
&lt;span class="s2"&gt;    var myCanvas = document.getElementById(&amp;#39;canvas&amp;#39;);&lt;/span&gt;
&lt;span class="s2"&gt;    var image = myCanvas.toDataURL(&amp;quot;image/png&amp;quot;);&lt;/span&gt;
&lt;span class="s2"&gt;    IPython.notebook.kernel.execute(&amp;quot;print(&amp;#39;testing&amp;#39;)&amp;quot;)&lt;/span&gt;
&lt;span class="s2"&gt;    IPython.notebook.kernel.execute(&amp;quot;image = &amp;#39;&amp;quot; + image + &amp;quot;&amp;#39;&amp;quot;)&lt;/span&gt;
&lt;span class="s2"&gt;});&lt;/span&gt;
&lt;span class="s2"&gt;&amp;lt;/script&amp;gt;&lt;/span&gt;

&lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;HTML&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;main_text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Step-2:-Convert-string-back-into-image"&gt;Step 2: Convert string back into image&lt;a class="anchor-link" href="#Step-2:-Convert-string-back-into-image"&gt;&amp;#182;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;We can now access the URL string from inside of python.  The following function does all of the magic to decode the base 64 bit image into an IO stream which is then passed into the &lt;code&gt;PIL.Image.open&lt;/code&gt; function.  The end result is a image in the Python Image Library (PIL) format.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[&amp;nbsp;]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;PIL&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Image&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;base64&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;io&lt;/span&gt;

&lt;span class="n"&gt;pil_im&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Image&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;io&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;BytesIO&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;base64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;b64decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])))&lt;/span&gt;
&lt;span class="n"&gt;pil_im&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Step-3:-(Optional)-Convert-PIL-image-to-Numpy-array"&gt;Step 3: (Optional) Convert PIL image to Numpy array&lt;a class="anchor-link" href="#Step-3:-(Optional)-Convert-PIL-image-to-Numpy-array"&gt;&amp;#182;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Typically I like to work with images as a 3D numpy array (row, columns, channel).  The following code just converts the PIL image into a numpy array.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="prompt input_prompt"&gt;In&amp;nbsp;[&amp;nbsp;]:&lt;/div&gt;
&lt;div class="inner_cell"&gt;
    &lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="k"&gt;matplotlib&lt;/span&gt; inline
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pylab&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="n"&gt;im3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pil_im&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;im3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;im3&lt;/span&gt;&lt;span class="p"&gt;[:,:,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;imshow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;im3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;I hope you found this example useful. Please leave a comment if you use it in your project.  I would really like to see how it is used.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dirk&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
 

&lt;/body&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['$','$'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        " linebreaks: { automatic: true, width: '95% container' }, " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;
</content><category term="Jupyter"></category></entry><entry><title>Using an X11 Virtual Frame Buffer to run GUI jobs in batch mode on the HPC.</title><link href="https://colbrydi.github.io/using-an-x11-virtual-frame-buffer-to-run-gui-jobs-in-batch-mode-on-the-hpc.html" rel="alternate"></link><published>2018-12-20T00:00:00-05:00</published><updated>2018-12-20T00:00:00-05:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-12-20:/using-an-x11-virtual-frame-buffer-to-run-gui-jobs-in-batch-mode-on-the-hpc.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="X11 Logo" hspace="10" src="//upload.wikimedia.org/wikipedia/commons/a/ab/X11.png" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;I have an example program that came with &lt;a href="http://bccd.net/"&gt;BCCD&lt;/a&gt; called Pandemic which I wanted to run on our local HPCC. Unfortunately Pandemic requires X11 to run and I would get a segmentation fault every time I ran it in the batch system.&lt;/p&gt;
&lt;p&gt;This blog post shows how I used the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="X11 Logo" hspace="10" src="//upload.wikimedia.org/wikipedia/commons/a/ab/X11.png" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;I have an example program that came with &lt;a href="http://bccd.net/"&gt;BCCD&lt;/a&gt; called Pandemic which I wanted to run on our local HPCC. Unfortunately Pandemic requires X11 to run and I would get a segmentation fault every time I ran it in the batch system.&lt;/p&gt;
&lt;p&gt;This blog post shows how I used the X11 Virtual Frame Buffer (Xvfb) to enable X11 in batch mode.  This example uses SLURM running in CentOS7.  This trick can come in really handing when you are using MATLAB to because last I checked it needed X11 to run in order to generate and save figures. This will let you do that even in batch mode.&lt;/p&gt;
&lt;p&gt;First, here is the batch script for the OpenMP version (Should work for serial jobs as well).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;
&lt;span class="c1"&gt;#SBATCH --time=00:10:00&lt;/span&gt;
&lt;span class="c1"&gt;#SBATCH --ntasks=1&lt;/span&gt;
&lt;span class="c1"&gt;#SBATCH --cpus-per-task=16&lt;/span&gt;
&lt;span class="c1"&gt;#SBATCH --mem=10G&lt;/span&gt;
&lt;span class="c1"&gt;#SBATCH --job-name Pandemic-OpenMP&lt;/span&gt;

&lt;span class="nb"&gt;cd&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;SLURM_SUBMIT_DIR&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;# Have X11 find an open display number and communicate the number&lt;/span&gt;
&lt;span class="c1"&gt;# though a temporary file to set the environment variable.&lt;/span&gt;
&lt;span class="nv"&gt;display_file&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;.tmp_display.txt
Xvfb -displayfd &lt;span class="m"&gt;1&lt;/span&gt; -auth /dev/null  &lt;span class="m"&gt;1&lt;/span&gt;&amp;gt;&lt;span class="nv"&gt;$display_file&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;&amp;gt; /dev/null &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;
sleep &lt;span class="m"&gt;5&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;DISPLAY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;:&lt;span class="sb"&gt;`&lt;/span&gt;cat &lt;span class="nv"&gt;$display_file&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;DISPLAY set to &lt;/span&gt;&lt;span class="nv"&gt;$DISPLAY&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
rm &lt;span class="nv"&gt;$display_file&lt;/span&gt;

&lt;span class="c1"&gt;# Benchmark program with different numbers of processes&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;OMP_NUM_THREADS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;16&lt;/span&gt;
&lt;span class="nb"&gt;time&lt;/span&gt; ./Pandemic.c-openmp
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;OMP_NUM_THREADS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;8&lt;/span&gt;
&lt;span class="nb"&gt;time&lt;/span&gt; ./Pandemic.c-openmp
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;OMP_NUM_THREADS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;
&lt;span class="nb"&gt;time&lt;/span&gt; ./Pandemic.c-openmp
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;OMP_NUM_THREADS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;
&lt;span class="nb"&gt;time&lt;/span&gt; ./Pandemic.c-openmp
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;OMP_NUM_THREADS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="nb"&gt;time&lt;/span&gt; ./Pandemic.c-openmp
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="k"&gt;done&lt;/span&gt;

&lt;span class="c1"&gt;# Report job statistics&lt;/span&gt;
scontrol show job &lt;span class="nv"&gt;$SLURM_JOB_ID&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And here is the job I got working with MPI. Notice it is basically the same but I need to pass the DISPLAY variable though MPI for it to work.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;
&lt;span class="c1"&gt;#SBATCH --time=00:10:00&lt;/span&gt;
&lt;span class="c1"&gt;#SBATCH --ntasks=16&lt;/span&gt;
&lt;span class="c1"&gt;#SBATCH --cpus-per-task=1&lt;/span&gt;
&lt;span class="c1"&gt;#SBATCH --mem=10G&lt;/span&gt;
&lt;span class="c1"&gt;#SBATCH --job-name Pandemic-MPI&lt;/span&gt;

&lt;span class="nb"&gt;cd&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;SLURM_SUBMIT_DIR&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
module swap GNU Intel
module load OpenMPI

&lt;span class="c1"&gt;# Have X11 find an open display number and communicate the number&lt;/span&gt;
&lt;span class="c1"&gt;# though a temporary file to set the environment variable.&lt;/span&gt;
&lt;span class="nv"&gt;display_file&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;.tmp_display.txt
Xvfb -displayfd &lt;span class="m"&gt;1&lt;/span&gt; -auth /dev/null  &lt;span class="m"&gt;1&lt;/span&gt;&amp;gt;&lt;span class="nv"&gt;$display_file&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;&amp;gt; /dev/null &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;
sleep &lt;span class="m"&gt;5&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;DISPLAY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;:&lt;span class="sb"&gt;`&lt;/span&gt;cat &lt;span class="nv"&gt;$display_file&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;DISPLAY set to &lt;/span&gt;&lt;span class="nv"&gt;$DISPLAY&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
rm &lt;span class="nv"&gt;$display_file&lt;/span&gt;

&lt;span class="c1"&gt;# Benchmark program with different numbers of processes&lt;/span&gt;
&lt;span class="nb"&gt;time&lt;/span&gt; mpirun -n &lt;span class="m"&gt;16&lt;/span&gt; -x &lt;span class="nv"&gt;DISPLAY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$HOSTNAME&lt;/span&gt;:&lt;span class="nv"&gt;$DISPLAY&lt;/span&gt; ./Pandemic.c-mpi
&lt;span class="nb"&gt;time&lt;/span&gt; mpirun -n &lt;span class="m"&gt;8&lt;/span&gt; -x &lt;span class="nv"&gt;DISPLAY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$HOSTNAME$DISPLAY&lt;/span&gt; ./Pandemic.c-mpi
&lt;span class="nb"&gt;time&lt;/span&gt; mpirun -n &lt;span class="m"&gt;4&lt;/span&gt; -x &lt;span class="nv"&gt;DISPLAY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$HOSTNAME$DISPLAY&lt;/span&gt; ./Pandemic.c-mpi
&lt;span class="nb"&gt;time&lt;/span&gt; mpirun -n &lt;span class="m"&gt;2&lt;/span&gt; -x &lt;span class="nv"&gt;DISPLAY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$HOSTNAME$DISPLAY&lt;/span&gt; ./Pandemic.c-mpi
&lt;span class="nb"&gt;time&lt;/span&gt; mpirun -n &lt;span class="m"&gt;1&lt;/span&gt; -x &lt;span class="nv"&gt;DISPLAY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$HOSTNAME$DISPLAY&lt;/span&gt; ./Pandemic.c-mpi

&lt;span class="c1"&gt;# Report job statistics&lt;/span&gt;
scontrol show job &lt;span class="nv"&gt;$SLURM_JOB_ID&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hope you find this useful.&lt;/p&gt;</content><category term="HPC"></category></entry><entry><title>How do we know what we don't know we don't know?</title><link href="https://colbrydi.github.io/how-do-we-know-what-we-dont-know-we-dont-know.html" rel="alternate"></link><published>2018-12-07T00:00:00-05:00</published><updated>2018-12-07T00:00:00-05:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-12-07:/how-do-we-know-what-we-dont-know-we-dont-know.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="Education2035" hspace="10" src="//colbrydi.github.io/images/Education2035.jpg" width="100%,"&gt;&lt;/p&gt;
&lt;p&gt;Faculty at MSU conducted a workshop to brainstorm and discuss ways we can try and foresee how education will be changed by technology in an effort to get ahead of the changes and make sure our teaching goals and values stay intact.&lt;/p&gt;
&lt;p&gt;My presentation was about the difficulty in predicting …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="Education2035" hspace="10" src="//colbrydi.github.io/images/Education2035.jpg" width="100%,"&gt;&lt;/p&gt;
&lt;p&gt;Faculty at MSU conducted a workshop to brainstorm and discuss ways we can try and foresee how education will be changed by technology in an effort to get ahead of the changes and make sure our teaching goals and values stay intact.&lt;/p&gt;
&lt;p&gt;My presentation was about the difficulty in predicting what technology will look like in 17 years.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="//colbrydi.github.io/images/20181207-Education_2035_colbrydi.pdf"&gt;Link to the Presentation Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="Presentations"></category></entry><entry><title>Emerging Technologies (FPGAs) @ 2018 ACI-REF VR</title><link href="https://colbrydi.github.io/emerging-technologies-fpgas-2018-aci-ref-vr.html" rel="alternate"></link><published>2018-08-10T00:00:00-04:00</published><updated>2018-08-10T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-08-10:/emerging-technologies-fpgas-2018-aci-ref-vr.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="Picture from Panel" hspace="10" src="//colbrydi.github.io/images/Emerging_Technologies.jpg" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;Today is the last day of the &lt;a href="http://www.oscer.ou.edu/acirefvirtres2018.php"&gt;2018 ACI-REF Virtual residency&lt;/a&gt; workshop here in Norman Ok.  It was a great week with a lot of great people.  I highly recommend the workshop for anyone in the area of Advanced Computing Instruction especially those do some Research and Education Facilitation in …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="Picture from Panel" hspace="10" src="//colbrydi.github.io/images/Emerging_Technologies.jpg" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;Today is the last day of the &lt;a href="http://www.oscer.ou.edu/acirefvirtres2018.php"&gt;2018 ACI-REF Virtual residency&lt;/a&gt; workshop here in Norman Ok.  It was a great week with a lot of great people.  I highly recommend the workshop for anyone in the area of Advanced Computing Instruction especially those do some Research and Education Facilitation in their roles.  &lt;/p&gt;
&lt;p&gt;Thank you Aaron Bergstrom (U North Dakota) for again facilitating the panel discussion on &lt;strong&gt;Emerging Technologies&lt;/strong&gt; at the . My fellow panel members included:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;David Chin, Drexel U re Hadoop/Spark/MapReduce&lt;/li&gt;
&lt;li&gt;Shawn Doughty, Tufts U re OnDemand and Jupyter/Rstudio&lt;/li&gt;
&lt;li&gt;Anita Schwartz, U Delaware re Singularity&lt;/li&gt;
&lt;li&gt;Mariya Vyushkova, U Notre Dame re Quantum Computing&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I was invited to this panel to share based on the work we are doing at the CMSE department related to FPGAs.  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Purchased 2 nodes with Altera FPGAs&lt;/li&gt;
&lt;li&gt;Started a FPGA Taskforce for interested researchers&lt;/li&gt;
&lt;li&gt;Working with a Graduate Student (Ahmed Yousif) on an independent study related to an optimization problem (function fitting) on FPGAs&lt;/li&gt;
&lt;li&gt;This fall CMSE plans to conduct a Graduate Course to benchmark and test the 7 dwarves algorithms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is a direct link to my FPGA slides:&lt;/p&gt;
&lt;p&gt;&lt;a href="//colbrydi.github.io/images/20180810_ACI_REF_VR_FPGAs.pdf"&gt;FPGA only slides&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Follow the workshop on &lt;a href="https://www.facebook.com/OUHPC/"&gt;Facebook&lt;/a&gt;&lt;/p&gt;</content><category term="Presentations"></category><category term="HPC"></category></entry><entry><title>Deciding Which Technologies to Adopt, and When @ 2018 ACI-REF VR</title><link href="https://colbrydi.github.io/deciding-which-technologies-to-adopt-and-when-2018-aci-ref-vr.html" rel="alternate"></link><published>2018-08-08T00:00:00-04:00</published><updated>2018-08-08T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-08-08:/deciding-which-technologies-to-adopt-and-when-2018-aci-ref-vr.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="Image used in presentation representing the technology adoption wave" hspace="10" src="//colbrydi.github.io/images/Wave.jpg" width="30%,"&gt;&lt;/p&gt;
&lt;p&gt;I had fun leading a discussion on &lt;strong&gt;Deciding Which Technologies to Adopt, and When&lt;/strong&gt; at the &lt;a href="http://www.oscer.ou.edu/acirefvirtres2018.php"&gt;2018 ACI-REF Virtual residency&lt;/a&gt; event in Norman Oklahoma. Since many of the participants were virtual I experimented with doing a Brainstorming exercise over zoom. We had local volunteers on typing in comments from our …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="Image used in presentation representing the technology adoption wave" hspace="10" src="//colbrydi.github.io/images/Wave.jpg" width="30%,"&gt;&lt;/p&gt;
&lt;p&gt;I had fun leading a discussion on &lt;strong&gt;Deciding Which Technologies to Adopt, and When&lt;/strong&gt; at the &lt;a href="http://www.oscer.ou.edu/acirefvirtres2018.php"&gt;2018 ACI-REF Virtual residency&lt;/a&gt; event in Norman Oklahoma. Since many of the participants were virtual I experimented with doing a Brainstorming exercise over zoom. We had local volunteers on typing in comments from our local participants and remote participants typing their comments directly into the zoom group chat.  I tried my best to use typical brainstorming techniques and repeat all of the comments so everyone could hear them. This was especially important since remote participates could not hear the local participants.&lt;/p&gt;
&lt;p&gt;See a video of the discussion here:&lt;/p&gt;
&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/HR1_OZnKqn0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;If you are interested, you can find a copy of my slides can be found here:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.oscer.ou.edu/acirefvirtres2018_talk_techadoption_colbry_20180808.pdf"&gt;PDF of Slides&lt;/a&gt;&lt;/p&gt;</content><category term="Presentations"></category><category term="HPC"></category></entry><entry><title>Teams of CI Professionals: Recruitment &amp; Retention, Management, Team-building, and Motivation Panel @ 2018 ACI-REF VR</title><link href="https://colbrydi.github.io/teams-of-ci-professionals-recruitment-retention-management-team-building-and-motivation-panel-2018-aci-ref-vr.html" rel="alternate"></link><published>2018-08-07T00:00:00-04:00</published><updated>2018-08-07T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-08-07:/teams-of-ci-professionals-recruitment-retention-management-team-building-and-motivation-panel-2018-aci-ref-vr.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="Image from Panel" hspace="10" src="//colbrydi.github.io/images/Audience.jpg" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;Thank you Aaron Bergstrom (U North Dakota) for facilitating the panel discussion on &lt;strong&gt;Teams of CI Professionals: Recruitment &amp;amp; Retention, Management, Team-building, and Motivation&lt;/strong&gt; at the &lt;a href="http://www.oscer.ou.edu/acirefvirtres2018.php"&gt;2018 ACI-REF Virtual residency&lt;/a&gt;. My fellow panel members included:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Jerry Perez, U Texas Dallas&lt;/li&gt;
&lt;li&gt;Derek Leydig, Pennsylvania State U&lt;/li&gt;
&lt;li&gt;Claire Mizumoto, U California San Diego …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="Image from Panel" hspace="10" src="//colbrydi.github.io/images/Audience.jpg" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;Thank you Aaron Bergstrom (U North Dakota) for facilitating the panel discussion on &lt;strong&gt;Teams of CI Professionals: Recruitment &amp;amp; Retention, Management, Team-building, and Motivation&lt;/strong&gt; at the &lt;a href="http://www.oscer.ou.edu/acirefvirtres2018.php"&gt;2018 ACI-REF Virtual residency&lt;/a&gt;. My fellow panel members included:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Jerry Perez, U Texas Dallas&lt;/li&gt;
&lt;li&gt;Derek Leydig, Pennsylvania State U&lt;/li&gt;
&lt;li&gt;Claire Mizumoto, U California San Diego&lt;/li&gt;
&lt;li&gt;Robert Ping, Indiana U&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I thought the panel went really well with both remote and local panelist and both local and remote participants. We discussed all types of topics related to finding good people, mentoring students, professional development and institutional politics.  Go to the  &lt;a href="http://www.oscer.ou.edu/acirefvirtres2018.php"&gt;2018 ACI-REF Virtual residency&lt;/a&gt; and they should link to a video if you want to watch.&lt;/p&gt;
&lt;p&gt;Follow the workshop on &lt;a href="https://www.facebook.com/OUHPC/"&gt;Facebook&lt;/a&gt;&lt;/p&gt;</content><category term="Presentations"></category><category term="HPC"></category></entry><entry><title>Leading and Listening in Complex CI Conversations @ 2018 ACI-REF VR</title><link href="https://colbrydi.github.io/leading-and-listening-in-complex-ci-conversations-2018-aci-ref-vr.html" rel="alternate"></link><published>2018-08-06T00:00:00-04:00</published><updated>2018-08-06T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-08-06:/leading-and-listening-in-complex-ci-conversations-2018-aci-ref-vr.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="Graphical Depiction of two people having a complex conversation" hspace="10" src="//www.leamcleod.com/wp-content/uploads/2014/06/Communication-challenge.jpg" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;I just got done trying out our latest CyberAmbassador Curriculum developed specifically for the  &lt;a href="http://www.oscer.ou.edu/acirefvirtres2018.php"&gt;2018 ACI-REF Virtual residency&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We had some growing pains related to getting zoom breakout rooms working with a large group of people calling in.  Some didn't have working mics, others work in a group room and …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="Graphical Depiction of two people having a complex conversation" hspace="10" src="//www.leamcleod.com/wp-content/uploads/2014/06/Communication-challenge.jpg" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;I just got done trying out our latest CyberAmbassador Curriculum developed specifically for the  &lt;a href="http://www.oscer.ou.edu/acirefvirtres2018.php"&gt;2018 ACI-REF Virtual residency&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We had some growing pains related to getting zoom breakout rooms working with a large group of people calling in.  Some didn't have working mics, others work in a group room and could not talk, others just didn't feel like participating.  Overall though I think it worked out well especially during the second breakout when we had a little more time.  Check out the slides on the CyberAmbassador website:&lt;/p&gt;
&lt;p&gt;&lt;a href="//colbrydi.github.io/cyberambassadors/practice-examples-for-complex-communication.html"&gt;Link to ACI-REF 2018 Complex Communications Files&lt;/a&gt;&lt;/p&gt;</content><category term="Presentations"></category></entry><entry><title>Progress Update on the Development and Implementation of the Advanced CI-REF VR Program</title><link href="https://colbrydi.github.io/progress-update-on-the-development-and-implementation-of-the-advanced-ci-ref-vr-program.html" rel="alternate"></link><published>2018-07-25T00:00:00-04:00</published><updated>2018-07-25T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-07-25:/progress-update-on-the-development-and-implementation-of-the-advanced-ci-ref-vr-program.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="ACI-Ref Buiding Picture" hspace="10" src="https://aciref.org/wp-content/uploads/2017/09/FullSizeRender-2-1024x765.jpg" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;Henry Neeman did a great job presenting our paper on &lt;a href="https://pearc18.conference-program.com/?page_id=10&amp;amp;id=pap144&amp;amp;sess=sess164"&gt;Progress Update for the CI-REF VR Program&lt;/a&gt; at &lt;a href="//www.pearc18.pearc.org/"&gt;PEARC18&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Writing of this paper was truly a unique experience for me. The entire paper was written virtually over weekly video conference meetings and included the thirteen sited (maximum) authors and I …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="ACI-Ref Buiding Picture" hspace="10" src="https://aciref.org/wp-content/uploads/2017/09/FullSizeRender-2-1024x765.jpg" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;Henry Neeman did a great job presenting our paper on &lt;a href="https://pearc18.conference-program.com/?page_id=10&amp;amp;id=pap144&amp;amp;sess=sess164"&gt;Progress Update for the CI-REF VR Program&lt;/a&gt; at &lt;a href="//www.pearc18.pearc.org/"&gt;PEARC18&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Writing of this paper was truly a unique experience for me. The entire paper was written virtually over weekly video conference meetings and included the thirteen sited (maximum) authors and I think dozens of other contributors.  Henry does an amazing job coordinating this army of people, soliciting their input and giving them opportunities to learn.   I am looking forward to the ACI-Ref Virtual Residency workshop in a couple of weeks so I can see everyone again in person.&lt;/p&gt;
&lt;p&gt;Below is a summary:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; Description: &lt;/strong&gt;
Cyberinfrastructure facilitation -- working directly with researchers to advance the computing-intensive and data-intensive aspects of their investigations, especially via large-scale and advanced computing -- has emerged as a crucial component of research computing processes. However, because no national formal education curriculum exists to cultivate the needed workforce, informal education is the most viable approach. The Advanced Cyberinfrastructure Research and Education Facilitator (ACI-REF) Virtual Residency (VR) program, in operation since summer 2015, is a national informal education program that trains Cyberinfrastructure (CI) Facilitators on effective methods for serving their research and education constituents, especially focusing on professional (soft) skills (because much of the technical content that facilitators need is available via other opportunities). The VR consists primarily of (a) summer weeklong intensive workshops that provide both content and experiences in facilitation, (b) biweekly conference calls that expand upon both the kinds of topics introduced in the workshops and additional content and experiences, (c) meetings at national conferences and (d) a grant proposal writing apprenticeship. Future plans focus on extending the VR model to intermediate and advanced levels, as well as disseminating a "train-the-trainers-of-trainers" approach to teaching other organizations to conduct their own VR activities within their own CI Facilitator communities, in order to expand the VR's scale, scope, and reach. The VR program and its offshoots have already served 364 CI professionals at 188 institutions across the US and internationally. Virtual Residents are positioned to advance to the intermediate level and beyond, and ultimately to become institutional and national CI leaders.&lt;/p&gt;</content><category term="Presentations"></category><category term="Publication"></category></entry><entry><title>Fitting iCE-Cube Neutrino Path models using Neural Networks</title><link href="https://colbrydi.github.io/fitting-ice-cube-neutrino-path-models-using-neural-networks.html" rel="alternate"></link><published>2018-07-24T00:00:00-04:00</published><updated>2018-07-24T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-07-24:/fitting-ice-cube-neutrino-path-models-using-neural-networks.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="Mohammed and his poster" hspace="10" src="//colbrydi.github.io/images/Mohammed.jpg" width="30%,"&gt;&lt;/p&gt;
&lt;p&gt;This summer Mohammed Salih worked with me as part of the Engineering &lt;a href="https://www.egr.msu.edu/graduate/ensure"&gt;ENSURE&lt;/a&gt; Program.  He presented his work with Jessie Micallef and me as a poster at &lt;a href="https://urca.msu.edu/mid-sure"&gt;MidSURE&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Poster Abstract&lt;/strong&gt;: Neutrinos are small particles with a mass close to zero. It’s rare interaction with normal matter makes it difficult …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="Mohammed and his poster" hspace="10" src="//colbrydi.github.io/images/Mohammed.jpg" width="30%,"&gt;&lt;/p&gt;
&lt;p&gt;This summer Mohammed Salih worked with me as part of the Engineering &lt;a href="https://www.egr.msu.edu/graduate/ensure"&gt;ENSURE&lt;/a&gt; Program.  He presented his work with Jessie Micallef and me as a poster at &lt;a href="https://urca.msu.edu/mid-sure"&gt;MidSURE&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Poster Abstract&lt;/strong&gt;: Neutrinos are small particles with a mass close to zero. It’s rare interaction with normal matter makes it difficult to determine its precise mass. Researchers in the the Ice Cube project are working on determining neutrinos precise mass. The Ice Cube project is a sub particle detector in the south pole that records the interactions of neutrinos. The detector is a 150 KM grid with a hexagonal shape 1 km under Ice. Each hole in the grid has a 1 km string, each with about 60 light sensors. Since a neutrino is faster than the speed of light in ice, it emits light in ice. Therefore, the emitted photon is detected by the sensors in the detector. Using the measurements from the detector, we can determine angle, origin, speed, and energy using analytics and machine learning. The interest in this project is to identify neutrinos have come from the center of the galaxy. To check if machine learning is an appropriate method for this project, we create a virtual ice cube simulator using phantom data generation method to simplify and control the data set. Then we use machine learning on this data to determine if it is an appropriate method for this problem.&lt;/p&gt;</content><category term="Presentations"></category></entry><entry><title>Campus Champions 101 Panel at PEARC18</title><link href="https://colbrydi.github.io/campus-champions-101-panel-at-pearc18.html" rel="alternate"></link><published>2018-07-23T00:00:00-04:00</published><updated>2018-07-23T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-07-23:/campus-champions-101-panel-at-pearc18.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="Campus Champion Logo Logo" hspace="10" src="https://www.xsede.org/wwwteragrid/archive/image/image_gallery%3Fuuid=554fecca-1a37-44d0-826f-afad9470153d&amp;amp;groupId=298192&amp;amp;t=1291845274821" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;I had an opportunity to participate on the "Researcher Facing" Panel as part of the  &lt;a href="https://www.xsede.org/community-engagement/campus-champions"&gt;Campus Champion 101&lt;/a&gt; workshop at &lt;a href="https://www.pearc18.pearc.org/"&gt;PEARC18&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;&lt;a href="//docs.google.com/document/d/1OsOCUOeWAk1IfJzEi8LuO5YnIiKkU2AO-cxzY0F0gzk/edit"&gt;Link to Notes For the Panel can be found  here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://pearc18.conference-program.com/?page_id=10&amp;amp;id=work108&amp;amp;sess=sess123"&gt;Campus Champions 101 workshop&lt;/a&gt; explores campus research computing roles. The workshop builds on the Campus Champions’ history and …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="Campus Champion Logo Logo" hspace="10" src="https://www.xsede.org/wwwteragrid/archive/image/image_gallery%3Fuuid=554fecca-1a37-44d0-826f-afad9470153d&amp;amp;groupId=298192&amp;amp;t=1291845274821" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;I had an opportunity to participate on the "Researcher Facing" Panel as part of the  &lt;a href="https://www.xsede.org/community-engagement/campus-champions"&gt;Campus Champion 101&lt;/a&gt; workshop at &lt;a href="https://www.pearc18.pearc.org/"&gt;PEARC18&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;&lt;a href="//docs.google.com/document/d/1OsOCUOeWAk1IfJzEi8LuO5YnIiKkU2AO-cxzY0F0gzk/edit"&gt;Link to Notes For the Panel can be found  here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://pearc18.conference-program.com/?page_id=10&amp;amp;id=work108&amp;amp;sess=sess123"&gt;Campus Champions 101 workshop&lt;/a&gt; explores campus research computing roles. The workshop builds on the Campus Champions’ history and leverages the recent Research Computing and Data Professionals Job Elements and Career Guide that was developed by the March 2018 NSF-sponsored Campus Research Computing Consortium (CaRCC) workshop. Opening sessions will cover (a) the Cyberinfrastructure ecosystem and (b) research computing roles and responsibilities, introducing four broad job families: researcher-facing roles, systems-facing roles, sponsor/stakeholder-facing roles, and software/data-facing roles. Short talks, panels and roundtables will cover three of these four roles: researcher-facing, sponsor/stakeholder-facing, and systems-facing.&lt;/p&gt;</content><category term="Presentations"></category></entry><entry><title>Bringing Professional Skills Training to CI - PEARC18 Birds of a Feather (BOF)</title><link href="https://colbrydi.github.io/bringing-professional-skills-training-to-ci-pearc18-birds-of-a-feather-bof.html" rel="alternate"></link><published>2018-07-22T00:00:00-04:00</published><updated>2018-07-22T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-07-22:/bringing-professional-skills-training-to-ci-pearc18-birds-of-a-feather-bof.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="PEARC18 Logo" hspace="10" src="http://insidehpc.com/wp-content/uploads/2017/10/pearc18.jpg" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href="//colbrydi.github.io/cyberambassadors"&gt;CyberAmbassador&lt;/a&gt;  a Birds of a Feather Event at the 2018 PEARC Conference. Please Join us on Wednesday, July 25th from 5pm - 6pm.  More information can be found here:&lt;/p&gt;
&lt;p&gt;&lt;a href="//pearc18.conference-program.com/?page_id=10&amp;amp;id=bof122&amp;amp;sess=sess203"&gt;Link to BOF Schedule&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; Description: &lt;/strong&gt;
A number of professional skills training programs and resources have been developed in recent years, in …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="PEARC18 Logo" hspace="10" src="http://insidehpc.com/wp-content/uploads/2017/10/pearc18.jpg" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href="//colbrydi.github.io/cyberambassadors"&gt;CyberAmbassador&lt;/a&gt;  a Birds of a Feather Event at the 2018 PEARC Conference. Please Join us on Wednesday, July 25th from 5pm - 6pm.  More information can be found here:&lt;/p&gt;
&lt;p&gt;&lt;a href="//pearc18.conference-program.com/?page_id=10&amp;amp;id=bof122&amp;amp;sess=sess203"&gt;Link to BOF Schedule&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; Description: &lt;/strong&gt;
A number of professional skills training programs and resources have been developed in recent years, in part due to the efforts of the NSF CyberTraining Initiative. The goal of this BOF is to bring these groups together and explore ways to share information and coordinate efforts.&lt;/p&gt;
&lt;p&gt;As the integration of CI in research continues, CI Professionals find themselves tackling problems and consulting on projects that are increasingly complex and collaborative. In order to respond to these various requests, CI Professionals need both the expertise to solve computational challenges and the professional skills to work effectively with individuals and teams who have diverse backgrounds, experiences, and goals.&lt;/p&gt;
&lt;p&gt;The organizers of this BOF will facilitate conversations and brainstorming activities within this interactive session, with the goal of identifying opportunities to build on each other’s success and develop ongoing collaborations. For example, authors of open-source professional skills curricula might meet experienced facilitators with an interest in bringing their content to new audiences. Or content developers might identify gaps in available resources and develop new partnerships to address these needs.&lt;/p&gt;
&lt;p&gt;This BOF is proposed by a team that has received NSF CyberTraining funds to develop open-source, professional skills training in communication, teamwork and leadership for CI Professionals along with a “train the trainers” module to facilitate national access to these materials.&lt;/p&gt;</content><category term="Presentations"></category></entry><entry><title>Pelican Github.io Tutorial</title><link href="https://colbrydi.github.io/pelican-githubio-tutorial.html" rel="alternate"></link><published>2018-07-17T00:00:00-04:00</published><updated>2018-07-17T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-07-17:/pelican-githubio-tutorial.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="Pelican Github.io  Logo" hspace="10" src="//docs.google.com/a/msu.edu/drawings/d/slwvmwORPg9obcema4qeYEg/image?parent=e/2PACX-1vRGU8icBbrWq1sHjWR3oDeCjeVVY_xgl2-aq1T3iTFxFMYiBdrv73kwax9A-P4pXXV_Wy6RwVtcG1Cz&amp;amp;rev=6&amp;amp;h=200&amp;amp;w=182&amp;amp;ac=1" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;My student's and I figured out how to use &lt;a href="https://blog.getpelican.com/"&gt;Pelican&lt;/a&gt; with &lt;a href="https://pages.github.com/"&gt;Github.io&lt;/a&gt; pages to create some websites for work.  We tried to type up the instructions as a tutorial and build a pelican template.  Here is a link to the tutorial:&lt;/p&gt;
&lt;p&gt;&lt;a href="//colbrydi.github.io/msupelican"&gt;Pelican / Github.io Tutorial&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Some of our websites …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="Pelican Github.io  Logo" hspace="10" src="//docs.google.com/a/msu.edu/drawings/d/slwvmwORPg9obcema4qeYEg/image?parent=e/2PACX-1vRGU8icBbrWq1sHjWR3oDeCjeVVY_xgl2-aq1T3iTFxFMYiBdrv73kwax9A-P4pXXV_Wy6RwVtcG1Cz&amp;amp;rev=6&amp;amp;h=200&amp;amp;w=182&amp;amp;ac=1" width="20%,"&gt;&lt;/p&gt;
&lt;p&gt;My student's and I figured out how to use &lt;a href="https://blog.getpelican.com/"&gt;Pelican&lt;/a&gt; with &lt;a href="https://pages.github.com/"&gt;Github.io&lt;/a&gt; pages to create some websites for work.  We tried to type up the instructions as a tutorial and build a pelican template.  Here is a link to the tutorial:&lt;/p&gt;
&lt;p&gt;&lt;a href="//colbrydi.github.io/msupelican"&gt;Pelican / Github.io Tutorial&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Some of our websites currently using this method of publishing include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="//colbrydi.github.io"&gt;http://colbrydi.github.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="//nolanfeeny.github.io/"&gt;http://nolanfeeny.github.io/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="//colbrydi.github.io/msupelican"&gt;http://colbrydi.github.io/msupelican&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="//colbrydi.github.io/cyberambassadors"&gt;http://colbrydi.github.io/cyberambassadors&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Feel free to comment below (or email me) if you have any questions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; Dirk &lt;/strong&gt;&lt;/p&gt;</content></entry><entry><title>Installing RStudio on the MSU HPCC</title><link href="https://colbrydi.github.io/installing-rstudio-on-the-msu-hpcc.html" rel="alternate"></link><published>2018-07-06T00:00:00-04:00</published><updated>2018-07-06T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-07-06:/installing-rstudio-on-the-msu-hpcc.html</id><summary type="html">&lt;p&gt;&lt;img alt="Rstudio" src="//www.rstudio.com/wp-content/uploads/2016/09/RStudio-Logo-Blue-Gray-250.png"&gt;&lt;/p&gt;
&lt;p&gt;These instructions are for installing RStudio on the HPCC. RStudio provides a variety of installers on their website &lt;a href="https://www.rstudio.com/products/rstudio/download2/"&gt;https://www.rstudio.com/products/rstudio/download2/&lt;/a&gt;. However, the HPCC uses an older version of Linux and the precompiled binaries are not compatible.  Trying to install RStudio from the source code is …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="Rstudio" src="//www.rstudio.com/wp-content/uploads/2016/09/RStudio-Logo-Blue-Gray-250.png"&gt;&lt;/p&gt;
&lt;p&gt;These instructions are for installing RStudio on the HPCC. RStudio provides a variety of installers on their website &lt;a href="https://www.rstudio.com/products/rstudio/download2/"&gt;https://www.rstudio.com/products/rstudio/download2/&lt;/a&gt;. However, the HPCC uses an older version of Linux and the precompiled binaries are not compatible.  Trying to install RStudio from the source code is an option but is also difficult due to the large numbers of libraries and compile dependancies.  I basically gave up trying to install RStudio on until I realized that a version is included as an option in Anaconda.  The following instructions show how to install RStudio using Anaconda.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Step 0:&lt;/strong&gt; Connect to the HPC.&lt;/h2&gt;
&lt;p&gt;Use ssh to connect to the HPCC and make sure you have a working X11 server (ex. MobaXterm on windows or XQuarts on Mac).  More information about X11 can be found here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="//wiki.hpcc.msu.edu/display/hpccdocs/Installing+an+X-server+on+Windows"&gt;Old HPCC Windows instructions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://wiki.hpcc.msu.edu/display/hpccdocs/Installing+an+X-server++for+Macs"&gt;Old HPCC Mac Instructions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;strong&gt;Step 1:&lt;/strong&gt; Download the Linux Anaconda installers&lt;/h2&gt;
&lt;p&gt;Find the latest Linux installer on the &lt;a href="//www.anaconda.com/download/#linux"&gt;Anaconda website&lt;/a&gt;. Right click on the download button for version 3.x and select "Copy Link". Use the &lt;code&gt;wget&lt;/code&gt; command on the hpcc to download the script file by typing wget and then pasting the url. For Example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;wget https://repo.anaconda.com/archive/Anaconda3-5.2.0-Linux-x86_64.sh
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;&lt;strong&gt;Step 2:&lt;/strong&gt; Install anaconda using the defaults&lt;/h2&gt;
&lt;p&gt;Run the downloaded script in bash using the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;bash ./Anaconda3-5.2.0-Linux-x86_64.sh
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The last question will ask you to add the anaconda folder to your bashrc file. Say yes...&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Step 3:&lt;/strong&gt; Install RStudio&lt;/h2&gt;
&lt;p&gt;Use the conda install command to install RStudio.  Note you may need to run &lt;code&gt;source ~/.bashrc&lt;/code&gt; first to update your path:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;conda install rstudio
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That should be it, RStudio is now installed in your home directory on the HPCC.  The only other thing you will need is a X11 server.  Assuming you have connected to the hpcc with an X11 connection you can run rstudio from the command line by typing:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;rstudio
&lt;/pre&gt;&lt;/div&gt;</content><category term="HPC"></category></entry><entry><title>Managing Inconsistent Runtimes on the HPCC</title><link href="https://colbrydi.github.io/managing-inconsistent-runtimes-on-the-hpcc.html" rel="alternate"></link><published>2018-06-29T00:00:00-04:00</published><updated>2018-06-29T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-06-29:/managing-inconsistent-runtimes-on-the-hpcc.html</id><summary type="html">&lt;p&gt;One of our postdocs stopped by my office today to talk about a problem with inconsistant runtimes on our &lt;a href="//icer.msu.edu"&gt;HPCC&lt;/a&gt;.  This user is running a lot of jobs with 512 cores (current cpu limit is 520).  The problem is that it is really difficult for the user to estimate the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;One of our postdocs stopped by my office today to talk about a problem with inconsistant runtimes on our &lt;a href="//icer.msu.edu"&gt;HPCC&lt;/a&gt;.  This user is running a lot of jobs with 512 cores (current cpu limit is 520).  The problem is that it is really difficult for the user to estimate the walltimes. There is a 2x difference in walltimes on the HPCC.  The code has been tested on other large scale systems with much less variation. The user would prefer more consistent runtimes and did not mind waiting in the queue (although less queue time is better).  &lt;/p&gt;
&lt;p&gt;The problem is that there are many things that can impact the runtime of a job. The HPCC runs at over 95% utilization most of the time so many of the resources are in contention.  Without additional information, my best guess is that the bottleneck is MPI communication over the high speed network. If this is the case, I hypothesize that moving more processes to the same nodes (instead of spread across the cluster) will help reduce network competition with other users and result in more consistent walltimes. Here are some things I suggested the user try:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Open a ticket with iCER and see if you can set up a consulting appointment. They may be able to get much better idea about what resources are in contention and causing the bottleneck: &lt;a href="https://contact.icer.msu.edu/contact"&gt;https://contact.icer.msu.edu/contact&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Add “qstat -f ${PBS_JOBID}” to the end of the jobscript.  This will provide some stats that may help us understand differences between jobs that run fast and slow.   &lt;/li&gt;
&lt;li&gt;Try different core and node ratios (ex. nodes=128:ppn=4, nodes=64:ppn=8, nodes=32:ppn=8 etc.). Although increasing the ppn will likely make queue times longer, i believe the overall runtime will be more consistent.&lt;/li&gt;
&lt;li&gt;Start the process to get DOE and XSEDE allocations.  Create XSEDE Portal account here: &lt;a href="https://portal.xsede.org/"&gt;https://portal.xsede.org/&lt;/a&gt; and send me your login name when you get it so we can add you to the MSU campus champion account.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Anyone else have a similar problem?  Other suggestions that I may have missed?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; Dirk &lt;/strong&gt;&lt;/p&gt;</content><category term="HPC"></category></entry><entry><title>Getting dlvr.it to work with Pelican generated website</title><link href="https://colbrydi.github.io/getting-dlvrit-to-work-with-pelican-generated-website.html" rel="alternate"></link><published>2018-06-28T14:00:00-04:00</published><updated>2018-06-28T14:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-06-28:/getting-dlvrit-to-work-with-pelican-generated-website.html</id><summary type="html">&lt;p&gt;Back when I worked for &lt;a href="//icer.msu.edi"&gt;iCER&lt;/a&gt; I had my blog set up to automatically Tweet when I posted something new using a service called Twitter Feed. Unfortunately, Twitter Feed is no longer around and their website recommended &lt;a href="//dlvr.it"&gt;dlvr.it&lt;/a&gt; as an alternative.  &lt;/p&gt;
&lt;p&gt;So far it was fairly strait forward to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Back when I worked for &lt;a href="//icer.msu.edi"&gt;iCER&lt;/a&gt; I had my blog set up to automatically Tweet when I posted something new using a service called Twitter Feed. Unfortunately, Twitter Feed is no longer around and their website recommended &lt;a href="//dlvr.it"&gt;dlvr.it&lt;/a&gt; as an alternative.  &lt;/p&gt;
&lt;p&gt;So far it was fairly strait forward to set up an account and I followed the menus to connect my &lt;a href="//docs.getpelican.com/en/3.6.3/"&gt;Pelican&lt;/a&gt; RSS feed to my &lt;a href="//twitter.com/colbrydi"&gt;Titter&lt;/a&gt; account. At first it didn't seem to do anything but then I noticed a message that said something like "Last checked 56 seconds ago" and I went back to my Twitter account and all of my blog posts had been tweeted.  Which is what I wanted so Yeah!&lt;/p&gt;
&lt;p&gt;However, there were a lot of options that I didn't understand.  For example, I thought it would only tweet the latest blog post.  It didn't, it tweeted them all. Which is fine, this is where I wanted to go but I was hoping to test it first before blasting all of my twitter followers (I do not think I have many).  &lt;/p&gt;
&lt;p&gt;The second problem was that it only tweeted the title and the URL which is not very detailed. I don't want to everyone to be required to go to my blog post.  I found an option to also include the body of the post.  We will see if that does anything.  &lt;/p&gt;
&lt;p&gt;I plan to use this post as a test.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dirk&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update 1:&lt;/strong&gt; There was a setting in dlvr.it that I turned on to "Post Body".  This let more come though the twitter feed and nicely includes an image.  This makes the behavior act as expected so I am really excited.  Oddly, this particular post is not seen on Twitter.  This is because I went over the 10 post limit on dlvr.it.   I am going to change the post date to today and see if that helps things out.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update 2:&lt;/strong&gt; Changing the date in the post didn't seem to trigger dlvr.it to post this message on twitter. I am now changing the filename inside of pelican to see if that changes the RSS feed enough to make dlvr.it think this is a new post.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update 3:&lt;/strong&gt; Changing the pelican filename didn't do anything either. I looked though the RSS feed and now I think maybe changing the post title will make a difference.&lt;/p&gt;</content><category term="Blogging"></category><category term="Product Reviews"></category></entry><entry><title>Ensure Talk - An Engineers Autobiography</title><link href="https://colbrydi.github.io/ensure-talk-an-engineers-autobiography.html" rel="alternate"></link><published>2018-06-27T00:00:00-04:00</published><updated>2018-06-27T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-06-27:/ensure-talk-an-engineers-autobiography.html</id><summary type="html">&lt;p&gt;&lt;img alt="EnSURE Logo" src="//www.egr.msu.edu/graduate/sites/default/files/content/ensure_logo.jpg"&gt;&lt;/p&gt;
&lt;p&gt;I gave an autobiographical talk today to the &lt;a href="//www.egr.msu.edu/graduate/ensure"&gt;EnSURE&lt;/a&gt; (Engineering Summer Undergraduate Research Experience) students. I have given this talk a few times and it is noticeably different that most of my presentations because the EnSURE organizers asked me to talk about myself and how I got where I am …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="EnSURE Logo" src="//www.egr.msu.edu/graduate/sites/default/files/content/ensure_logo.jpg"&gt;&lt;/p&gt;
&lt;p&gt;I gave an autobiographical talk today to the &lt;a href="//www.egr.msu.edu/graduate/ensure"&gt;EnSURE&lt;/a&gt; (Engineering Summer Undergraduate Research Experience) students. I have given this talk a few times and it is noticeably different that most of my presentations because the EnSURE organizers asked me to talk about myself and how I got where I am (instead of research or teaching).  The first time I gave this talk it was really awkward.  However, now I think it is kind of fun to tell stories about the choices I made throughout school and my carrier.  I get a lot of questions when I am done so I like to think the student's enjoyed the talk as well.  Here are a copy of my slides:&lt;/p&gt;
&lt;p&gt;&lt;a href="./Images/20180628_An_Engineers_Autobiography.pdf"&gt;0180628_An_Engineers_Autobiography.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; Dirk &lt;/strong&gt;&lt;/p&gt;</content><category term="Presentations"></category></entry><entry><title>Commit Early and Often</title><link href="https://colbrydi.github.io/commit-early-and-often.html" rel="alternate"></link><published>2018-06-26T12:00:00-04:00</published><updated>2018-06-26T12:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-06-26:/commit-early-and-often.html</id><summary type="html">&lt;p&gt;&lt;strong&gt;Ugh! Rookie mistake!&lt;/strong&gt;  I just spent all morning working on my website and blog.  I was really happy with the improvements. I was making some modifications to the Makefile in the pelican folder to streamline my workflow when... all of my files disappeared.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rookie Mistake #1:&lt;/strong&gt; I unintentionally did a …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;Ugh! Rookie mistake!&lt;/strong&gt;  I just spent all morning working on my website and blog.  I was really happy with the improvements. I was making some modifications to the Makefile in the pelican folder to streamline my workflow when... all of my files disappeared.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rookie Mistake #1:&lt;/strong&gt; I unintentionally did a &lt;code&gt;rm -rf *&lt;/code&gt; in the wrong folder and lost of of my work.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rookie Mistake #2:&lt;/strong&gt; I had not committed any of my changes to the repository.  All was lost.  &lt;/p&gt;
&lt;p&gt;Sigh. Now I need to try to go back and remember what I did all morning.  &lt;/p&gt;
&lt;p&gt;Lessons relearned:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Commit early and Often&lt;/li&gt;
&lt;li&gt;Be respectful of &lt;code&gt;rm -rf *&lt;/code&gt; especially when it is in a &lt;code&gt;Makefile&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt; Dirk &lt;/strong&gt;&lt;/p&gt;</content><category term="Blogging"></category><category term="Pelican"></category></entry><entry><title>Planning a new Course</title><link href="https://colbrydi.github.io/planning-a-new-course.html" rel="alternate"></link><published>2018-06-10T00:00:00-04:00</published><updated>2018-06-10T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-06-10:/planning-a-new-course.html</id><summary type="html">&lt;p&gt;This post describes a technique I use to plan an organize a course from scratch.  I learned this technique from Dr. Brian O'Shea.  &lt;/p&gt;
&lt;p&gt;At Michigan State University (MSU) my official title is curriculum specialist.  I have the unique opportunity to help develop entirely new courses for a brand new department …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This post describes a technique I use to plan an organize a course from scratch.  I learned this technique from Dr. Brian O'Shea.  &lt;/p&gt;
&lt;p&gt;At Michigan State University (MSU) my official title is curriculum specialist.  I have the unique opportunity to help develop entirely new courses for a brand new department (Computational Mathematics, Science and Engineering CMSE, EST 2015).  &lt;/p&gt;
&lt;p&gt;My colleague (Dr. Brian O'Shea) showed me a nice trick to organize my semester and brainstorm ideas to do a better job with backward design and matching up my lessons to my learning goals.  I make a grid of 3 rows with 5 columns on a whiteboard.  Each box represents one week of the semester (15 total).  I then use post-it notes to write down ideas and place them on the board.  This is a brainstorming stage where all ideas are equal.  If I do this early enough I can leave the board up and move the sticky notes around as I think about my learning goals.&lt;/p&gt;
&lt;p&gt;&lt;img alt="MarkerBoard Grid" src="./Images/markdown-img-paste-20180610141148377.png"&gt;&lt;/p&gt;
&lt;p&gt;I recently moved away from the whiteboard and use a blank wall in my office. I created the grid with painters tape. This leaves my whiteboard open for other ideas and lets me put up a board really early. For example, it is June and I have a board up for my Spring Course on Parallel programming.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Painters Tape Wall" src="./Images/markdown-img-paste-20180610140831494.png"&gt;&lt;/p&gt;
&lt;p&gt;Since I have been desinging many courses I may just leave the painters tape up.  &lt;/p&gt;</content><category term="Teaching"></category></entry><entry><title>Spark mail</title><link href="https://colbrydi.github.io/spark-mail.html" rel="alternate"></link><published>2018-06-06T00:00:00-04:00</published><updated>2018-06-06T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-06-06:/spark-mail.html</id><summary type="html">&lt;p&gt;&lt;img align="right," alt="Spark Logo" hspace="10" src="//sparkmailapp.com/img/spark2/common/spark.svg" width="20%,"&gt;
I am weird that I like email.  It is my preferred form of communication on projects (maybe I am just getting old).  I trust that I will get to my email and that I will not loose things.  I realize that this trust is often not true but it is …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img align="right," alt="Spark Logo" hspace="10" src="//sparkmailapp.com/img/spark2/common/spark.svg" width="20%,"&gt;
I am weird that I like email.  It is my preferred form of communication on projects (maybe I am just getting old).  I trust that I will get to my email and that I will not loose things.  I realize that this trust is often not true but it is true enough for me to keep productive. For the longest time Gmail was my favorite email application. However, work changed policy from "we highly recommend you don't use Gmail" to "don't use gmail".  So I chose to switch to the university Office 365 accounts.  &lt;/p&gt;
&lt;p&gt;I tried the built-in Mac mail program.  It didn't thread my email the way I prefer.  I also tried outlook which had its own problems.  I don't really feel like bashing this software, it just didn't work in a way that fit my Gmail workflow.&lt;/p&gt;
&lt;p&gt;As I move into a new laptop I stubbled across the spark email client. About three weeks into using it I am very satisfied. The laptop and phone versions work nicely together. I really like having both my personal Gmail account and work accounts connected in one application.  There are a lot of things I like but probably the best is that since using Spark I have gotten my inbox to zero almost every day.  This is big news. I am a big fan of emptying my inbox but this is often a challenge.  I like the fact that Spark will allow me to show badges with the number of messages in my inbox instead of the number of unread messages.  For some reason this is a real motivator for getting my email where they need to be. It also helps me keep my Gmail clean which is mostly news feeds, advertisements, etc.  &lt;/p&gt;</content><category term="Product Reviews"></category><category term="Lifehacking"></category></entry><entry><title>Inverse Problems Seminar</title><link href="https://colbrydi.github.io/inverse-problems-seminar.html" rel="alternate"></link><published>2018-06-04T00:00:00-04:00</published><updated>2018-06-04T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-06-04:/inverse-problems-seminar.html</id><summary type="html">&lt;p&gt;I was invited to give a talk at the inverse seminars symposium:&lt;/p&gt;
&lt;p&gt;&lt;a href="//inverseproblems2018.org/"&gt;https://inverseproblems2018.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;At first I was a little nervous since I don't consider myself an expert in inverse problems so I did not fully understand what they wanted me to present. However after talking to the organizers …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I was invited to give a talk at the inverse seminars symposium:&lt;/p&gt;
&lt;p&gt;&lt;a href="//inverseproblems2018.org/"&gt;https://inverseproblems2018.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;At first I was a little nervous since I don't consider myself an expert in inverse problems so I did not fully understand what they wanted me to present. However after talking to the organizers (Kirk and James), I discovered what they wanted was a high level talk and overview of advanced computing. This was something I could do! I put together snippets from a variety of my previous talks. Here is a link to the slides:&lt;/p&gt;
&lt;p&gt;&lt;a href="./Images/20180604-InverseProblems.pdf"&gt;20180604-InverseProblems&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Originally I planned for a 60 minute talk but only ended up with 45 minutes (at most) of content. Luckly for me the organizers only really wanted a 30 Minutes talk and in the end I was relaxed and able to get though my slides at a reasonable pace in 20 minutes which led to 10 minutes of questions which turned out to be perfect.  &lt;/p&gt;
&lt;p&gt;Overall the Inverse Problems Symposium was a great event and I learned a lot. I was honored to be invited to give a talk. I was even considering attending next year at Notre Dame.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; Dirk &lt;/strong&gt;&lt;/p&gt;</content><category term="Presentations"></category><category term="HPC"></category></entry><entry><title>White Noise and Teaching</title><link href="https://colbrydi.github.io/white-noise-and-teaching.html" rel="alternate"></link><published>2018-05-23T00:00:00-04:00</published><updated>2018-05-23T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-05-23:/white-noise-and-teaching.html</id><summary type="html">&lt;p&gt;It can be difficult to be the first student to talk in a quite classroom.  I have been experimenting with the use of white noise to raise the overall din in the room and encourage taking more quickly.&lt;/p&gt;
&lt;p&gt;When I teach I try to encourage peer and group discussions.  Activities …&lt;/p&gt;</summary><content type="html">&lt;p&gt;It can be difficult to be the first student to talk in a quite classroom.  I have been experimenting with the use of white noise to raise the overall din in the room and encourage taking more quickly.&lt;/p&gt;
&lt;p&gt;When I teach I try to encourage peer and group discussions.  Activities such as think-pair-share, brainstorming and just group problem solving happen in of my classes.  I have started pumping white noise into the room during these work times. I do this more often when class size is low, there is low energy (such as after lunch) or the activity starts with a coding exercise where students work individually.  &lt;/p&gt;
&lt;p&gt;I feel that by using the white noise it encourages talking.  A quite room can
&lt;a href="//coffitivity.com/"&gt;Coffitivity.com&lt;/a&gt;&lt;/p&gt;</content><category term="Product Reviews"></category><category term="Teaching"></category></entry><entry><title>Remember the Milk</title><link href="https://colbrydi.github.io/remember-the-milk.html" rel="alternate"></link><published>2018-05-19T00:00:00-04:00</published><updated>2018-05-19T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-05-19:/remember-the-milk.html</id><summary type="html">&lt;p&gt;I have been a paid subscriber and dedicated customer to Remember the Milk (RTM) for many years (I have lost count). RTM is a todo list application. It is in the same category of something like Wonderlist and ToDoist (There are many others). RTM fits my personality and needs quite …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I have been a paid subscriber and dedicated customer to Remember the Milk (RTM) for many years (I have lost count). RTM is a todo list application. It is in the same category of something like Wonderlist and ToDoist (There are many others). RTM fits my personality and needs quite nicely. My workflow usese a lot of ideas from David Allen's "Getting things Done" (GTD) and I mostly utilize RTM with insparation from the following blog post:&lt;/p&gt;
&lt;p&gt;&lt;a href="blog.rememberthemilk.com/post/116665489183/guest-post-advanced-gtd-with-remember-the-milk"&gt;Remember the Milk&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Over the years I have thought about switching to one of the many different product. However, I like RTM, I like the company and it works for me.  I have my "Smart lists" setup with my basic workflows.&lt;/p&gt;
&lt;p&gt;The smart lists  allow me to "Program" RTM and make it into the app I want.  Sure there are a lot of features I would request but RTM is the tool for me.&lt;/p&gt;</content><category term="Product Reviews"></category><category term="Lifehacking"></category></entry><entry><title>Back to Blogging</title><link href="https://colbrydi.github.io/back-to-blogging.html" rel="alternate"></link><published>2018-05-18T00:00:00-04:00</published><updated>2018-05-18T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-05-18:/back-to-blogging.html</id><summary type="html">&lt;p&gt;I like the idea of blogging but often have difficulty in the delivery.  A few years ago I maintained a blog when I worked for the Institute for Cyber-Enabled Research (iCER) at Michigan State University (MSU). At iCER I did a lot of High Performance Computing (HPC) User support. This …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I like the idea of blogging but often have difficulty in the delivery.  A few years ago I maintained a blog when I worked for the Institute for Cyber-Enabled Research (iCER) at Michigan State University (MSU). At iCER I did a lot of High Performance Computing (HPC) User support. This involved mostly helping researchers figure out how to use advanced computing systems in their research.  I got into a habit of writing up a blog post when I learned something new or figured out a solution to a practical technical problem.  I also found the blog useful for posting slides and examples from presentations I would often make at workshops and conferences. Many of these old posts are still see a little traffic. Check them out here:&lt;/p&gt;
&lt;p&gt;&lt;a href="//wiki.hpcc.msu.edu/display/~colbrydi@msu.edu/Dirk%27s+iCER+wiki+homepage"&gt;iCER Wiki&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I also did some blogging related to my kids and our "maker" hobby.&lt;/p&gt;
&lt;p&gt;&lt;a href="//apprenticemaker.blogspot.com/"&gt;Maker Wiki&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Over the years I moved away from working directly for iCER and have not done a good job keeping up with my maker blog. I am going to try to bring the blogging habit back into my workflow.   I am currently in the middle of quite a few projects relating to education and large scale computing.&lt;/p&gt;
&lt;p&gt;I have a couple of goals for writing a blog. These include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Getting over my reluctance to share and communicate in online communities&lt;/li&gt;
&lt;li&gt;Helping me organize and be accountable for my projects&lt;/li&gt;
&lt;li&gt;Connecting with people with similar interests to my own&lt;/li&gt;
&lt;li&gt;Providing informations that others may find helpful&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To reach these goals I am going to try to get into a daily habit of writing.  I don't think I will post a blog everyday but the writing habit is important to me.&lt;/p&gt;</content><category term="Lifehacking"></category></entry><entry><title>Picking Blog Software</title><link href="https://colbrydi.github.io/picking-blog-software.html" rel="alternate"></link><published>2018-05-18T00:00:00-04:00</published><updated>2018-05-18T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-05-18:/picking-blog-software.html</id><summary type="html">&lt;p&gt;When I was at iCER we used confluence for our &lt;a href="//wiki.hpcc.msu.edu/display/~colbrydi@msu.edu/Dirk%27s+iCER+wiki+homepage"&gt;blogging software&lt;/a&gt; and when I did a (personal blog](//apprenticemaker.blogspot.com/) I used google blogger. On of the barriers for me getting back into blogging (besides my own personal hangups) is that I was never really satisified with either …&lt;/p&gt;</summary><content type="html">&lt;p&gt;When I was at iCER we used confluence for our &lt;a href="//wiki.hpcc.msu.edu/display/~colbrydi@msu.edu/Dirk%27s+iCER+wiki+homepage"&gt;blogging software&lt;/a&gt; and when I did a (personal blog](//apprenticemaker.blogspot.com/) I used google blogger. On of the barriers for me getting back into blogging (besides my own personal hangups) is that I was never really satisified with either solution.  I wanted to "own" my blog information and didn't really feel comfortable with advertisers making money directly from my content (this is it's own argument).  Here are some criteria for what I was looking for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Easy to edit/ add new content&lt;/li&gt;
&lt;li&gt;Easily backed up to my own computer and ported to a different system.&lt;/li&gt;
&lt;li&gt;Ability to modify and add my own tweaks/ features.&lt;/li&gt;
&lt;li&gt;Uses markdown or some similar text based file format to make it easy to use linux commands&lt;/li&gt;
&lt;li&gt;Comments&lt;/li&gt;
&lt;li&gt;Tags&lt;/li&gt;
&lt;li&gt;Usage statistics&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After some digging and talking to people I decided that I wanted to try out a static website generation tool and the obvious one that seemed to fit my interests and criteria is Pelican and a git repository.&lt;/p&gt;
&lt;p&gt;Unfortunately, Pelican was not as easy as I had hoped.  On two different occasions over the last couple of years I have made a deliberate effort to build a new website using Pelican.  It "worked" but there was some missing feature or bug that would get in my way actually making me adopt the format.  I also think that my reluctance to post things makes it harder for me to get started.&lt;/p&gt;
&lt;p&gt;In fact, as I write this blog post (in markdown) I do not actually have a blog to post it on.  My hope is that having some posts already waiting "in the hopper" will make my use of the software easier.  &lt;/p&gt;
&lt;p&gt;With the help of one of my summer students, I am making an effort to try to come up with a useable version of a blog using Pelican.  My feeling is that active open source projects are constantly evolving and therefore getting better. Maybe third time is a charm?  If Pelican still does not work out I may need to explore a different platform.  &lt;/p&gt;
&lt;p&gt;In the end I would like a workflow that not only works for my blog but also for some of other projects that need websites.  I also would like to try to make a kind of Pelican template repository that I can give to some of my peers and make it quick and easy for them to start their own website/blog.&lt;/p&gt;</content><category term="Blogging"></category><category term="Product Reviews"></category></entry><entry><title>Jupyter Accessibility Project</title><link href="https://colbrydi.github.io/jupyter-accessibility-project.html" rel="alternate"></link><published>2018-05-17T00:00:00-04:00</published><updated>2018-05-17T00:00:00-04:00</updated><author><name>Dr. Dirk Colbry</name></author><id>tag:colbrydi.github.io,2018-05-17:/jupyter-accessibility-project.html</id><summary type="html">&lt;p&gt;My university (Michigan State University) plans to scale up the use of Jupyter in our classrooms but we need to address accessibility issues before we can adopt the platform for wide scale use.  On behalf of MSU I had an external group conduct a preliminary audit of our current jupyterhub …&lt;/p&gt;</summary><content type="html">&lt;p&gt;My university (Michigan State University) plans to scale up the use of Jupyter in our classrooms but we need to address accessibility issues before we can adopt the platform for wide scale use.  On behalf of MSU I had an external group conduct a preliminary audit of our current jupyterhub server.  Based on this audit we determined that finding ways to improve Jupyter for the following user communities would be a good start.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Individuals who have some one of the more common types of colorblindness&lt;/li&gt;
&lt;li&gt;Individuals who use screen readers to help with understanding (ex. Dyslexia)&lt;/li&gt;
&lt;li&gt;Individuals with dexterity issues who cannot effectively use a mouse&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For part of my Jupyter hub project I am going to try to address these issues.  My hope is that some people are already working on these issues and I can just integrate existing plugins or patches.  However, If these communities can not be found I will try to build one myself.  I am currently talking with leaders in the Jupyter community to see the best way to build such a community.  Feel free to send me an email (colbrydi@msu.edu) and I would be happy to include you in on the conversation once I figure it out.&lt;/p&gt;</content><category term="Jupyter"></category><category term="Accessibility"></category></entry></feed>